"""
åŸºäº Ollama çš„æ‰¹é‡ç¿»è¯‘è„šæœ¬
å°†ä¸­æ–‡å­—å¹•ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€
ä½¿ç”¨åŒæ­¥è°ƒç”¨ï¼Œä¼˜åŒ–æ€§èƒ½
"""
import sys
import os
import json
import time
from typing import List, Dict, Any
import requests

# å¼ºåˆ¶ UTF-8 è¾“å‡º
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
if sys.stderr.encoding != 'utf-8':
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')


# JSON æå–å‡½æ•°
def extract_translation_from_json(text: str, fallback: str = "") -> str:
    """ä»JSONæ ¼å¼çš„æ¨¡å‹è¾“å‡ºä¸­æå–ç¿»è¯‘ç»“æœ"""
    import re
    try:
        data = json.loads(text)
        if isinstance(data, dict) and "tr" in data:
            result = data["tr"].strip()
            if result.lower() not in ['translation', 'tr', 'key', 'value', '']:
                return result
    except:
        pass

    # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡
    json_patterns = [
        r'\{["\']tr["\']\s*:\s*["\']([^"\']+)["\']\s*\}',
        r'\{\s*"tr"\s*:\s*"([^"]+)"\s*\}',
    ]

    for pattern in json_patterns:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            result = match.group(1).strip()
            if result and result.lower() not in ['translation', 'tr', 'key', 'value']:
                return result

    return fallback if fallback else text

# ä½¿ç”¨ 127.0.0.1 é¿å… Windows ä¸‹ localhost çš„ IPv6 è§£æå»¶è¿Ÿ
OLLAMA_API_URL = 'http://127.0.0.1:11434/v1/chat/completions'

# åˆ›å»ºä¸€ä¸ªsessionä»¥å¤ç”¨è¿æ¥
SESSION = requests.Session()
SESSION.headers.update({'Content-Type': 'application/json'})


def start_ollama_service():
    """
    è‡ªåŠ¨å¯åŠ¨ Ollama æœåŠ¡
    """
    import subprocess
    import platform

    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Ollama æœåŠ¡...", flush=True)

    try:
        if platform.system() == "Windows":
            # Windows: ä½¿ç”¨ START å‘½ä»¤åœ¨æ–°çª—å£ä¸­å¯åŠ¨ ollama serve
            subprocess.Popen(
                ["cmd", "/c", "start", "ollama", "serve"],
                shell=False,
                creationflags=subprocess.CREATE_NEW_CONSOLE
            )
        else:
            # Linux/Mac: åå°å¯åŠ¨
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True
            )

        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        print("â³ ç­‰å¾… Ollama æœåŠ¡å¯åŠ¨...", flush=True)
        max_retries = 10
        for i in range(max_retries):
            time.sleep(2)
            try:
                response = SESSION.get("http://127.0.0.1:11434/api/tags", timeout=2)
                if response.status_code == 200:
                    print(f"âœ… Ollama æœåŠ¡å·²å¯åŠ¨ï¼", flush=True)
                    return True
            except:
                pass
            print(f"  ç­‰å¾…ä¸­... ({i+1}/{max_retries})", flush=True)

        print("âŒ Ollama æœåŠ¡å¯åŠ¨è¶…æ—¶", flush=True)
        return False

    except Exception as e:
        print(f"âŒ å¯åŠ¨ Ollama æœåŠ¡å¤±è´¥: {e}", flush=True)
        return False


def warm_up(model: str = "qwen2.5:7b"):
    """
    çƒ­å¯åŠ¨å‡½æ•°ï¼šå‘é€ä¸€ä¸ªç©ºè¯·æ±‚ï¼Œç¡®ä¿æ¨¡å‹ä»ç¡¬ç›˜åŠ è½½åˆ°äº†æ˜¾å­˜ä¸­ã€‚
    å¦‚æœ Ollama æœªå¯åŠ¨ï¼Œä¼šè‡ªåŠ¨å¯åŠ¨æœåŠ¡ã€‚
    """
    print(f"ğŸ”¥ æ­£åœ¨è¿›è¡Œçƒ­å¯åŠ¨ (åŠ è½½æ¨¡å‹ {model} åˆ°æ˜¾å­˜)...", flush=True)
    start = time.time()

    # å…ˆå°è¯•è¿æ¥
    max_attempts = 2
    for attempt in range(max_attempts):
        try:
            # è®¾ç½® keep_alive=-1 è®©æ¨¡å‹æ°¸ä¹…ä¿æŒåœ¨æ˜¾å­˜ä¸­
            response = SESSION.post(
                OLLAMA_API_URL,
                json={
                    'model': model,
                    'messages': [{"role": "user", "content": "hi"}],
                    'max_tokens': 1,
                    'keep_alive': -1
                },
                timeout=30
            )
            response.raise_for_status()
            elapsed = time.time() - start
            print(f"âœ… çƒ­å¯åŠ¨å®Œæˆï¼åŠ è½½è€—æ—¶: {elapsed:.2f}s", flush=True)
            print(f"âœ… æ¨¡å‹å·²é”å®šåœ¨æ˜¾å­˜ä¸­ï¼ˆä¸ä¼šè‡ªåŠ¨å¸è½½ï¼‰", flush=True)
            print("-" * 60, flush=True)
            return

        except requests.exceptions.ConnectionError as e:
            if attempt == 0:
                # ç¬¬ä¸€æ¬¡å¤±è´¥ï¼Œå°è¯•å¯åŠ¨ Ollama
                print(f"âš ï¸ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡ (å°è¯• {attempt+1}/{max_attempts})", flush=True)
                if start_ollama_service():
                    # é‡æ–°è®¡æ—¶
                    start = time.time()
                    continue
                else:
                    print(f"âŒ è¿æ¥ Ollama å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¼€å¯ã€‚é”™è¯¯ä¿¡æ¯: {e}", flush=True)
                    raise
            else:
                # ç¬¬äºŒæ¬¡è¿˜æ˜¯å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                print(f"âŒ è¿æ¥ Ollama å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¼€å¯ã€‚é”™è¯¯ä¿¡æ¯: {e}", flush=True)
                raise
        except Exception as e:
            print(f"âŒ è¿æ¥ Ollama å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¼€å¯ã€‚é”™è¯¯ä¿¡æ¯: {e}", flush=True)
            raise


def translate_single(
    sentence: str,
    target_language: str,
    task_id: str,
    model: str = "qwen2.5:7b"
) -> Dict[str, Any]:
    """
    å•ä¸ªç¿»è¯‘ä»»åŠ¡ï¼ˆåŒæ­¥ï¼‰

    Args:
        sentence: æºæ–‡æœ¬ï¼ˆä¸­æ–‡ï¼‰
        target_language: ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡åç§°ï¼Œå¦‚"è‹±è¯­"ã€"æ—¥è¯­"ç­‰ï¼‰
        task_id: ä»»åŠ¡ID
        model: æ¨¡å‹åç§°

    Returns:
        dict: ç¿»è¯‘ç»“æœ
    """
    # æ„å»º system prompt - åˆ†ç¦»æŒ‡ä»¤ï¼Œæ•ˆæœæ›´å¥½
    # æ‰€æœ‰è¯­è¨€éƒ½è¦æ±‚ä¸å«æ±‰å­—ï¼ˆå¯¹è¯­éŸ³å…‹éš†å¾ˆé‡è¦ï¼‰
    # æ—¥è¯­ç‰¹æ®Šè¦æ±‚ï¼šå¼ºåˆ¶ä½¿ç”¨å‡å
    if 'æ—¥' in target_language or 'ja' in target_language.lower():
        system_prompt = f'å°†ä¸­æ–‡ç¿»è¯‘æˆ{target_language}ã€‚è¦æ±‚ï¼šæ±‰å­—å¼ºåˆ¶ç”¨å‡åã€è¯­ä¹‰å°½é‡ä¿è¯ã€è¾“å‡ºæç®€ã€å­—æ•°æå°‘ã€‚è¿”å› JSON å¯¹è±¡ï¼ŒKey ä¸º "tr"ã€‚'
    elif 'éŸ©' in target_language or 'ko' in target_language.lower():
        system_prompt = f'å°†ä¸­æ–‡ç¿»è¯‘æˆ{target_language}ã€‚è¦æ±‚ï¼šä¸å«æ±‰å­—ã€è¯­ä¹‰å°½é‡ä¿è¯ã€è¾“å‡ºæç®€ã€å­—æ•°æå°‘ã€‚è¿”å› JSON å¯¹è±¡ï¼ŒKey ä¸º "tr"ã€‚'
    else:
        system_prompt = f'å°†ä¸­æ–‡ç¿»è¯‘æˆ{target_language}ã€‚è¦æ±‚ï¼šè¯­ä¹‰å°½é‡ä¿è¯ã€è¾“å‡ºæç®€ã€å­—æ•°æå°‘ã€‚è¿”å› JSON å¯¹è±¡ï¼ŒKey ä¸º "tr"ã€‚'

    try:
        start_time = time.time()

        # ä½¿ç”¨ requests ç›´æ¥è°ƒç”¨ Ollama API
        response = SESSION.post(
            OLLAMA_API_URL,
            json={
                'model': model,
                'messages': [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": sentence}
                ],
                'temperature': 0,
                'response_format': {"type": "json_object"},
                'stream': False,
                'keep_alive': -1
            },
            timeout=30
        )

        response.raise_for_status()
        result_json = response.json()
        result = result_json['choices'][0]['message']['content'].strip()

        # æå– JSON ä¸­çš„ç¿»è¯‘ç»“æœ
        translation = extract_translation_from_json(result, sentence)

        elapsed = time.time() - start_time

        return {
            "task_id": task_id,
            "source": sentence,
            "translation": translation,
            "success": True,
            "elapsed": elapsed
        }

    except Exception as e:
        print(f"[ç¿»è¯‘é”™è¯¯] {task_id}: {e}", flush=True)
        return {
            "task_id": task_id,
            "source": sentence,
            "translation": sentence,  # å¤±è´¥æ—¶è¿”å›åŸæ–‡
            "success": False,
            "error": str(e)
        }


def batch_translate(
    tasks: List[Dict[str, str]],
    model: str = "qwen2.5:7b"
) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡ç¿»è¯‘ä»»åŠ¡

    Args:
        tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«:
            - task_id: ä»»åŠ¡ID
            - source: æºæ–‡æœ¬ï¼ˆä¸­æ–‡ï¼‰
            - target_language: ç›®æ ‡è¯­è¨€

        model: ä½¿ç”¨çš„æ¨¡å‹åç§°

    Returns:
        List[Dict]: ç¿»è¯‘ç»“æœåˆ—è¡¨
    """
    # 1. çƒ­å¯åŠ¨ï¼ˆä¼šè‡ªåŠ¨æ£€æµ‹ Ollama æ˜¯å¦è¿è¡Œï¼‰
    try:
        warm_up(model=model)
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡å™¨: {e}", flush=True)
        print("è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨ï¼ˆè¿è¡Œ 'ollama serve'ï¼‰", flush=True)
        return []

    # 2. é¡ºåºæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = []
    total = len(tasks)

    print(f"\n[ç¿»è¯‘] å¼€å§‹ç¿»è¯‘ {total} æ¡å­—å¹•...\n", flush=True)

    # è®°å½•æ€»æ—¶é•¿
    batch_start_time = time.time()

    # é€ä¸ªç¿»è¯‘
    for i, task in enumerate(tasks, 1):
        result = translate_single(
            sentence=task["source"],
            target_language=task["target_language"],
            task_id=task["task_id"],
            model=model
        )
        results.append(result)

        # å®æ—¶è¾“å‡ºè¿›åº¦
        status = "âœ“" if result["success"] else "âœ—"
        elapsed = result.get("elapsed", 0)
        source = result["source"][:20] + "..." if len(result["source"]) > 20 else result["source"]
        translation = result["translation"][:30] + "..." if len(result["translation"]) > 30 else result["translation"]

        print(
            f"[{i}/{total}] {status} {result['task_id']}: {source} -> {translation} "
            f"({elapsed:.2f}s)",
            flush=True
        )

    # è®¡ç®—æ€»æ—¶é•¿
    total_elapsed = time.time() - batch_start_time
    avg_elapsed = total_elapsed / total if total > 0 else 0

    print(f"\n[ç¿»è¯‘] âœ“ å®Œæˆæ‰€æœ‰ç¿»è¯‘", flush=True)
    print(f"[ç¿»è¯‘] æ€»è€—æ—¶: {total_elapsed:.2f}ç§’ | å¹³å‡: {avg_elapsed:.2f}ç§’/æ¡\n", flush=True)

    # å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾GPU
    try:
        print(f"[ç¿»è¯‘] æ­£åœ¨å¸è½½æ¨¡å‹ {model}ï¼Œé‡Šæ”¾GPU...", flush=True)
        unload_response = SESSION.post(
            'http://127.0.0.1:11434/api/generate',
            json={
                'model': model,
                'keep_alive': 0
            },
            timeout=10
        )
        if unload_response.status_code == 200:
            print(f"[ç¿»è¯‘] âœ“ æ¨¡å‹å·²å¸è½½ï¼ŒGPUå·²é‡Šæ”¾", flush=True)
    except Exception as e:
        print(f"[ç¿»è¯‘] âš  å¸è½½æ¨¡å‹å¤±è´¥: {e}", flush=True)

    return results


def main(config_path: str):
    """
    ä¸»å‡½æ•°

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
    """
    # è¯»å–é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    tasks = config.get("tasks", [])
    model = config.get("model", "qwen2.5:7b")

    if not tasks:
        print("âŒ æ²¡æœ‰ç¿»è¯‘ä»»åŠ¡", flush=True)
        return

    # æ‰§è¡Œæ‰¹é‡ç¿»è¯‘
    results = batch_translate(tasks, model=model)

    # è¾“å‡ºç»“æœåˆ°æ ‡å‡†è¾“å‡ºï¼ˆJSONæ ¼å¼ï¼‰
    print("\n" + "="*60, flush=True)
    print("ç¿»è¯‘ç»“æœï¼ˆJSONï¼‰:", flush=True)
    print("="*60, flush=True)
    print(json.dumps(results, ensure_ascii=False, indent=2), flush=True)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python batch_translate_ollama.py <config.json>")
        sys.exit(1)

    config_path = sys.argv[1]

    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)

    # è¿è¡Œä¸»å‡½æ•°
    main(config_path)
