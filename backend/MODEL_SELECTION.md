# è‡ªåŠ¨æ¨¡å‹é€‰æ‹©åŠŸèƒ½

## æ›´æ–°æ—¥æœŸ
2025-12-25

## åŠŸèƒ½è¯´æ˜

ç³»ç»Ÿç°åœ¨æ”¯æŒæ ¹æ® GPU æ˜¾å­˜è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„ç¿»è¯‘æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„ç¿»è¯‘è´¨é‡ã€‚

## æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹åç§° | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | ç¿»è¯‘è´¨é‡ | çŠ¶æ€ |
|---------|--------|---------|---------|------|
| Qwen3-4B-FP8 | 4B | ~6 GB | æœ€ä¼˜ | âœ… å·²ä¸‹è½½ |
| Qwen3-4B | 4B | ~8 GB | ä¼˜ç§€ | âš ï¸ æœªä¸‹è½½ |
| Qwen3-1.7B | 1.7B | ~4 GB | è‰¯å¥½ | âœ… å·²ä¸‹è½½ |

## é€‰æ‹©ç­–ç•¥

### è‡ªåŠ¨é€‰æ‹©é€»è¾‘

ç³»ç»Ÿä¼šæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§é€‰æ‹©æ¨¡å‹ï¼š

1. **Qwen3-4B-FP8** (ä¼˜å…ˆ)
   - éœ€è¦çº¦ 6 GB æ˜¾å­˜
   - FP8 é‡åŒ–ï¼Œæ˜¾å­˜å ç”¨è¾ƒå°
   - ç¿»è¯‘è´¨é‡æœ€ä¼˜
   - **æ¨èç”¨äº RTX 5070/5090 ç­‰æ–°å¡**

2. **Qwen3-4B** (å¤‡é€‰)
   - éœ€è¦çº¦ 8 GB æ˜¾å­˜
   - FP16 ç²¾åº¦ï¼Œæ˜¾å­˜å ç”¨è¾ƒå¤§
   - ç¿»è¯‘è´¨é‡ä¼˜ç§€
   - éœ€è¦å•ç‹¬ä¸‹è½½

3. **Qwen3-1.7B** (å›é€€)
   - éœ€è¦çº¦ 4 GB æ˜¾å­˜
   - å°æ¨¡å‹ï¼Œé€Ÿåº¦å¿«
   - ç¿»è¯‘è´¨é‡è‰¯å¥½
   - **æ˜¾å­˜ä¸è¶³æ—¶çš„å›é€€é€‰é¡¹**

### é€‰æ‹©ç¤ºä¾‹

```
[GPUæ£€æµ‹] GPUæ˜¾å­˜ä¿¡æ¯:
  æ€»æ˜¾å­˜: 12.00 GB
  å·²åˆ†é…: 0.00 GB
  å·²ä¿ç•™: 0.00 GB
  å¯ç”¨: 12.00 GB

[æ¨¡å‹é€‰æ‹©] å¯ç”¨æ˜¾å­˜: 12.00 GB
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-4B-FP8 (éœ€è¦ 6.0 GB, å¯ç”¨ 12.00 GB)
```

## å®ç°ç»†èŠ‚

### æ ¸å¿ƒå‡½æ•°

#### 1. `get_gpu_memory_gb()`
```python
def get_gpu_memory_gb() -> float:
    """
    è·å–GPUå¯ç”¨æ˜¾å­˜ï¼ˆGBï¼‰

    Returns:
        float: å¯ç”¨æ˜¾å­˜å¤§å°ï¼ˆGBï¼‰ï¼Œå¦‚æœæ²¡æœ‰GPUè¿”å›0
    """
```

æ£€æµ‹ GPU æ˜¾å­˜ä¿¡æ¯ï¼š
- æ€»æ˜¾å­˜
- å·²åˆ†é…æ˜¾å­˜
- å·²ä¿ç•™æ˜¾å­˜
- å¯ç”¨æ˜¾å­˜

#### 2. `select_model_by_gpu(models_dir: str)`
```python
def select_model_by_gpu(models_dir: str) -> str:
    """
    æ ¹æ®GPUæ˜¾å­˜è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹

    Args:
        models_dir: æ¨¡å‹æ ¹ç›®å½•

    Returns:
        str: é€‰æ‹©çš„æ¨¡å‹è·¯å¾„
    """
```

é€‰æ‹©é€»è¾‘ï¼š
1. æ£€æµ‹å¯ç”¨æ˜¾å­˜
2. éå†æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰æ˜¾å­˜éœ€æ±‚é™åºï¼‰
3. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
4. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦æ»¡è¶³
5. è¿”å›ç¬¬ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„æ¨¡å‹
6. å¦‚æœéƒ½ä¸æ»¡è¶³ï¼Œè¿”å›æœ€å°æ¨¡å‹ä½œä¸ºå›é€€

### é…ç½®æ–‡ä»¶ä¿®æ”¹

#### batch_retranslate.py

```python
# æ—§ä»£ç ï¼šå›ºå®šä½¿ç”¨ Qwen3-1.7B
model_path = os.path.join(models_dir, "Qwen3-1.7B")

# æ–°ä»£ç ï¼šè‡ªåŠ¨é€‰æ‹©æ¨¡å‹
model_path = select_model_by_gpu(models_dir)
```

#### main.py

```python
# æ—§ä»£ç ï¼šåœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šå›ºå®šæ¨¡å‹è·¯å¾„
retranslate_config = {
    "tasks": retranslate_tasks,
    "model_path": model_path,  # å›ºå®šè·¯å¾„
    "num_processes": 1
}

# æ–°ä»£ç ï¼šä¸æŒ‡å®š model_pathï¼Œè®© batch_retranslate.py è‡ªåŠ¨é€‰æ‹©
retranslate_config = {
    "tasks": retranslate_tasks,
    # model_path çœç•¥ï¼Œè‡ªåŠ¨é€‰æ‹©
    "num_processes": 1
}
```

## æœ¬åœ°æ¨¡å‹åŠ è½½

æ‰€æœ‰æ¨¡å‹åŠ è½½éƒ½ä½¿ç”¨ `local_files_only=True` å‚æ•°ï¼Œç¡®ä¿ï¼š

1. âœ… **ä¸è®¿é—®ç½‘ç»œ** - å®Œå…¨ç¦»çº¿å·¥ä½œ
2. âœ… **ä¸ä¸‹è½½æ¨¡å‹** - åªä½¿ç”¨æœ¬åœ°å·²æœ‰æ¨¡å‹
3. âœ… **åŠ è½½é€Ÿåº¦å¿«** - æ— éœ€ç½‘ç»œæ£€æŸ¥
4. âœ… **éšç§ä¿æŠ¤** - ä¸å‘ HuggingFace å‘é€è¯·æ±‚

### ç¯å¢ƒå˜é‡

```python
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'
```

### åŠ è½½ä»£ç 

```python
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    local_files_only=True,  # åªä»æœ¬åœ°åŠ è½½
    trust_remote_code=True,
    use_fast=True
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True,
    local_files_only=True  # åªä»æœ¬åœ°åŠ è½½
)
```

## å¦‚ä½•ä¸‹è½½ Qwen3-4B æ¨¡å‹

å¦‚æœä½ æƒ³ä½¿ç”¨å®Œæ•´ç²¾åº¦çš„ Qwen3-4B æ¨¡å‹ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½ï¼š

### æ–¹æ³•1: ä½¿ç”¨ HuggingFace CLI

```bash
# æ¿€æ´» qwen_inference ç¯å¢ƒ
conda activate qwen_inference

# ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
huggingface-cli download Qwen/Qwen3-4B \
  --local-dir C:\workspace\ai_editing\models\Qwen3-4B \
  --resume-download
```

### æ–¹æ³•2: ä½¿ç”¨ Python è„šæœ¬

```python
from huggingface_hub import snapshot_download

snapshot_download(
    repo_id="Qwen/Qwen3-4B",
    local_dir="C:\\workspace\\ai_editing\\models\\Qwen3-4B",
    resume_download=True
)
```

### æ–¹æ³•3: ä½¿ç”¨ Git LFS

```bash
cd C:\workspace\ai_editing\models
git lfs clone https://huggingface.co/Qwen/Qwen3-4B
```

ä¸‹è½½å®Œæˆåï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨æ˜¾å­˜å……è¶³æ—¶é€‰æ‹©ä½¿ç”¨ Qwen3-4Bã€‚

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# æ–¹æ³•1: ä½¿ç”¨æ‰¹å¤„ç†æ–‡ä»¶
cd C:\workspace\ai_editing\workspace\LocalClip-Editor\backend
test_model_select.bat

# æ–¹æ³•2: æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒ
conda activate qwen_inference
python test_model_selection.py
```

### é¢„æœŸè¾“å‡º

```
ğŸ” å¼€å§‹æµ‹è¯•æ¨¡å‹é€‰æ‹©åŠŸèƒ½...

============================================================
æµ‹è¯•GPUæ˜¾å­˜æ£€æµ‹
============================================================
[GPUæ£€æµ‹] GPUæ˜¾å­˜ä¿¡æ¯:
  æ€»æ˜¾å­˜: 12.00 GB
  å·²åˆ†é…: 0.00 GB
  å·²ä¿ç•™: 0.00 GB
  å¯ç”¨: 12.00 GB

âœ… GPUæ£€æµ‹æˆåŠŸï¼Œå¯ç”¨æ˜¾å­˜: 12.00 GB

============================================================
æµ‹è¯•æ¨¡å‹é€‰æ‹©
============================================================

æ¨¡å‹ç›®å½•: C:\workspace\ai_editing\models

å¯ç”¨æ¨¡å‹:
  âœ“ Qwen3-4B-FP8
  âœ— Qwen3-4B
  âœ“ Qwen3-1.7B

------------------------------------------------------------
[æ¨¡å‹é€‰æ‹©] å¯ç”¨æ˜¾å­˜: 12.00 GB
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-4B-FP8 (éœ€è¦ 6.0 GB, å¯ç”¨ 12.00 GB)
------------------------------------------------------------

âœ… é€‰æ‹©çš„æ¨¡å‹è·¯å¾„: C:\workspace\ai_editing\models\Qwen3-4B-FP8
   æ¨¡å‹åç§°: Qwen3-4B-FP8

============================================================
æµ‹è¯•æ€»ç»“
============================================================
âœ… GPUå¯ç”¨æ˜¾å­˜: 12.00 GB
âœ… å·²é€‰æ‹©æ¨¡å‹: Qwen3-4B-FP8

ğŸ’¡ å»ºè®®: ä½¿ç”¨ Qwen3-4B-FP8 å¯ä»¥è·å¾—æœ€ä½³ç¿»è¯‘è´¨é‡

============================================================
âœ… æµ‹è¯•å®Œæˆ
============================================================
```

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šæ¨¡å‹ï¼Ÿ

åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜¾å¼æŒ‡å®š `model_path`:

```json
{
  "tasks": [...],
  "model_path": "C:\\workspace\\ai_editing\\models\\Qwen3-1.7B",
  "num_processes": 1
}
```

### Q2: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

ç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ° Qwen3-1.7Bã€‚å¦‚æœè¿ 1.7B éƒ½æ— æ³•åŠ è½½ï¼Œå»ºè®®ï¼š
1. å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº
2. å‡å°‘ Fish-Speech ç­‰å…¶ä»–æ¨¡å‹çš„æ˜¾å­˜å ç”¨
3. è€ƒè™‘å‡çº§ GPU

### Q3: å¦‚ä½•æŸ¥çœ‹å½“å‰ä½¿ç”¨çš„æ¨¡å‹ï¼Ÿ

æŸ¥çœ‹æ—¥å¿—è¾“å‡ºï¼š

```
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-4B-FP8 (éœ€è¦ 6.0 GB, å¯ç”¨ 12.00 GB)
[PID 12345] Loading model from C:\workspace\ai_editing\models\Qwen3-4B-FP8...
```

### Q4: FP8 æ¨¡å‹å’Œ FP16 æ¨¡å‹çš„åŒºåˆ«ï¼Ÿ

- **FP8**: 8ä½æµ®ç‚¹ç²¾åº¦
  - âœ… æ˜¾å­˜å ç”¨æ›´å°ï¼ˆçº¦ 6GBï¼‰
  - âœ… æ¨ç†é€Ÿåº¦æ›´å¿«
  - âš ï¸ ç²¾åº¦ç•¥æœ‰æŸå¤±ï¼ˆä½†ç¿»è¯‘è´¨é‡ä»ç„¶å¾ˆå¥½ï¼‰

- **FP16**: 16ä½æµ®ç‚¹ç²¾åº¦
  - âœ… ç²¾åº¦æ›´é«˜
  - âš ï¸ æ˜¾å­˜å ç”¨æ›´å¤§ï¼ˆçº¦ 8GBï¼‰
  - âš ï¸ æ¨ç†é€Ÿåº¦ç¨æ…¢

å¯¹äºçŸ­æ–‡æœ¬ç¿»è¯‘ä»»åŠ¡ï¼ŒFP8 æ¨¡å‹å·²ç»è¶³å¤Ÿå¥½ï¼Œæ€§ä»·æ¯”æœ€é«˜ã€‚

## æ–‡ä»¶æ¸…å•

### ä¿®æ”¹çš„æ–‡ä»¶

1. **backend/batch_retranslate.py**
   - æ–°å¢ `get_gpu_memory_gb()` å‡½æ•°
   - æ–°å¢ `select_model_by_gpu()` å‡½æ•°
   - ä¿®æ”¹ `retranslate_from_config()` ä½¿ç”¨è‡ªåŠ¨é€‰æ‹©

2. **backend/main.py**
   - ä¿®æ”¹é…ç½®æ–‡ä»¶ç”Ÿæˆé€»è¾‘ï¼ˆåˆ é™¤å›ºå®š model_pathï¼‰
   - ä¸¤å¤„ä¿®æ”¹ï¼šè¯­éŸ³å…‹éš† + ç¿»è¯‘ API

### æ–°å¢çš„æ–‡ä»¶

1. **backend/test_model_selection.py**
   - GPU æ˜¾å­˜æ£€æµ‹æµ‹è¯•
   - æ¨¡å‹é€‰æ‹©é€»è¾‘æµ‹è¯•
   - ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š

2. **backend/test_model_select.bat**
   - Windows æ‰¹å¤„ç†å¯åŠ¨è„šæœ¬
   - è‡ªåŠ¨æ¿€æ´» conda ç¯å¢ƒ

3. **backend/MODEL_SELECTION.md**
   - æœ¬æ–‡æ¡£

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### RTX 5090 (24GB æ˜¾å­˜)

```
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-4B-FP8
```

- æ˜¾å­˜å……è¶³ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€å¤§æ¨¡å‹
- ç¿»è¯‘è´¨é‡æœ€ä¼˜
- å¯åŒæ—¶è¿è¡Œ Fish-Speech

### RTX 5070 (12GB æ˜¾å­˜)

```
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-4B-FP8
```

- æ˜¾å­˜è¶³å¤Ÿè¿è¡Œ Qwen3-4B-FP8
- éœ€è¦æ³¨æ„ä¸ Fish-Speech çš„æ˜¾å­˜åˆ†é…
- å»ºè®®å•ç‹¬è¿è¡Œç¿»è¯‘ä»»åŠ¡

### å…¶ä»–æ˜¾å¡ (<8GB æ˜¾å­˜)

```
[æ¨¡å‹é€‰æ‹©] âœ“ é€‰æ‹© Qwen3-1.7B
```

- è‡ªåŠ¨å›é€€åˆ°å°æ¨¡å‹
- ä»èƒ½ä¿è¯åŸºæœ¬çš„ç¿»è¯‘è´¨é‡
- é€Ÿåº¦æ›´å¿«

## ä¼˜åŒ–å»ºè®®

### å½“å‰ä¼˜åŒ–

1. âœ… è‡ªåŠ¨æ¨¡å‹é€‰æ‹© - æ ¹æ® GPU æ˜¾å­˜æ™ºèƒ½é€‰æ‹©
2. âœ… æœ¬åœ°åŠ è½½ - å®Œå…¨ç¦»çº¿ï¼Œä¸ä¾èµ–ç½‘ç»œ
3. âœ… å•è¿›ç¨‹æ¨¡å¼ - é¿å…æ˜¾å­˜å†²çª
4. âœ… å®æ—¶æ—¥å¿— - æ¯å¥ç¿»è¯‘ç«‹å³è¾“å‡º

### æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **æ¨¡å‹é¢„åŠ è½½ç¼“å­˜**
   - ä¿æŒæ¨¡å‹å¸¸é©»å†…å­˜
   - é¿å…é‡å¤åŠ è½½
   - æå‡å“åº”é€Ÿåº¦

2. **æ‰¹é‡ä¼˜åŒ–**
   - æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œï¼ˆå¦‚æœæ˜¾å­˜å……è¶³ï¼‰
   - åŠ¨æ€è°ƒæ•´ batch size
   - æå‡ååé‡

3. **æ¨¡å‹é‡åŒ–**
   - æ”¯æŒ INT8/INT4 é‡åŒ–
   - è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨
   - é€‚é…æ›´å¤šç¡¬ä»¶ç¯å¢ƒ

4. **A/B æµ‹è¯•**
   - å¯¹æ¯”ä¸åŒæ¨¡å‹çš„ç¿»è¯‘è´¨é‡
   - æ”¶é›†ç”¨æˆ·åé¦ˆ
   - ä¼˜åŒ–æ¨¡å‹é€‰æ‹©ç­–ç•¥

## æ€»ç»“

### ä¸»è¦æ”¹è¿›

1. âœ… **æ™ºèƒ½æ¨¡å‹é€‰æ‹©** - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®
2. âœ… **æ˜¾å­˜æ„ŸçŸ¥** - æ ¹æ®å®é™…æ˜¾å­˜æƒ…å†µåŠ¨æ€è°ƒæ•´
3. âœ… **å‘åå…¼å®¹** - ç°æœ‰åŠŸèƒ½ä¸å—å½±å“
4. âœ… **æœ¬åœ°ä¼˜å…ˆ** - å®Œå…¨ç¦»çº¿å·¥ä½œï¼Œéšç§å®‰å…¨
5. âœ… **å·²ä¸‹è½½ Qwen3-4B-FP8** - ç”Ÿäº§ç¯å¢ƒå¯ç«‹å³ä½¿ç”¨

### ç”¨æˆ·ä½“éªŒæå‡

- ğŸš€ **æ›´å¥½çš„ç¿»è¯‘è´¨é‡** - ä¼˜å…ˆä½¿ç”¨ 4B æ¨¡å‹
- âš¡ **æ›´å¿«çš„æ¨ç†é€Ÿåº¦** - FP8 é‡åŒ–åŠ é€Ÿ
- ğŸ”§ **é›¶é…ç½®** - è‡ªåŠ¨é€‰æ‹©ï¼Œå¼€ç®±å³ç”¨
- ğŸ“Š **é€æ˜åº¦é«˜** - è¯¦ç»†æ—¥å¿—ï¼ŒçŠ¶æ€æ¸…æ™°
