# -*- coding: utf-8 -*-
# è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨torch dynamoï¼ˆåœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰ï¼‰
import os
os.environ["TORCH_DYNAMO_DISABLE"] = "1"

# åŠ è½½ .env é…ç½®æ–‡ä»¶
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶
project_root = Path(__file__).parent.parent
dotenv_path = project_root / '.env'
if dotenv_path.exists():
    load_dotenv(dotenv_path)
    print(f"[OK] å·²åŠ è½½ç¯å¢ƒé…ç½®: {dotenv_path}")
else:
    print(f"[WARNING] æœªæ‰¾åˆ° .env æ–‡ä»¶: {dotenv_path}")

from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse, FileResponse
import uuid
from pathlib import Path
from typing import Optional
import json
import re

from video_processor import VideoProcessor
from srt_parser import SRTParser

# æ·»åŠ å¯¹è¯´è¯äººè¯†åˆ«åŠŸèƒ½çš„æ”¯æŒ
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥speaker_diarization_processingæ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'speaker_diarization_processing'))
from audio_extraction import AudioExtractor
from embedding_extraction import SpeakerEmbeddingExtractor
from cluster_processor import SpeakerClusterer

app = FastAPI(title="LocalClip Editor API", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”é™åˆ¶ä¸ºå…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¡®ä¿ä¸Šä¼ å’Œå¯¼å‡ºç›®å½•å­˜åœ¨
UPLOADS_DIR = Path("uploads")
EXPORTS_DIR = Path("exports")

UPLOADS_DIR.mkdir(exist_ok=True)
EXPORTS_DIR.mkdir(exist_ok=True)

# è‡ªå®šä¹‰è§†é¢‘è·¯ç”±ï¼Œæ”¯æŒ Range è¯·æ±‚
@app.get("/uploads/{filename}")
async def serve_video(filename: str, request: Request):
    """æä¾›æ”¯æŒ HTTP Range è¯·æ±‚çš„è§†é¢‘æµå¼ä¼ è¾“"""
    file_path = UPLOADS_DIR / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶æœªæ‰¾åˆ°")

    file_size = file_path.stat().st_size
    range_header = request.headers.get("range")

    # å¦‚æœæ²¡æœ‰ Range è¯·æ±‚å¤´ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
    if not range_header:
        return FileResponse(
            file_path,
            media_type="video/mp4",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
            }
        )

    # è§£æ Range è¯·æ±‚å¤´
    range_match = re.match(r"bytes=(\d+)-(\d*)", range_header)
    if not range_match:
        raise HTTPException(status_code=416, detail="Invalid range")

    start = int(range_match.group(1))
    end = int(range_match.group(2)) if range_match.group(2) else file_size - 1

    # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
    if start >= file_size or end >= file_size or start > end:
        raise HTTPException(status_code=416, detail="Range not satisfiable")

    chunk_size = end - start + 1

    # è¯»å–æ–‡ä»¶çš„æŒ‡å®šèŒƒå›´
    def iterfile():
        with open(file_path, "rb") as f:
            f.seek(start)
            remaining = chunk_size
            while remaining > 0:
                chunk = f.read(min(8192, remaining))
                if not chunk:
                    break
                remaining -= len(chunk)
                yield chunk

    # è¿”å› 206 Partial Content
    return StreamingResponse(
        iterfile(),
        status_code=206,
        media_type="video/mp4",
        headers={
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Accept-Ranges": "bytes",
            "Content-Length": str(chunk_size),
        }
    )

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆç”¨äºå…¶ä»–éè§†é¢‘æ–‡ä»¶ï¼‰
# æ³¨æ„ï¼šè§†é¢‘æ–‡ä»¶ä¼šè¢«ä¸Šé¢çš„è·¯ç”±ä¼˜å…ˆå¤„ç†
app.mount("/exports", StaticFiles(directory=EXPORTS_DIR), name="exports")

# åˆå§‹åŒ–å¤„ç†å™¨
video_processor = VideoProcessor()
srt_parser = SRTParser()

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨è¯´è¯äººè¯†åˆ«å¤„ç†çŠ¶æ€
speaker_processing_status = {}

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨è¯­éŸ³å…‹éš†å¤„ç†çŠ¶æ€
voice_cloning_status = {}

# å…¨å±€ç¼“å­˜ï¼šå­˜å‚¨å·²æå–çš„éŸ³é¢‘ç‰‡æ®µä¿¡æ¯ï¼Œé¿å…é‡å¤æå–
# key: (video_filename, subtitle_filename), value: {"audio_paths": [...], "speaker_labels": [...], "audio_dir": "..."}
audio_extraction_cache = {}

@app.get("/")
async def root():
    return {"message": "LocalClip Editor API"}

@app.post("/upload/video")
async def upload_video(file: UploadFile = File(...)):
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_types = [".mp4", ".mov", ".avi", ".mkv"]
        file_extension = Path(file.filename).suffix.lower()
        
        if file_extension not in allowed_types:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = UPLOADS_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = video_processor.get_video_info(str(file_path))
        
        return {
            "filename": unique_filename,
            "original_name": file.filename,
            "size": os.path.getsize(file_path),
            "video_info": video_info
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/subtitle")
async def upload_subtitle(file: UploadFile = File(...)):
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename.lower().endswith('.srt'):
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒSRTå­—å¹•æ–‡ä»¶")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        unique_filename = f"{uuid.uuid4()}.srt"
        file_path = UPLOADS_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # è§£æSRTæ–‡ä»¶
        subtitles = srt_parser.parse_srt(str(file_path))
        
        return {
            "filename": unique_filename,
            "original_name": file.filename,
            "size": os.path.getsize(file_path),
            "subtitles": subtitles
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/videos")
async def get_videos():
    video_extensions = {".mp4", ".mov", ".avi", ".mkv"}
    videos = []
    
    for file_path in UPLOADS_DIR.iterdir():
        if file_path.suffix.lower() in video_extensions:
            video_info = video_processor.get_video_info(str(file_path))
            videos.append({
                "filename": file_path.name,
                "size": os.path.getsize(file_path),
                "video_info": video_info
            })
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    videos.sort(key=lambda x: UPLOADS_DIR.joinpath(x["filename"]).stat().st_mtime, reverse=True)
    
    return {"videos": videos}

from pydantic import BaseModel

class SpeakerDiarizationRequest(BaseModel):
    video_filename: str
    subtitle_filename: str

@app.post("/speaker-diarization/process")
async def process_speaker_diarization(request: SpeakerDiarizationRequest):
    """å¯åŠ¨è¯´è¯äººè¯†åˆ«å’Œèšç±»å¤„ç†æµç¨‹"""
    try:
        print(f"\n===== æ”¶åˆ°è¯´è¯äººè¯†åˆ«è¯·æ±‚ =====")
        print(f"è§†é¢‘æ–‡ä»¶å: {request.video_filename}")
        print(f"å­—å¹•æ–‡ä»¶å: {request.subtitle_filename}")

        video_path = UPLOADS_DIR / request.video_filename
        subtitle_path = UPLOADS_DIR / request.subtitle_filename

        print(f"æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨...")
        print(f"è§†é¢‘è·¯å¾„: {video_path}, å­˜åœ¨: {video_path.exists()}")
        print(f"å­—å¹•è·¯å¾„: {subtitle_path}, å­˜åœ¨: {subtitle_path.exists()}")

        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not subtitle_path.exists():
            raise HTTPException(status_code=404, detail="å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")

        # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        print(f"ç”Ÿæˆä»»åŠ¡ID: {task_id}")

        # è®¾ç½®åˆå§‹å¤„ç†çŠ¶æ€
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "ä»»åŠ¡å¯åŠ¨ä¸­...",
            "progress": 0
        }
        print(f"è®¾ç½®åˆå§‹çŠ¶æ€: {speaker_processing_status[task_id]}")

        # åœ¨åå°æ‰§è¡Œå¤„ç†
        import asyncio
        print(f"åˆ›å»ºåå°ä»»åŠ¡...")
        task = asyncio.create_task(run_speaker_diarization_process(task_id, str(video_path), str(subtitle_path)))

        # æ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒ
        def handle_task_exception(t):
            try:
                t.result()
            except Exception as e:
                import traceback
                print(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {traceback.format_exc()}")

        task.add_done_callback(handle_task_exception)
        print(f"åå°ä»»åŠ¡å·²åˆ›å»º")

        return {
            "task_id": task_id,
            "message": "è¯´è¯äººè¯†åˆ«ä»»åŠ¡å·²å¯åŠ¨",
            "status": "processing"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def run_speaker_diarization_process(task_id: str, video_path: str, subtitle_path: str):
    """åå°æ‰§è¡Œè¯´è¯äººè¯†åˆ«å’Œèšç±»å¤„ç†"""
    import time
    start_time = time.time()

    try:
        import asyncio

        print(f"\n========== å¼€å§‹æ‰§è¡Œè¯´è¯äººè¯†åˆ«ä»»åŠ¡: {task_id} ==========")
        print(f"è§†é¢‘è·¯å¾„: {video_path}")
        print(f"å­—å¹•è·¯å¾„: {subtitle_path}")

        # ç­‰å¾…2ç§’ï¼Œç¡®ä¿å‰ç«¯å¼€å§‹è½®è¯¢
        await asyncio.sleep(2)

        # ä»»åŠ¡1ï¼šéŸ³é¢‘åˆ‡åˆ† (0-25%)
        print(f"[ä»»åŠ¡1] æ›´æ–°çŠ¶æ€: éŸ³é¢‘åˆ‡åˆ†ä¸­... (5%)")
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "éŸ³é¢‘åˆ‡åˆ†ä¸­...",
            "progress": 5
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’ï¼Œè®©å‰ç«¯çœ‹åˆ°è¿™ä¸ªçŠ¶æ€

        # æå–éŸ³é¢‘ç‰‡æ®µ
        audio_dir = os.path.join("..", "audio_segments", task_id)
        extractor = AudioExtractor(cache_dir=audio_dir)
        audio_paths = extractor.extract_audio_segments(video_path, subtitle_path)

        # ä»»åŠ¡2ï¼šè¯´è¯äººè¯†åˆ« (25-60%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "è¯´è¯äººç‰¹å¾æå–ä¸­...",
            "progress": 30
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æå–åµŒå…¥
        embedding_extractor = SpeakerEmbeddingExtractor(offline_mode=True)
        embeddings = embedding_extractor.extract_embeddings(audio_paths)

        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "è¯´è¯äººèšç±»åˆ†æä¸­...",
            "progress": 55
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # èšç±»è¯†åˆ«è¯´è¯äºº
        clusterer = SpeakerClusterer()
        speaker_labels = clusterer.cluster_embeddings(embeddings)

        # ä»»åŠ¡3ï¼šMOSéŸ³é¢‘è´¨é‡è¯„åˆ† (60-80%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "éŸ³é¢‘è´¨é‡è¯„ä¼°ä¸­...",
            "progress": 65
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æŒ‰è¯´è¯äººåˆ†ç»„éŸ³é¢‘
        speaker_segments = {}
        for audio_path, speaker_id in zip(audio_paths, speaker_labels):
            if speaker_id is not None:
                if speaker_id not in speaker_segments:
                    speaker_segments[speaker_id] = []
                speaker_segments[speaker_id].append(audio_path)

        # è®¡ç®—MOSåˆ†æ•°ï¼ˆä½¿ç”¨ NISQAï¼‰
        from nisqa_scorer import NISQAScorer
        mos_scorer = NISQAScorer()
        scored_segments = mos_scorer.score_speaker_audios(audio_dir, speaker_segments)

        print(f"å·²å®ŒæˆMOSè¯„åˆ†ï¼ˆNISQAï¼‰ï¼Œå…± {len(scored_segments)} ä¸ªè¯´è¯äºº")

        # ä»»åŠ¡4ï¼šæ€§åˆ«è¯†åˆ« (80-100%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "æ€§åˆ«è¯†åˆ«åˆ†æä¸­...",
            "progress": 85
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æ€§åˆ«è¯†åˆ«
        from gender_classifier import GenderClassifier, rename_speakers_by_gender
        gender_classifier = GenderClassifier()
        gender_dict = gender_classifier.classify_speakers(scored_segments, min_duration=2.0)

        # æ ¹æ®æ€§åˆ«å’Œå‡ºç°æ¬¡æ•°é‡æ–°å‘½åè¯´è¯äºº
        print(f"\næ ¹æ®æ€§åˆ«å’Œå‡ºç°æ¬¡æ•°é‡æ–°å‘½åè¯´è¯äºº...")
        speaker_name_mapping, gender_stats = rename_speakers_by_gender(speaker_labels, gender_dict)

        print(f"\næ€§åˆ«ç»Ÿè®¡: ç”·æ€§ {gender_stats['male']} äºº, å¥³æ€§ {gender_stats['female']} äºº")

        # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜ï¼Œä¾›è¯­éŸ³å…‹éš†å¤ç”¨
        video_filename = os.path.basename(video_path)
        subtitle_filename = os.path.basename(subtitle_path)
        cache_key = (video_filename, subtitle_filename)
        audio_extraction_cache[cache_key] = {
            "audio_paths": audio_paths,
            "speaker_labels": speaker_labels,
            "audio_dir": audio_dir,
            "task_id": task_id,
            "scored_segments": scored_segments,  # ä¿å­˜MOSè¯„åˆ†ç»“æœ
            "gender_dict": gender_dict,  # ä¿å­˜æ€§åˆ«è¯†åˆ«ç»“æœ
            "speaker_name_mapping": speaker_name_mapping,  # ä¿å­˜è¯´è¯äººåç§°æ˜ å°„
            "gender_stats": gender_stats  # ä¿å­˜æ€§åˆ«ç»Ÿè®¡
        }
        print(f"å·²ç¼“å­˜éŸ³é¢‘æå–ç»“æœã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«: {cache_key}")

        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        def format_duration(seconds):
            """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´å­—ç¬¦ä¸²"""
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(total_duration)

        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        speaker_processing_status[task_id] = {
            "status": "completed",
            "message": f"å…¨éƒ¨ä»»åŠ¡å·²å®Œæˆ (è€—æ—¶: {duration_str})",
            "progress": 100,
            "speaker_labels": speaker_labels,
            "unique_speakers": clusterer.get_unique_speakers_count(speaker_labels),
            "speaker_name_mapping": speaker_name_mapping,
            "gender_stats": gender_stats,
            "total_duration": total_duration,
            "duration_str": duration_str
        }

        print(f"\nâœ… è¯´è¯äººè¯†åˆ«ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")

    except Exception as e:
        # è®¡ç®—å¤±è´¥æ—¶çš„è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time
        duration_str = f"{total_duration:.1f}ç§’"

        # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        import traceback
        error_detail = traceback.format_exc()
        print(f"\n========== è¯´è¯äººè¯†åˆ«ä»»åŠ¡å¤±è´¥: {task_id} ==========")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"è¯¦ç»†å †æ ˆ:\n{error_detail}")
        print(f"â±ï¸  å¤±è´¥å‰è€—æ—¶: {duration_str}")

        speaker_processing_status[task_id] = {
            "status": "failed",
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "progress": 0,
            "total_duration": total_duration,
            "duration_str": duration_str
        }


@app.get("/speaker-diarization/status/{task_id}")
async def get_speaker_diarization_status(task_id: str):
    """è·å–è¯´è¯äººè¯†åˆ«å¤„ç†çŠ¶æ€"""
    print(f"[çŠ¶æ€æŸ¥è¯¢] task_id: {task_id}")
    if task_id not in speaker_processing_status:
        print(f"[çŠ¶æ€æŸ¥è¯¢] ä»»åŠ¡ä¸å­˜åœ¨")
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    status = speaker_processing_status[task_id]
    print(f"[çŠ¶æ€æŸ¥è¯¢] è¿”å›çŠ¶æ€: {status}")
    return status


class VoiceCloningRequest(BaseModel):
    video_filename: str
    source_subtitle_filename: str
    target_language: str
    target_subtitle_filename: str


@app.post("/voice-cloning/process")
async def process_voice_cloning(request: VoiceCloningRequest):
    """å¯åŠ¨è¯­éŸ³å…‹éš†å¤„ç†æµç¨‹ï¼ˆå½“å‰ä¸ºç©ºå®ç°ï¼‰"""
    try:
        video_path = UPLOADS_DIR / request.video_filename
        source_subtitle_path = UPLOADS_DIR / request.source_subtitle_filename
        target_subtitle_path = UPLOADS_DIR / request.target_subtitle_filename

        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not source_subtitle_path.exists():
            raise HTTPException(status_code=404, detail="æºå­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")
        if not target_subtitle_path.exists():
            raise HTTPException(status_code=404, detail="ç›®æ ‡å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")

        # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ä»»åŠ¡ID
        task_id = str(uuid.uuid4())

        # è®¾ç½®å¤„ç†çŠ¶æ€
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨å‡†å¤‡è¯­éŸ³å…‹éš†...",
            "progress": 0
        }

        # åœ¨åå°æ‰§è¡Œå¤„ç†
        import asyncio
        task = asyncio.create_task(run_voice_cloning_process(
            task_id,
            str(video_path),
            str(source_subtitle_path),
            request.target_language,
            str(target_subtitle_path)
        ))

        # æ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒ
        def handle_task_exception(t):
            try:
                t.result()
            except Exception as e:
                import traceback
                print(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {traceback.format_exc()}")

        task.add_done_callback(handle_task_exception)

        return {
            "task_id": task_id,
            "message": "è¯­éŸ³å…‹éš†ä»»åŠ¡å·²å¯åŠ¨",
            "status": "processing"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def run_voice_cloning_process(
    task_id: str,
    video_path: str,
    source_subtitle_path: str,
    target_language: str,
    target_subtitle_path: str
):
    """åå°æ‰§è¡Œè¯­éŸ³å…‹éš†å¤„ç†"""
    import time
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

    try:
        import asyncio
        from nisqa_scorer import NISQAScorer
        from speaker_audio_processor import SpeakerAudioProcessor
        from subtitle_text_extractor import SubtitleTextExtractor

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²æå–çš„éŸ³é¢‘
        video_filename = os.path.basename(video_path)
        subtitle_filename = os.path.basename(source_subtitle_path)
        cache_key = (video_filename, subtitle_filename)

        # é»˜è®¤å€¼
        scored_segments = None
        has_cached_mos = False
        gender_dict = {}
        speaker_name_mapping = {}

        if cache_key in audio_extraction_cache:
            # å¤ç”¨å·²æå–çš„éŸ³é¢‘ã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«
            print(f"å¤ç”¨å·²ç¼“å­˜çš„éŸ³é¢‘æå–ç»“æœã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«: {cache_key}")
            cached_data = audio_extraction_cache[cache_key]
            audio_paths = cached_data["audio_paths"]
            speaker_labels = cached_data["speaker_labels"]
            audio_dir = cached_data["audio_dir"]
            scored_segments = cached_data.get("scored_segments")  # è·å–ç¼“å­˜çš„MOSè¯„åˆ†
            gender_dict = cached_data.get("gender_dict", {})  # è·å–æ€§åˆ«è¯†åˆ«ç»“æœ
            speaker_name_mapping = cached_data.get("speaker_name_mapping", {})  # è·å–è¯´è¯äººåç§°æ˜ å°„
            has_cached_mos = scored_segments is not None

            # æ›´æ–°çŠ¶æ€ï¼šå¤ç”¨å·²æå–çš„éŸ³é¢‘
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨å¤ç”¨å·²æå–çš„éŸ³é¢‘ã€è¯´è¯äººè¯†åˆ«ã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«ç»“æœ...",
                "progress": 35
            }
        else:
            # éœ€è¦é‡æ–°æå–éŸ³é¢‘
            print(f"æœªæ‰¾åˆ°ç¼“å­˜ï¼Œé‡æ–°æå–éŸ³é¢‘: {cache_key}")

            # æ›´æ–°çŠ¶æ€ï¼šæå–éŸ³é¢‘ç‰‡æ®µ
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨æå–éŸ³é¢‘ç‰‡æ®µ...",
                "progress": 5
            }

            # 1. æå–éŸ³é¢‘ç‰‡æ®µ
            audio_dir = os.path.join("..", "audio_segments", task_id)
            extractor = AudioExtractor(cache_dir=audio_dir)
            audio_paths = extractor.extract_audio_segments(video_path, source_subtitle_path)

            # æ›´æ–°çŠ¶æ€ï¼šæå–è¯´è¯äººåµŒå…¥
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨æå–è¯´è¯äººåµŒå…¥...",
                "progress": 15
            }

            # 2. æå–åµŒå…¥
            embedding_extractor = SpeakerEmbeddingExtractor(offline_mode=True)
            embeddings = embedding_extractor.extract_embeddings(audio_paths)

            # æ›´æ–°çŠ¶æ€ï¼šè¯†åˆ«è¯´è¯äºº
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨è¯†åˆ«è¯´è¯äºº...",
                "progress": 25
            }

            # 3. èšç±»è¯†åˆ«è¯´è¯äºº
            clusterer = SpeakerClusterer()
            speaker_labels = clusterer.cluster_embeddings(embeddings)

        # 4. å¦‚æœæ²¡æœ‰ç¼“å­˜çš„MOSè¯„åˆ†ï¼Œåˆ™éœ€è¦è®¡ç®—
        if not has_cached_mos:
            # æŒ‰è¯´è¯äººåˆ†ç»„éŸ³é¢‘
            speaker_segments = {}
            for audio_path, speaker_id in zip(audio_paths, speaker_labels):
                if speaker_id is not None:
                    if speaker_id not in speaker_segments:
                        speaker_segments[speaker_id] = []
                    speaker_segments[speaker_id].append(audio_path)

            # æ›´æ–°çŠ¶æ€ï¼šMOSè¯„åˆ†
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨å¯¹éŸ³é¢‘ç‰‡æ®µè¿›è¡Œè´¨é‡è¯„åˆ†...",
                "progress": 35
            }

            # 5. MOSæ‰“åˆ†ï¼ˆä½¿ç”¨ NISQAï¼‰
            mos_scorer = NISQAScorer()
            scored_segments = mos_scorer.score_speaker_audios(audio_dir, speaker_segments)
            print(f"å·²å®ŒæˆMOSè¯„åˆ†ï¼ˆNISQAï¼‰")
        else:
            print(f"ä½¿ç”¨ç¼“å­˜çš„MOSè¯„åˆ†ç»“æœ")

        # æ›´æ–°çŠ¶æ€ï¼šç­›é€‰å’Œæ‹¼æ¥éŸ³é¢‘
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨ç­›é€‰å’Œæ‹¼æ¥è¯´è¯äººéŸ³é¢‘...",
            "progress": 50
        }

        # 6. ç­›é€‰ã€æ’åºã€æ‹¼æ¥éŸ³é¢‘
        audio_processor = SpeakerAudioProcessor(target_duration=10.0, silence_duration=1.0)
        # ä½¿ç”¨audio_dirå¯¹åº”çš„referencesç›®å½•
        reference_output_dir = os.path.join(audio_dir, "references")
        speaker_audio_results = audio_processor.process_all_speakers(
            scored_segments, reference_output_dir
        )

        # æ›´æ–°çŠ¶æ€ï¼šæå–å­—å¹•æ–‡æœ¬
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æå–å‚è€ƒå­—å¹•æ–‡æœ¬...",
            "progress": 65
        }

        # 7. æå–å­—å¹•æ–‡æœ¬
        text_extractor = SubtitleTextExtractor()
        speaker_segments_for_text = {
            speaker_id: selected_segments
            for speaker_id, (_, selected_segments) in speaker_audio_results.items()
        }
        speaker_texts = text_extractor.process_all_speakers(
            speaker_segments_for_text, source_subtitle_path
        )

        # 8. ä¿å­˜è¯´è¯äººå‚è€ƒæ•°æ®
        speaker_references = {}
        for speaker_id in speaker_audio_results.keys():
            audio_path, _ = speaker_audio_results[speaker_id]
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            audio_path = os.path.abspath(audio_path)
            reference_text = speaker_texts.get(speaker_id, "")
            speaker_name = speaker_name_mapping.get(speaker_id, f"è¯´è¯äºº{speaker_id}")
            gender = gender_dict.get(speaker_id, "unknown")

            speaker_references[speaker_id] = {
                "reference_audio": audio_path,
                "reference_text": reference_text,
                "target_language": target_language,
                "speaker_name": speaker_name,
                "gender": gender
            }

        # ä¿å­˜åˆ°çŠ¶æ€ä¸­
        voice_cloning_status[task_id]["speaker_references"] = speaker_references

        # ========== å¼€å§‹è¯­éŸ³å…‹éš†æµç¨‹ï¼ˆæ‰¹é‡å¤„ç†ï¼‰ ==========
        await asyncio.sleep(1)  # ç»™å‰ç«¯æ—¶é—´è½®è¯¢

        # ä½¿ç”¨æ–°çš„ç®€å•æ‰¹é‡å…‹éš†å™¨ï¼ˆå‚ç…§ batch_inference.pyï¼‰
        print("[Voice Clone] Using simple batch cloner (based on batch_inference.py)")
        from fish_simple_cloner import SimpleFishCloner
        batch_cloner = SimpleFishCloner()

        # 9. æ‰¹é‡ç¼–ç æ‰€æœ‰è¯´è¯äººçš„å‚è€ƒéŸ³é¢‘
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æ‰¹é‡ç¼–ç è¯´è¯äººå‚è€ƒéŸ³é¢‘...",
            "progress": 70
        }
        await asyncio.sleep(0.5)

        encode_output_dir = os.path.join(audio_dir, "encoded")
        os.makedirs(encode_output_dir, exist_ok=True)

        print(f"\nğŸš€ æ‰¹é‡ç¼–ç  {len(speaker_references)} ä¸ªè¯´è¯äººçš„å‚è€ƒéŸ³é¢‘...")
        speaker_npy_files = batch_cloner.batch_encode_speakers(
            speaker_references,
            encode_output_dir
        )

        # 10. è¯»å–ç›®æ ‡è¯­è¨€å­—å¹•
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨è¯»å–ç›®æ ‡è¯­è¨€å­—å¹•...",
            "progress": 75
        }
        await asyncio.sleep(0.5)

        from srt_parser import SRTParser
        srt_parser = SRTParser()
        target_subtitles = srt_parser.parse_srt(target_subtitle_path)
        source_subtitles = srt_parser.parse_srt(source_subtitle_path)

        # 10.5 éªŒè¯è¯‘æ–‡é•¿åº¦å¹¶æ‰¹é‡é‡æ–°ç¿»è¯‘è¶…é•¿æ–‡æœ¬
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨éªŒè¯è¯‘æ–‡é•¿åº¦...",
            "progress": 76
        }
        await asyncio.sleep(0.5)

        from text_utils import check_translation_length

        # æ£€æŸ¥æ¯å¥è¯‘æ–‡é•¿åº¦
        too_long_items = []
        for idx, (source_sub, target_sub) in enumerate(zip(source_subtitles, target_subtitles)):
            source_text = source_sub["text"]
            target_text = target_sub["text"]

            is_too_long, source_len, target_len, ratio = check_translation_length(
                source_text, target_text, target_language, max_ratio=1.2
            )

            if is_too_long:
                too_long_items.append({
                    "index": idx,
                    "source": source_text,
                    "target": target_text,
                    "source_length": source_len,
                    "target_length": target_len,
                    "ratio": ratio
                })

        # å¦‚æœæœ‰è¶…é•¿è¯‘æ–‡ï¼Œè¿›è¡Œæ‰¹é‡é‡æ–°ç¿»è¯‘
        if too_long_items:
            print(f"\nâš ï¸  å‘ç° {len(too_long_items)} æ¡è¶…é•¿è¯‘æ–‡ï¼Œå‡†å¤‡æ‰¹é‡é‡æ–°ç¿»è¯‘...")

            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": f"æ­£åœ¨æ‰¹é‡é‡æ–°ç¿»è¯‘ {len(too_long_items)} æ¡è¶…é•¿æ–‡æœ¬...",
                "progress": 77
            }
            await asyncio.sleep(0.5)

            # å‡†å¤‡é‡æ–°ç¿»è¯‘ä»»åŠ¡
            import tempfile
            import json
            import subprocess

            retranslate_tasks = []
            for item in too_long_items:
                retranslate_tasks.append({
                    "task_id": f"retrans-{item['index']}",
                    "source": item["source"],
                    "target_language": target_language
                })

            # å†™å…¥é…ç½®æ–‡ä»¶
            config_file = os.path.join(audio_dir, "retranslate_config.json")

            # è·å–æ¨¡å‹è·¯å¾„
            # æ¨¡å‹åœ¨ C:\workspace\ai_editing\models\Qwen3-1.7B
            # ä» backend ç›®å½•å‘ä¸Š 4 çº§åˆ°è¾¾ ai_editing ç›®å½•
            backend_dir = os.path.dirname(os.path.abspath(__file__))  # backend
            localclip_dir = os.path.dirname(backend_dir)  # LocalClip-Editor
            workspace_dir = os.path.dirname(localclip_dir)  # workspace
            ai_editing_dir = os.path.dirname(workspace_dir)  # ai_editing
            model_path = os.path.join(ai_editing_dir, "models", "Qwen3-1.7B")

            retranslate_config = {
                "tasks": retranslate_tasks,
                "model_path": model_path,
                "num_processes": 1  # ä½¿ç”¨å•è¿›ç¨‹ï¼Œé¿å…æ˜¾å­˜å†²çª
            }

            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(retranslate_config, f, ensure_ascii=False, indent=2)

            # è°ƒç”¨æ‰¹é‡é‡æ–°ç¿»è¯‘è„šæœ¬
            # ä½¿ç”¨ qwen_inference conda ç¯å¢ƒ
            qwen_env_python = os.environ.get("QWEN_INFERENCE_PYTHON")
            if not qwen_env_python:
                # é»˜è®¤è·¯å¾„
                import platform
                if platform.system() == "Windows":
                    qwen_env_python = r"C:\Users\7\miniconda3\envs\qwen_inference\python.exe"
                else:
                    qwen_env_python = os.path.expanduser("~/miniconda3/envs/qwen_inference/bin/python")

            batch_retranslate_script = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "batch_retranslate.py"
            )

            print(f"[Retranslate] ä½¿ç”¨ Python: {qwen_env_python}")
            print(f"[Retranslate] è„šæœ¬: {batch_retranslate_script}")
            print(f"[Retranslate] é…ç½®: {config_file}")
            print(f"[Retranslate] æ¨¡å‹è·¯å¾„: {model_path}")

            # æ£€æŸ¥ Python ç¯å¢ƒå’Œæ¨¡å‹æ˜¯å¦å­˜åœ¨
            if not os.path.exists(qwen_env_python):
                print(f"âš ï¸  Qwen Python ç¯å¢ƒä¸å­˜åœ¨: {qwen_env_python}")
                print(f"ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
            elif not os.path.exists(model_path):
                print(f"âš ï¸  æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
                print(f"ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
            else:
                try:
                    print(f"[Retranslate] å¯åŠ¨æ‰¹é‡é‡æ–°ç¿»è¯‘è¿›ç¨‹...")

                    # ä½¿ç”¨ Popenï¼Œä¸æŒ‡å®šç¼–ç ä»¥é¿å… UnicodeDecodeError
                    process = subprocess.Popen(
                        [qwen_env_python, batch_retranslate_script, config_file],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        # ä½¿ç”¨ bytes æ¨¡å¼ï¼Œæ‰‹åŠ¨è§£ç 
                    )

                    # è¯»å–è¾“å‡ºï¼ˆå¸¦è¶…æ—¶ï¼‰
                    try:
                        stdout_bytes, stderr_bytes = process.communicate(timeout=600)
                        returncode = process.returncode

                        # æ‰‹åŠ¨è§£ç ï¼Œä½¿ç”¨ errors='replace' é¿å…è§£ç é”™è¯¯
                        stdout = stdout_bytes.decode('utf-8', errors='replace') if stdout_bytes else ""
                        stderr = stderr_bytes.decode('utf-8', errors='replace') if stderr_bytes else ""

                    except subprocess.TimeoutExpired:
                        process.kill()
                        print("âš ï¸  é‡æ–°ç¿»è¯‘è¶…æ—¶ï¼Œä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
                        stdout, stderr = "", ""
                        returncode = -1

                    # æ‰“å° stderrï¼ˆå¦‚æœæœ‰ï¼Œå¿½ç•¥ç©ºç™½ï¼‰
                    if stderr and stderr.strip():
                        # è¿‡æ»¤æ‰ UnicodeDecodeError ç›¸å…³çš„æ— å…³è­¦å‘Š
                        stderr_lines = stderr.strip().split('\n')
                        filtered_stderr = '\n'.join([line for line in stderr_lines if 'UnicodeDecodeError' not in line and '_readerthread' not in line])
                        if filtered_stderr:
                            print(f"[Retranslate] stderr:\n{filtered_stderr}")

                    if returncode == 0 and stdout:
                        # è§£æè¾“å‡ºä¸­çš„ JSON ç»“æœ
                        output_lines = stdout.strip().split('\n')
                        # æŸ¥æ‰¾æœ€åä¸€ä¸ª JSON å—
                        json_start = -1
                        for i in range(len(output_lines) - 1, -1, -1):
                            if output_lines[i].strip().startswith('['):
                                json_start = i
                                break

                        if json_start >= 0:
                            json_output = '\n'.join(output_lines[json_start:])
                            retranslate_results = json.loads(json_output)

                            print(f"\n[Retranslate] è§£æåˆ° {len(retranslate_results)} æ¡é‡æ–°ç¿»è¯‘ç»“æœ:")
                            print(json.dumps(retranslate_results, ensure_ascii=False, indent=2))

                            # æ›´æ–°ç›®æ ‡å­—å¹•
                            for result_item in retranslate_results:
                                task_id_str = result_item["task_id"]
                                # æå–ç´¢å¼•: "retrans-123" -> 123
                                idx = int(task_id_str.split('-')[1])
                                new_translation = result_item["translation"]

                                old_translation = target_subtitles[idx]["text"]

                                # å¦‚æœæ–°ç¿»è¯‘ä¸ºç©ºï¼Œä¿ç•™æ—§ç¿»è¯‘
                                if not new_translation or new_translation.strip() == "":
                                    print(f"  [æ›´æ–° {idx}] âš ï¸  ç¿»è¯‘ç»“æœä¸ºç©ºï¼Œä¿ç•™åŸè¯‘æ–‡")
                                    print(f"    åŸè¯‘æ–‡: '{old_translation}'")
                                    # ä¸æ›´æ–°ï¼Œä¿æŒåŸæ–‡
                                else:
                                    target_subtitles[idx]["text"] = new_translation
                                    print(f"  [æ›´æ–° {idx}]")
                                    print(f"    æ—§: '{old_translation}'")
                                    print(f"    æ–°: '{new_translation}'")

                            print(f"\nâœ… æˆåŠŸé‡æ–°ç¿»è¯‘ {len(retranslate_results)} æ¡æ–‡æœ¬")

                            # ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°æ–‡ä»¶
                            print(f"\n[Retranslate] ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°: {target_subtitle_path}")
                            srt_parser.save_srt(target_subtitles, target_subtitle_path)
                            print(f"âœ… å­—å¹•æ–‡ä»¶å·²æ›´æ–°")

                            # éªŒè¯ä¿å­˜ï¼šè¯»å–æ–‡ä»¶æŸ¥çœ‹æ˜¯å¦çœŸçš„æ›´æ–°äº†
                            print(f"\n[Retranslate] éªŒè¯ä¿å­˜ç»“æœ...")
                            print(f"[Retranslate] è¯»å–æ–‡ä»¶: {target_subtitle_path}")
                            saved_subtitles = srt_parser.parse_srt(target_subtitle_path)
                            print(f"[Retranslate] æ–‡ä»¶ä¸­å…±æœ‰ {len(saved_subtitles)} æ¡å­—å¹•")
                            for result_item in retranslate_results:
                                idx = int(result_item["task_id"].split('-')[1])
                                if idx < len(saved_subtitles):
                                    saved_text = saved_subtitles[idx]["text"]
                                    expected_text = result_item["translation"]
                                    match = "âœ…" if saved_text == expected_text else "âŒ"
                                    print(f"  {match} [{idx}]")
                                    print(f"      æœŸå¾…: '{expected_text}'")
                                    print(f"      æ–‡ä»¶: '{saved_text}'")
                                else:
                                    print(f"  âŒ [{idx}] ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼ˆæ–‡ä»¶åªæœ‰ {len(saved_subtitles)} æ¡ï¼‰")
                        else:
                            print("âš ï¸  æœªæ‰¾åˆ°é‡æ–°ç¿»è¯‘ç»“æœï¼Œä½¿ç”¨åŸè¯‘æ–‡")
                    elif returncode != 0:
                        print(f"âš ï¸  é‡æ–°ç¿»è¯‘å¤±è´¥ (è¿”å›ç : {returncode})")
                        if stdout and stdout.strip():
                            print(f"[Retranslate] stdout:\n{stdout[:500]}")  # åªæ‰“å°å‰500å­—ç¬¦
                        print("ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
                    else:
                        print("âš ï¸  é‡æ–°ç¿»è¯‘è¿”å›æˆåŠŸä½†æ²¡æœ‰è¾“å‡ºï¼Œä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")

                except Exception as e:
                    print(f"âš ï¸  é‡æ–°ç¿»è¯‘å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    print("ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")

        # 11. å‡†å¤‡æ‰¹é‡ç”Ÿæˆä»»åŠ¡
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æ‰¹é‡ç”Ÿæˆå…‹éš†è¯­éŸ³...",
            "progress": 80
        }
        await asyncio.sleep(0.5)

        cloned_audio_dir = os.path.join("exports", f"cloned_{task_id}")
        os.makedirs(cloned_audio_dir, exist_ok=True)

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        cloned_results = []

        print(f"\n[DEBUG] å‡†å¤‡ä»»åŠ¡åˆ—è¡¨ï¼Œtarget_subtitles ä¸­å‰3æ¡æ–‡æœ¬:")
        for i in range(min(3, len(target_subtitles))):
            print(f"  [{i}] {target_subtitles[i]['text']}")

        for idx, (speaker_id, target_sub) in enumerate(zip(speaker_labels, target_subtitles)):
            target_text = target_sub["text"]

            if speaker_id is None or speaker_id not in speaker_npy_files:
                # æ²¡æœ‰åˆ†é…è¯´è¯äººæˆ–è¯´è¯äººç¼–ç å¤±è´¥çš„ç‰‡æ®µï¼Œè®°å½•ä½†ä¸ç”Ÿæˆ
                cloned_results.append({
                    "index": idx,
                    "speaker_id": speaker_id,
                    "target_text": target_text,
                    "cloned_audio_path": None
                })
            else:
                # æ·»åŠ åˆ°æ‰¹é‡ç”Ÿæˆä»»åŠ¡
                tasks.append({
                    "speaker_id": speaker_id,
                    "target_text": target_text,
                    "segment_index": idx
                })

        # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è¯­éŸ³
        print(f"\nğŸš€ æ‰¹é‡ç”Ÿæˆ {len(tasks)} ä¸ªè¯­éŸ³ç‰‡æ®µ...")
        # å°†ç”Ÿæˆè„šæœ¬ä¿å­˜åˆ°audio_dirä¸‹çš„scriptsç›®å½•ï¼Œé¿å…è§¦å‘uvicorn reload
        script_dir = os.path.join(audio_dir, "scripts")
        generated_audio_files = batch_cloner.batch_generate_audio(
            tasks,
            speaker_npy_files,
            speaker_references,
            cloned_audio_dir,
            script_dir=script_dir
        )

        # è°ƒè¯•ï¼šæ‰“å°ç”Ÿæˆç»“æœ
        print(f"\n[DEBUG] generated_audio_files ç±»å‹: {type(generated_audio_files)}")
        print(f"[DEBUG] generated_audio_files é”®ç¤ºä¾‹ (å‰3ä¸ª): {list(generated_audio_files.keys())[:3]}")
        print(f"[DEBUG] generated_audio_files ç¤ºä¾‹:")
        for key in list(generated_audio_files.keys())[:3]:
            print(f"  key={key} (type={type(key)}), value={generated_audio_files[key]}")

        # æ›´æ–°ç»“æœï¼Œæ·»åŠ ç”ŸæˆæˆåŠŸçš„éŸ³é¢‘è·¯å¾„
        for task in tasks:
            segment_index = task["segment_index"]
            if segment_index in generated_audio_files:
                # ç”ŸæˆAPIè·¯å¾„ï¼ˆä¸ fish_simple_cloner.py ä¸­çš„æ–‡ä»¶åæ ¼å¼ä¸€è‡´ï¼‰
                audio_filename = f"segment_{segment_index}.wav"
                api_path = f"/cloned-audio/{task_id}/{audio_filename}"

                cloned_results.append({
                    "index": segment_index,
                    "speaker_id": task["speaker_id"],
                    "target_text": task["target_text"],
                    "cloned_audio_path": api_path
                })
            else:
                cloned_results.append({
                    "index": segment_index,
                    "speaker_id": task["speaker_id"],
                    "target_text": task["target_text"],
                    "cloned_audio_path": None,
                    "error": "ç”Ÿæˆå¤±è´¥"
                })

        # æŒ‰ç´¢å¼•æ’åºç»“æœ
        cloned_results.sort(key=lambda x: x["index"])

        # è°ƒè¯•ï¼šæ‰“å°å‰å‡ ä¸ªç»“æœï¼ˆåŒ…å« target_textï¼‰
        print(f"\n[DEBUG] cloned_results ç¤ºä¾‹ (å‰3ä¸ª):")
        for i, result in enumerate(cloned_results[:3]):
            print(f"  [{i}] index={result['index']}, speaker_id={result['speaker_id']}")
            print(f"      target_text='{result['target_text']}'")
            print(f"      cloned_audio_path={result.get('cloned_audio_path', 'None')}")

        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        def format_duration(seconds):
            """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´å­—ç¬¦ä¸²"""
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(total_duration)

        # æ›´æ–°çŠ¶æ€ï¼šå®Œæˆ
        voice_cloning_status[task_id] = {
            "status": "completed",
            "message": f"è¯­éŸ³å…‹éš†å®Œæˆ (è€—æ—¶: {duration_str})",
            "progress": 100,
            "speaker_references": speaker_references,
            "unique_speakers": len(speaker_references),
            "speaker_name_mapping": speaker_name_mapping,
            "gender_dict": gender_dict,
            "cloned_results": cloned_results,
            "cloned_audio_dir": cloned_audio_dir,
            "total_duration": total_duration,  # åŸå§‹ç§’æ•°
            "duration_str": duration_str  # æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        }

        print(f"\nè¯­éŸ³å…‹éš†å‡†å¤‡å®Œæˆï¼")
        print(f"è¯†åˆ«åˆ° {len(speaker_references)} ä¸ªè¯´è¯äºº")
        for speaker_id, ref_data in speaker_references.items():
            print(f"\n{ref_data['speaker_name']} (ID: {speaker_id}, æ€§åˆ«: {ref_data['gender']}):")
            print(f"  å‚è€ƒéŸ³é¢‘: {ref_data['reference_audio']}")
            print(f"  å‚è€ƒæ–‡æœ¬: {ref_data['reference_text'][:100]}...")

        print(f"\nâœ… è¯­éŸ³å…‹éš†ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")
        return  # æ˜¾å¼è¿”å›ï¼Œç¡®ä¿å‡½æ•°æ­£å¸¸ç»“æŸ

    except Exception as e:
        # è®¡ç®—å¤±è´¥æ—¶çš„è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        import traceback
        error_detail = traceback.format_exc()
        print(f"è¯­éŸ³å…‹éš†å¤„ç†å¤±è´¥: {error_detail}")
        print(f"â±ï¸  å¤±è´¥å‰è€—æ—¶: {total_duration:.1f}ç§’")

        voice_cloning_status[task_id] = {
            "status": "failed",
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "progress": 0,
            "total_duration": total_duration,
            "duration_str": f"{total_duration:.1f}ç§’"
        }


@app.get("/voice-cloning/status/{task_id}")
async def get_voice_cloning_status(task_id: str):
    """è·å–è¯­éŸ³å…‹éš†å¤„ç†çŠ¶æ€"""
    if task_id not in voice_cloning_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return voice_cloning_status[task_id]


@app.get("/cloned-audio/{task_id}/{filename}")
async def serve_cloned_audio(task_id: str, filename: str, request: Request):
    """æä¾›å…‹éš†éŸ³é¢‘æ–‡ä»¶çš„æµå¼ä¼ è¾“ï¼Œæ”¯æŒ HTTP Range è¯·æ±‚"""
    file_path = EXPORTS_DIR / f"cloned_{task_id}" / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")

    file_size = file_path.stat().st_size
    range_header = request.headers.get("range")

    # å¦‚æœæ²¡æœ‰ Range è¯·æ±‚å¤´ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
    if not range_header:
        return FileResponse(
            file_path,
            media_type="audio/wav",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
            }
        )

    # è§£æ Range è¯·æ±‚å¤´
    range_match = re.match(r"bytes=(\d+)-(\d*)", range_header)
    if not range_match:
        raise HTTPException(status_code=416, detail="Invalid range")

    start = int(range_match.group(1))
    end = int(range_match.group(2)) if range_match.group(2) else file_size - 1

    # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
    if start >= file_size or end >= file_size or start > end:
        raise HTTPException(status_code=416, detail="Range not satisfiable")

    chunk_size = end - start + 1

    # è¯»å–æ–‡ä»¶çš„æŒ‡å®šèŒƒå›´
    def iterfile():
        with open(file_path, "rb") as f:
            f.seek(start)
            remaining = chunk_size
            while remaining > 0:
                chunk = f.read(min(8192, remaining))
                if not chunk:
                    break
                remaining -= len(chunk)
                yield chunk

    # è¿”å› 206 Partial Content
    return StreamingResponse(
        iterfile(),
        status_code=206,
        media_type="audio/wav",
        headers={
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Accept-Ranges": "bytes",
            "Content-Length": str(chunk_size),
        }
    )


class RegenerateSegmentRequest(BaseModel):
    task_id: str
    segment_index: int
    new_speaker_id: int


@app.post("/voice-cloning/regenerate-segment")
async def regenerate_segment(request: RegenerateSegmentRequest):
    """é‡æ–°ç”Ÿæˆå•ä¸ªå­—å¹•ç‰‡æ®µçš„å…‹éš†è¯­éŸ³ï¼ˆä½¿ç”¨ä¸åŒçš„è¯´è¯äººéŸ³è‰²ï¼‰"""
    try:
        task_id = request.task_id
        segment_index = request.segment_index
        new_speaker_id = request.new_speaker_id

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if task_id not in voice_cloning_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        status = voice_cloning_status[task_id]
        if status["status"] != "completed":
            raise HTTPException(status_code=400, detail="è¯­éŸ³å…‹éš†ä»»åŠ¡å°šæœªå®Œæˆ")

        # è·å–å…‹éš†ç»“æœ
        cloned_results = status.get("cloned_results", [])
        if segment_index < 0 or segment_index >= len(cloned_results):
            raise HTTPException(status_code=400, detail="ç‰‡æ®µç´¢å¼•æ— æ•ˆ")

        # è·å–è¯´è¯äººå‚è€ƒæ•°æ®
        speaker_references = status.get("speaker_references", {})
        if new_speaker_id not in speaker_references:
            raise HTTPException(status_code=400, detail=f"è¯´è¯äºº {new_speaker_id} ä¸å­˜åœ¨")

        # è·å–ç›®æ ‡æ–‡æœ¬
        segment_data = cloned_results[segment_index]
        target_text = segment_data["target_text"]

        # æŸ¥æ‰¾éŸ³é¢‘æå–ç¼“å­˜ä»¥è·å–audio_dir
        audio_dir = None
        print(f"[DEBUG] æŸ¥æ‰¾ task_id={task_id} çš„ audio_dir...")
        print(f"[DEBUG] audio_extraction_cache ä¸­çš„ keys: {list(audio_extraction_cache.keys())}")

        for cache_key, cache_data in audio_extraction_cache.items():
            cache_task_id = cache_data.get("task_id")
            cache_audio_dir = cache_data.get("audio_dir", "")
            print(f"[DEBUG] æ£€æŸ¥ cache_key={cache_key}, task_id={cache_task_id}, audio_dir={cache_audio_dir}")

            if cache_task_id == task_id or task_id in cache_audio_dir:
                audio_dir = cache_data["audio_dir"]
                print(f"[DEBUG] âœ… æ‰¾åˆ°åŒ¹é…çš„ audio_dir: {audio_dir}")
                break

        if not audio_dir:
            # å¦‚æœæ‰¾ä¸åˆ°ç¼“å­˜ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„
            audio_dir = f"audio_segments/{task_id}"
            print(f"[DEBUG] âš ï¸  æœªæ‰¾åˆ°ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {audio_dir}")

            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(audio_dir):
                print(f"[DEBUG] âŒ é»˜è®¤è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨ backend ç›®å½•ä¸‹æŸ¥æ‰¾")
                backend_audio_dir = os.path.join("backend", audio_dir)
                if os.path.exists(backend_audio_dir):
                    audio_dir = backend_audio_dir
                    print(f"[DEBUG] âœ… æ‰¾åˆ°: {audio_dir}")
                else:
                    print(f"[DEBUG] âŒ backend ç›®å½•ä¸‹ä¹Ÿä¸å­˜åœ¨")

        from fish_voice_cloner import FishVoiceCloner
        cloner = FishVoiceCloner()

        # é¦–å…ˆåœ¨æ‰€æœ‰å¯èƒ½çš„ç›®å½•ä¸­æŸ¥æ‰¾å·²ç¼–ç çš„æ–‡ä»¶
        print(f"[æŸ¥æ‰¾ç¼–ç ] æŸ¥æ‰¾ speaker_{new_speaker_id} çš„ç¼–ç æ–‡ä»¶...")

        possible_dirs = [
            "audio_segments",
            "../audio_segments",
            "backend/audio_segments",
        ]

        found_npy = None
        for base_dir in possible_dirs:
            if not os.path.exists(base_dir):
                continue

            # éå†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶å¤¹
            for task_folder in os.listdir(base_dir):
                task_path = os.path.join(base_dir, task_folder)
                if not os.path.isdir(task_path):
                    continue

                # æ£€æŸ¥è¯¥ä»»åŠ¡æ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰æ­¤è¯´è¯äººçš„ç¼–ç 
                encoded_path = os.path.join(task_path, f"speaker_{new_speaker_id}_encoded", "fake.npy")
                if os.path.exists(encoded_path):
                    found_npy = encoded_path
                    print(f"[æŸ¥æ‰¾ç¼–ç ] âœ… æ‰¾åˆ°ç¼–ç æ–‡ä»¶: {encoded_path}")
                    break

            if found_npy:
                break

        # å¦‚æœæ‰¾åˆ°äº†ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä¸å¤åˆ¶ï¼ŒèŠ‚çœæ—¶é—´ï¼‰
        if found_npy:
            fake_npy_path = found_npy
            print(f"[ç¼–ç ] âœ… ä½¿ç”¨å·²å­˜åœ¨çš„ç¼–ç æ–‡ä»¶: {fake_npy_path}")
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œéœ€è¦é‡æ–°ç¼–ç 
            print(f"[æŸ¥æ‰¾ç¼–ç ] âŒ æœªæ‰¾åˆ°å·²æœ‰ç¼–ç ï¼Œéœ€è¦é‡æ–°ç¼–ç ...")

            # åˆ›å»ºç¼–ç ç›®å½•
            speaker_encoded_dir = os.path.join(audio_dir, f"speaker_{new_speaker_id}_encoded")
            os.makedirs(speaker_encoded_dir, exist_ok=True)

            ref_data = speaker_references[new_speaker_id]
            reference_audio_path = ref_data["reference_audio"]
            print(f"[ç¼–ç ] å‚è€ƒéŸ³é¢‘: {reference_audio_path}")
            print(f"[ç¼–ç ] è¾“å‡ºç›®å½•: {speaker_encoded_dir}")

            fake_npy_path = cloner.encode_reference_audio(
                reference_audio_path,
                speaker_encoded_dir
            )

        # è·å–å‚è€ƒæ–‡æœ¬
        ref_text = speaker_references[new_speaker_id]["reference_text"]

        # ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶åæ ¼å¼ï¼‰
        cloned_audio_dir = status.get("cloned_audio_dir", os.path.join("exports", f"cloned_{task_id}"))
        audio_filename = f"segment_{segment_index}.wav"  # ç»Ÿä¸€ä½¿ç”¨ç®€å•æ ¼å¼
        output_audio = os.path.join(cloned_audio_dir, audio_filename)
        work_dir = os.path.join(audio_dir, f"regen_{segment_index}_{new_speaker_id}")
        os.makedirs(work_dir, exist_ok=True)

        print(f"é‡æ–°ç”Ÿæˆç‰‡æ®µ {segment_index}: æ–°è¯´è¯äºº {new_speaker_id}, æ–‡æœ¬: {target_text[:30]}...")

        # æ­¥éª¤2: ç”Ÿæˆè¯­ä¹‰token
        codes_path = cloner.generate_semantic_tokens(
            target_text=target_text,
            ref_text=ref_text,
            fake_npy_path=fake_npy_path,
            output_dir=work_dir
        )

        # æ­¥éª¤3: è§£ç ä¸ºéŸ³é¢‘
        cloner.decode_to_audio(codes_path, output_audio)

        # ç”ŸæˆAPIè·¯å¾„
        api_path = f"/cloned-audio/{task_id}/{audio_filename}"

        # æ›´æ–°å…‹éš†ç»“æœ
        cloned_results[segment_index]["speaker_id"] = new_speaker_id
        cloned_results[segment_index]["cloned_audio_path"] = api_path
        voice_cloning_status[task_id]["cloned_results"] = cloned_results

        return {
            "success": True,
            "segment_index": segment_index,
            "new_speaker_id": new_speaker_id,
            "cloned_audio_path": api_path,
            "target_text": target_text
        }

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"é‡æ–°ç”Ÿæˆç‰‡æ®µå¤±è´¥: {error_detail}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/export")
async def export_video(
    video_filename: str,
    subtitle_filename: Optional[str] = None,
    export_hard_subtitles: bool = False
):
    try:
        video_path = UPLOADS_DIR / video_filename
        
        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶å
        export_filename = f"export_{uuid.uuid4()}.mp4"
        export_path = EXPORTS_DIR / export_filename
        
        # æ‰§è¡Œå¯¼å‡º
        result = video_processor.export_video(
            str(video_path),
            str(export_path),
            subtitle_filename,
            export_hard_subtitles
        )
        
        return {
            "export_filename": export_filename,
            "success": True,
            "message": "è§†é¢‘å¯¼å‡ºæˆåŠŸ",
            "details": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)