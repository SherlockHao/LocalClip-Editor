# -*- coding: utf-8 -*-
# è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨torch dynamoï¼ˆåœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰ï¼‰
import os
os.environ["TORCH_DYNAMO_DISABLE"] = "1"

# åŠ è½½ .env é…ç½®æ–‡ä»¶
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶
project_root = Path(__file__).parent.parent
dotenv_path = project_root / '.env'
if dotenv_path.exists():
    load_dotenv(dotenv_path)
    print(f"[OK] å·²åŠ è½½ç¯å¢ƒé…ç½®: {dotenv_path}")
else:
    print(f"[WARNING] æœªæ‰¾åˆ° .env æ–‡ä»¶: {dotenv_path}")

from fastapi import FastAPI, File, UploadFile, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse, FileResponse
import uuid
from pathlib import Path
from typing import Optional, List, Dict
import json
import re
import time

from video_processor import VideoProcessor
from srt_parser import SRTParser

# è¯­è¨€ä»£ç åˆ°ä¸­æ–‡åç§°çš„æ˜ å°„
def get_language_name(language_code: str) -> str:
    """
    å°†è¯­è¨€ä»£ç è½¬æ¢ä¸ºä¸­æ–‡åç§°ï¼ˆç”¨äºLLM promptï¼‰

    Args:
        language_code: è¯­è¨€ä»£ç  (en, ko, ja ç­‰)

    Returns:
        str: è¯­è¨€çš„ä¸­æ–‡åç§°
    """
    language_map = {
        'en': 'è‹±è¯­',
        'ko': 'éŸ©è¯­',
        'ja': 'æ—¥è¯­',
        'fr': 'æ³•è¯­',
        'de': 'å¾·è¯­',
        'es': 'è¥¿ç­ç‰™è¯­'
    }
    return language_map.get(language_code.lower(), language_code)

# æ·»åŠ å¯¹è¯´è¯äººè¯†åˆ«åŠŸèƒ½çš„æ”¯æŒ
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥speaker_diarization_processingæ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'speaker_diarization_processing'))
from audio_extraction import AudioExtractor
from embedding_extraction import SpeakerEmbeddingExtractor
from cluster_processor import SpeakerClusterer

app = FastAPI(title="LocalClip Editor API", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”é™åˆ¶ä¸ºå…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¡®ä¿ä¸Šä¼ å’Œå¯¼å‡ºç›®å½•å­˜åœ¨
UPLOADS_DIR = Path("uploads")
EXPORTS_DIR = Path("exports")

UPLOADS_DIR.mkdir(exist_ok=True)
EXPORTS_DIR.mkdir(exist_ok=True)

# è‡ªå®šä¹‰è§†é¢‘è·¯ç”±ï¼Œæ”¯æŒ Range è¯·æ±‚
@app.get("/uploads/{filename}")
async def serve_video(filename: str, request: Request):
    """æä¾›æ”¯æŒ HTTP Range è¯·æ±‚çš„è§†é¢‘æµå¼ä¼ è¾“"""
    file_path = UPLOADS_DIR / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶æœªæ‰¾åˆ°")

    file_size = file_path.stat().st_size
    range_header = request.headers.get("range")

    # å¦‚æœæ²¡æœ‰ Range è¯·æ±‚å¤´ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
    if not range_header:
        return FileResponse(
            file_path,
            media_type="video/mp4",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
            }
        )

    # è§£æ Range è¯·æ±‚å¤´
    range_match = re.match(r"bytes=(\d+)-(\d*)", range_header)
    if not range_match:
        raise HTTPException(status_code=416, detail="Invalid range")

    start = int(range_match.group(1))
    end = int(range_match.group(2)) if range_match.group(2) else file_size - 1

    # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
    if start >= file_size or end >= file_size or start > end:
        raise HTTPException(status_code=416, detail="Range not satisfiable")

    chunk_size = end - start + 1

    # è¯»å–æ–‡ä»¶çš„æŒ‡å®šèŒƒå›´
    def iterfile():
        with open(file_path, "rb") as f:
            f.seek(start)
            remaining = chunk_size
            while remaining > 0:
                chunk = f.read(min(8192, remaining))
                if not chunk:
                    break
                remaining -= len(chunk)
                yield chunk

    # è¿”å› 206 Partial Content
    return StreamingResponse(
        iterfile(),
        status_code=206,
        media_type="video/mp4",
        headers={
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Accept-Ranges": "bytes",
            "Content-Length": str(chunk_size),
        }
    )

# è‡ªå®šä¹‰éŸ³é¢‘è·¯ç”±ï¼Œæ”¯æŒ Range è¯·æ±‚ï¼ˆç”¨äºæ‹¼æ¥éŸ³é¢‘ï¼‰
@app.get("/exports/stitched_{task_id}.wav")
async def serve_stitched_audio(task_id: str, request: Request):
    """æä¾›æ”¯æŒ HTTP Range è¯·æ±‚çš„æ‹¼æ¥éŸ³é¢‘æµå¼ä¼ è¾“"""
    file_path = EXPORTS_DIR / f"stitched_{task_id}.wav"

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")

    file_size = file_path.stat().st_size
    range_header = request.headers.get("range")

    # å¦‚æœæ²¡æœ‰ Range è¯·æ±‚å¤´ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
    if not range_header:
        return FileResponse(
            file_path,
            media_type="audio/wav",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )

    # è§£æ Range è¯·æ±‚å¤´
    range_match = re.match(r"bytes=(\d+)-(\d*)", range_header)
    if not range_match:
        raise HTTPException(status_code=416, detail="Invalid range")

    start = int(range_match.group(1))
    end = int(range_match.group(2)) if range_match.group(2) else file_size - 1

    # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
    if start >= file_size or end >= file_size or start > end:
        raise HTTPException(status_code=416, detail="Range not satisfiable")

    chunk_size = end - start + 1

    # è¯»å–æ–‡ä»¶çš„æŒ‡å®šèŒƒå›´
    def iterfile():
        with open(file_path, "rb") as f:
            f.seek(start)
            remaining = chunk_size
            while remaining > 0:
                chunk = f.read(min(8192, remaining))
                if not chunk:
                    break
                remaining -= len(chunk)
                yield chunk

    # è¿”å› 206 Partial Content
    return StreamingResponse(
        iterfile(),
        status_code=206,
        media_type="audio/wav",
        headers={
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Accept-Ranges": "bytes",
            "Content-Length": str(chunk_size),
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆç”¨äºå…¶ä»–éè§†é¢‘æ–‡ä»¶ï¼‰
# æ³¨æ„ï¼šè§†é¢‘å’Œæ‹¼æ¥éŸ³é¢‘æ–‡ä»¶ä¼šè¢«ä¸Šé¢çš„è·¯ç”±ä¼˜å…ˆå¤„ç†
app.mount("/exports", StaticFiles(directory=EXPORTS_DIR), name="exports")

# åˆå§‹åŒ–å¤„ç†å™¨
video_processor = VideoProcessor()
srt_parser = SRTParser()

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨è¯´è¯äººè¯†åˆ«å¤„ç†çŠ¶æ€
speaker_processing_status = {}

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨è¯­éŸ³å…‹éš†å¤„ç†çŠ¶æ€
voice_cloning_status = {}

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨ç¿»è¯‘å¤„ç†çŠ¶æ€
translation_status = {}

# å…¨å±€ç¼“å­˜ï¼šå­˜å‚¨å·²æå–çš„éŸ³é¢‘ç‰‡æ®µä¿¡æ¯ï¼Œé¿å…é‡å¤æå–
# key: (video_filename, subtitle_filename), value: {"audio_paths": [...], "speaker_labels": [...], "audio_dir": "..."}
audio_extraction_cache = {}

# é»˜è®¤éŸ³è‰²åº“é…ç½®
DEFAULT_VOICES_DIR = Path(__file__).parent / "default_seed"
DEFAULT_VOICES = [
    {
        "id": "voice_1",
        "name": "æ²‰ç¨³ç»…å£«",
        "npy_file": "æ²‰ç¨³ç»…å£«_codes.npy",
        "audio_file": "æ²‰ç¨³ç»…å£«.wav",
        "reference_text": "ä»Šå¤©æ—©æ™¨å¸‚ä¸­å¿ƒçš„ä¸»è¦é“è·¯å› çªå‘äº‹æ•…é€ æˆäº†ä¸¥é‡å µå¡ï¼Œè¯·é©¾é©¶å‘˜æœ‹å‹ä»¬æ³¨æ„ç»•è¡Œå¹¶å¬ä»ç°åœºäº¤è­¦çš„æŒ‡æŒ¥ã€‚"
    },
    {
        "id": "voice_2",
        "name": "æ¸…çˆ½å°‘å¹´",
        "npy_file": "æ¸…çˆ½å°‘å¹´_codes.npy",
        "audio_file": "æ¸…çˆ½å°‘å¹´.wav",
        "reference_text": "ä»Šå¤©æ—©æ™¨å¸‚ä¸­å¿ƒçš„ä¸»è¦é“è·¯å› çªå‘äº‹æ•…é€ æˆäº†ä¸¥é‡å µå¡ï¼Œè¯·é©¾é©¶å‘˜æœ‹å‹ä»¬æ³¨æ„ç»•è¡Œå¹¶å¬ä»ç°åœºäº¤è­¦çš„æŒ‡æŒ¥ã€‚"
    },
    {
        "id": "voice_3",
        "name": "ç”œç¾å¥³å£°",
        "npy_file": "ç”œç¾å¥³å£°_codes.npy",
        "audio_file": "ç”œç¾å¥³å£°.wav",
        "reference_text": "ä»Šå¤©æ—©æ™¨å¸‚ä¸­å¿ƒçš„ä¸»è¦é“è·¯å› çªå‘äº‹æ•…é€ æˆäº†ä¸¥é‡å µå¡ï¼Œè¯·é©¾é©¶å‘˜æœ‹å‹ä»¬æ³¨æ„ç»•è¡Œå¹¶å¬ä»ç°åœºäº¤è­¦çš„æŒ‡æŒ¥ã€‚"
    },
    {
        "id": "voice_4",
        "name": "çŸ¥æ€§å¾¡å§",
        "npy_file": "çŸ¥æ€§å¾¡å§_codes.npy",
        "audio_file": "çŸ¥æ€§å¾¡å§.wav",
        "reference_text": "ä»Šå¤©æ—©æ™¨å¸‚ä¸­å¿ƒçš„ä¸»è¦é“è·¯å› çªå‘äº‹æ•…é€ æˆäº†ä¸¥é‡å µå¡ï¼Œè¯·é©¾é©¶å‘˜æœ‹å‹ä»¬æ³¨æ„ç»•è¡Œå¹¶å¬ä»ç°åœºäº¤è­¦çš„æŒ‡æŒ¥ã€‚"
    }
]

@app.get("/")
async def root():
    return {"message": "LocalClip Editor API"}

@app.post("/upload/video")
async def upload_video(file: UploadFile = File(...)):
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_types = [".mp4", ".mov", ".avi", ".mkv"]
        file_extension = Path(file.filename).suffix.lower()
        
        if file_extension not in allowed_types:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = UPLOADS_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = video_processor.get_video_info(str(file_path))
        
        return {
            "filename": unique_filename,
            "original_name": file.filename,
            "size": os.path.getsize(file_path),
            "video_info": video_info
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/subtitle")
async def upload_subtitle(file: UploadFile = File(...)):
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename.lower().endswith('.srt'):
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒSRTå­—å¹•æ–‡ä»¶")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        unique_filename = f"{uuid.uuid4()}.srt"
        file_path = UPLOADS_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # è§£æSRTæ–‡ä»¶
        subtitles = srt_parser.parse_srt(str(file_path))
        
        return {
            "filename": unique_filename,
            "original_name": file.filename,
            "size": os.path.getsize(file_path),
            "subtitles": subtitles
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/videos")
async def get_videos():
    video_extensions = {".mp4", ".mov", ".avi", ".mkv"}
    videos = []
    
    for file_path in UPLOADS_DIR.iterdir():
        if file_path.suffix.lower() in video_extensions:
            video_info = video_processor.get_video_info(str(file_path))
            videos.append({
                "filename": file_path.name,
                "size": os.path.getsize(file_path),
                "video_info": video_info
            })
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    videos.sort(key=lambda x: UPLOADS_DIR.joinpath(x["filename"]).stat().st_mtime, reverse=True)
    
    return {"videos": videos}

from pydantic import BaseModel

class SpeakerDiarizationRequest(BaseModel):
    video_filename: str
    subtitle_filename: str

@app.post("/speaker-diarization/process")
async def process_speaker_diarization(request: SpeakerDiarizationRequest):
    """å¯åŠ¨è¯´è¯äººè¯†åˆ«å’Œèšç±»å¤„ç†æµç¨‹"""
    try:
        print(f"\n===== æ”¶åˆ°è¯´è¯äººè¯†åˆ«è¯·æ±‚ =====")
        print(f"è§†é¢‘æ–‡ä»¶å: {request.video_filename}")
        print(f"å­—å¹•æ–‡ä»¶å: {request.subtitle_filename}")

        video_path = UPLOADS_DIR / request.video_filename
        subtitle_path = UPLOADS_DIR / request.subtitle_filename

        print(f"æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨...")
        print(f"è§†é¢‘è·¯å¾„: {video_path}, å­˜åœ¨: {video_path.exists()}")
        print(f"å­—å¹•è·¯å¾„: {subtitle_path}, å­˜åœ¨: {subtitle_path.exists()}")

        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not subtitle_path.exists():
            raise HTTPException(status_code=404, detail="å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")

        # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        print(f"ç”Ÿæˆä»»åŠ¡ID: {task_id}")

        # è®¾ç½®åˆå§‹å¤„ç†çŠ¶æ€
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "ä»»åŠ¡å¯åŠ¨ä¸­...",
            "progress": 0
        }
        print(f"è®¾ç½®åˆå§‹çŠ¶æ€: {speaker_processing_status[task_id]}")

        # åœ¨åå°æ‰§è¡Œå¤„ç†
        import asyncio
        print(f"åˆ›å»ºåå°ä»»åŠ¡...")
        task = asyncio.create_task(run_speaker_diarization_process(task_id, str(video_path), str(subtitle_path)))

        # æ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒ
        def handle_task_exception(t):
            try:
                t.result()
            except Exception as e:
                import traceback
                print(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {traceback.format_exc()}")

        task.add_done_callback(handle_task_exception)
        print(f"åå°ä»»åŠ¡å·²åˆ›å»º")

        return {
            "task_id": task_id,
            "message": "è¯´è¯äººè¯†åˆ«ä»»åŠ¡å·²å¯åŠ¨",
            "status": "processing"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def run_speaker_diarization_process(task_id: str, video_path: str, subtitle_path: str):
    """åå°æ‰§è¡Œè¯´è¯äººè¯†åˆ«å’Œèšç±»å¤„ç†"""
    import time
    start_time = time.time()

    try:
        import asyncio

        print(f"\n========== å¼€å§‹æ‰§è¡Œè¯´è¯äººè¯†åˆ«ä»»åŠ¡: {task_id} ==========")
        print(f"è§†é¢‘è·¯å¾„: {video_path}")
        print(f"å­—å¹•è·¯å¾„: {subtitle_path}")

        # ç­‰å¾…2ç§’ï¼Œç¡®ä¿å‰ç«¯å¼€å§‹è½®è¯¢
        await asyncio.sleep(2)

        # ä»»åŠ¡1ï¼šéŸ³é¢‘åˆ‡åˆ† (0-25%)
        print(f"[ä»»åŠ¡1] æ›´æ–°çŠ¶æ€: éŸ³é¢‘åˆ‡åˆ†ä¸­... (5%)")
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "éŸ³é¢‘åˆ‡åˆ†ä¸­...",
            "progress": 5
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’ï¼Œè®©å‰ç«¯çœ‹åˆ°è¿™ä¸ªçŠ¶æ€

        # æå–éŸ³é¢‘ç‰‡æ®µ
        audio_dir = os.path.join("..", "audio_segments", task_id)
        extractor = AudioExtractor(cache_dir=audio_dir)
        audio_paths = extractor.extract_audio_segments(video_path, subtitle_path)

        # ä»»åŠ¡2ï¼šè¯´è¯äººè¯†åˆ« (25-60%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "è¯´è¯äººç‰¹å¾æå–ä¸­...",
            "progress": 30
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æå–åµŒå…¥
        embedding_extractor = SpeakerEmbeddingExtractor(offline_mode=True)
        embeddings = embedding_extractor.extract_embeddings(audio_paths)

        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "è¯´è¯äººèšç±»åˆ†æä¸­...",
            "progress": 55
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # èšç±»è¯†åˆ«è¯´è¯äºº
        clusterer = SpeakerClusterer()
        speaker_labels = clusterer.cluster_embeddings(embeddings)

        # ä»»åŠ¡3ï¼šMOSéŸ³é¢‘è´¨é‡è¯„åˆ† (60-80%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "éŸ³é¢‘è´¨é‡è¯„ä¼°ä¸­...",
            "progress": 65
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æŒ‰è¯´è¯äººåˆ†ç»„éŸ³é¢‘
        speaker_segments = {}
        for audio_path, speaker_id in zip(audio_paths, speaker_labels):
            if speaker_id is not None:
                if speaker_id not in speaker_segments:
                    speaker_segments[speaker_id] = []
                speaker_segments[speaker_id].append(audio_path)

        # è®¡ç®—MOSåˆ†æ•°ï¼ˆä½¿ç”¨ NISQAï¼‰
        from nisqa_scorer import NISQAScorer
        mos_scorer = NISQAScorer()
        scored_segments = mos_scorer.score_speaker_audios(audio_dir, speaker_segments)

        print(f"å·²å®ŒæˆMOSè¯„åˆ†ï¼ˆNISQAï¼‰ï¼Œå…± {len(scored_segments)} ä¸ªè¯´è¯äºº")

        # ä»»åŠ¡4ï¼šæ€§åˆ«è¯†åˆ« (80-100%)
        speaker_processing_status[task_id] = {
            "status": "processing",
            "message": "æ€§åˆ«è¯†åˆ«åˆ†æä¸­...",
            "progress": 85
        }
        await asyncio.sleep(1.5)  # å»¶è¿Ÿ1.5ç§’

        # æ€§åˆ«è¯†åˆ«
        from gender_classifier import GenderClassifier, rename_speakers_by_gender
        gender_classifier = GenderClassifier()
        gender_dict = gender_classifier.classify_speakers(scored_segments, min_duration=2.0)

        # æ ¹æ®æ€§åˆ«å’Œå‡ºç°æ¬¡æ•°é‡æ–°å‘½åè¯´è¯äºº
        print(f"\næ ¹æ®æ€§åˆ«å’Œå‡ºç°æ¬¡æ•°é‡æ–°å‘½åè¯´è¯äºº...")
        speaker_name_mapping, gender_stats = rename_speakers_by_gender(speaker_labels, gender_dict)

        print(f"\næ€§åˆ«ç»Ÿè®¡: ç”·æ€§ {gender_stats['male']} äºº, å¥³æ€§ {gender_stats['female']} äºº")

        # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜ï¼Œä¾›è¯­éŸ³å…‹éš†å¤ç”¨
        video_filename = os.path.basename(video_path)
        subtitle_filename = os.path.basename(subtitle_path)
        cache_key = (video_filename, subtitle_filename)
        audio_extraction_cache[cache_key] = {
            "audio_paths": audio_paths,
            "speaker_labels": speaker_labels,
            "audio_dir": audio_dir,
            "task_id": task_id,
            "scored_segments": scored_segments,  # ä¿å­˜MOSè¯„åˆ†ç»“æœ
            "gender_dict": gender_dict,  # ä¿å­˜æ€§åˆ«è¯†åˆ«ç»“æœ
            "speaker_name_mapping": speaker_name_mapping,  # ä¿å­˜è¯´è¯äººåç§°æ˜ å°„
            "gender_stats": gender_stats  # ä¿å­˜æ€§åˆ«ç»Ÿè®¡
        }
        print(f"å·²ç¼“å­˜éŸ³é¢‘æå–ç»“æœã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«: {cache_key}")

        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        def format_duration(seconds):
            """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´å­—ç¬¦ä¸²"""
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(total_duration)

        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        speaker_processing_status[task_id] = {
            "status": "completed",
            "message": f"å…¨éƒ¨ä»»åŠ¡å·²å®Œæˆ (è€—æ—¶: {duration_str})",
            "progress": 100,
            "speaker_labels": speaker_labels,
            "unique_speakers": clusterer.get_unique_speakers_count(speaker_labels),
            "speaker_name_mapping": speaker_name_mapping,
            "gender_stats": gender_stats,
            "total_duration": total_duration,
            "duration_str": duration_str
        }

        print(f"\nâœ… è¯´è¯äººè¯†åˆ«ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")

    except Exception as e:
        # è®¡ç®—å¤±è´¥æ—¶çš„è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time
        duration_str = f"{total_duration:.1f}ç§’"

        # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        import traceback
        error_detail = traceback.format_exc()
        print(f"\n========== è¯´è¯äººè¯†åˆ«ä»»åŠ¡å¤±è´¥: {task_id} ==========")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"è¯¦ç»†å †æ ˆ:\n{error_detail}")
        print(f"â±ï¸  å¤±è´¥å‰è€—æ—¶: {duration_str}")

        speaker_processing_status[task_id] = {
            "status": "failed",
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "progress": 0,
            "total_duration": total_duration,
            "duration_str": duration_str
        }


@app.get("/speaker-diarization/status/{task_id}")
async def get_speaker_diarization_status(task_id: str):
    """è·å–è¯´è¯äººè¯†åˆ«å¤„ç†çŠ¶æ€"""
    print(f"[çŠ¶æ€æŸ¥è¯¢] task_id: {task_id}")
    if task_id not in speaker_processing_status:
        print(f"[çŠ¶æ€æŸ¥è¯¢] ä»»åŠ¡ä¸å­˜åœ¨")
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    status = speaker_processing_status[task_id]
    print(f"[çŠ¶æ€æŸ¥è¯¢] è¿”å›çŠ¶æ€: {status}")
    return status


class VoiceCloningRequest(BaseModel):
    video_filename: str
    source_subtitle_filename: str
    target_language: str
    target_subtitle_filename: str
    speaker_voice_mapping: Optional[Dict[str, str]] = None  # {speaker_id: voice_id}, voice_idå¯ä»¥æ˜¯"default"æˆ–é»˜è®¤éŸ³è‰²çš„id


@app.post("/voice-cloning/process")
async def process_voice_cloning(request: VoiceCloningRequest):
    """å¯åŠ¨è¯­éŸ³å…‹éš†å¤„ç†æµç¨‹ï¼ˆå½“å‰ä¸ºç©ºå®ç°ï¼‰"""
    try:
        video_path = UPLOADS_DIR / request.video_filename
        source_subtitle_path = UPLOADS_DIR / request.source_subtitle_filename
        target_subtitle_path = UPLOADS_DIR / request.target_subtitle_filename

        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not source_subtitle_path.exists():
            raise HTTPException(status_code=404, detail="æºå­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")
        if not target_subtitle_path.exists():
            raise HTTPException(status_code=404, detail="ç›®æ ‡å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨")

        # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ä»»åŠ¡ID
        task_id = str(uuid.uuid4())

        # è®¾ç½®å¤„ç†çŠ¶æ€
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨å‡†å¤‡è¯­éŸ³å…‹éš†...",
            "progress": 0
        }

        # åœ¨åå°æ‰§è¡Œå¤„ç†
        import asyncio
        task = asyncio.create_task(run_voice_cloning_process(
            task_id,
            str(video_path),
            str(source_subtitle_path),
            request.target_language,
            str(target_subtitle_path),
            request.speaker_voice_mapping
        ))

        # æ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒ
        def handle_task_exception(t):
            try:
                t.result()
            except Exception as e:
                import traceback
                print(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {traceback.format_exc()}")

        task.add_done_callback(handle_task_exception)

        return {
            "task_id": task_id,
            "message": "è¯­éŸ³å…‹éš†ä»»åŠ¡å·²å¯åŠ¨",
            "status": "processing"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def run_voice_cloning_process(
    task_id: str,
    video_path: str,
    source_subtitle_path: str,
    target_language: str,
    target_subtitle_path: str,
    speaker_voice_mapping: Optional[Dict[str, str]] = None
):
    """åå°æ‰§è¡Œè¯­éŸ³å…‹éš†å¤„ç†"""
    import time
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

    # è®¾ç½®é»˜è®¤å€¼
    if speaker_voice_mapping is None:
        speaker_voice_mapping = {}

    try:
        import asyncio
        from nisqa_scorer import NISQAScorer
        from speaker_audio_processor import SpeakerAudioProcessor
        from subtitle_text_extractor import SubtitleTextExtractor

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²æå–çš„éŸ³é¢‘
        video_filename = os.path.basename(video_path)
        subtitle_filename = os.path.basename(source_subtitle_path)
        cache_key = (video_filename, subtitle_filename)

        # é»˜è®¤å€¼
        scored_segments = None
        has_cached_mos = False
        gender_dict = {}
        speaker_name_mapping = {}

        if cache_key in audio_extraction_cache:
            # å¤ç”¨å·²æå–çš„éŸ³é¢‘ã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«
            print(f"å¤ç”¨å·²ç¼“å­˜çš„éŸ³é¢‘æå–ç»“æœã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«: {cache_key}")
            cached_data = audio_extraction_cache[cache_key]
            audio_paths = cached_data["audio_paths"]
            speaker_labels = cached_data["speaker_labels"]
            audio_dir = cached_data["audio_dir"]
            scored_segments = cached_data.get("scored_segments")  # è·å–ç¼“å­˜çš„MOSè¯„åˆ†
            gender_dict = cached_data.get("gender_dict", {})  # è·å–æ€§åˆ«è¯†åˆ«ç»“æœ
            speaker_name_mapping = cached_data.get("speaker_name_mapping", {})  # è·å–è¯´è¯äººåç§°æ˜ å°„
            has_cached_mos = scored_segments is not None

            # æ›´æ–°çŠ¶æ€ï¼šå¤ç”¨å·²æå–çš„éŸ³é¢‘
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨å¤ç”¨å·²æå–çš„éŸ³é¢‘ã€è¯´è¯äººè¯†åˆ«ã€MOSè¯„åˆ†å’Œæ€§åˆ«è¯†åˆ«ç»“æœ...",
                "progress": 3
            }
        else:
            # éœ€è¦é‡æ–°æå–éŸ³é¢‘
            print(f"æœªæ‰¾åˆ°ç¼“å­˜ï¼Œé‡æ–°æå–éŸ³é¢‘: {cache_key}")

            # æ›´æ–°çŠ¶æ€ï¼šæå–éŸ³é¢‘ç‰‡æ®µ
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨æå–éŸ³é¢‘ç‰‡æ®µ...",
                "progress": 2
            }

            # 1. æå–éŸ³é¢‘ç‰‡æ®µ
            audio_dir = os.path.join("..", "audio_segments", task_id)
            extractor = AudioExtractor(cache_dir=audio_dir)
            audio_paths = extractor.extract_audio_segments(video_path, source_subtitle_path)

            # æ›´æ–°çŠ¶æ€ï¼šæå–è¯´è¯äººåµŒå…¥
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨æå–è¯´è¯äººåµŒå…¥...",
                "progress": 4
            }

            # 2. æå–åµŒå…¥
            embedding_extractor = SpeakerEmbeddingExtractor(offline_mode=True)
            embeddings = embedding_extractor.extract_embeddings(audio_paths)

            # æ›´æ–°çŠ¶æ€ï¼šè¯†åˆ«è¯´è¯äºº
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨è¯†åˆ«è¯´è¯äºº...",
                "progress": 7
            }

            # 3. èšç±»è¯†åˆ«è¯´è¯äºº
            clusterer = SpeakerClusterer()
            speaker_labels = clusterer.cluster_embeddings(embeddings)

        # 4. å¦‚æœæ²¡æœ‰ç¼“å­˜çš„MOSè¯„åˆ†ï¼Œåˆ™éœ€è¦è®¡ç®—
        if not has_cached_mos:
            # æŒ‰è¯´è¯äººåˆ†ç»„éŸ³é¢‘
            speaker_segments = {}
            for audio_path, speaker_id in zip(audio_paths, speaker_labels):
                if speaker_id is not None:
                    if speaker_id not in speaker_segments:
                        speaker_segments[speaker_id] = []
                    speaker_segments[speaker_id].append(audio_path)

            # æ›´æ–°çŠ¶æ€ï¼šMOSè¯„åˆ†
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": "æ­£åœ¨å¯¹éŸ³é¢‘ç‰‡æ®µè¿›è¡Œè´¨é‡è¯„åˆ†...",
                "progress": 9
            }

            # 5. MOSæ‰“åˆ†ï¼ˆä½¿ç”¨ NISQAï¼‰
            mos_scorer = NISQAScorer()
            scored_segments = mos_scorer.score_speaker_audios(audio_dir, speaker_segments)
            print(f"å·²å®ŒæˆMOSè¯„åˆ†ï¼ˆNISQAï¼‰")
        else:
            print(f"ä½¿ç”¨ç¼“å­˜çš„MOSè¯„åˆ†ç»“æœ")

        # æ›´æ–°çŠ¶æ€ï¼šç­›é€‰å’Œæ‹¼æ¥éŸ³é¢‘ï¼ˆæ— ç¼“å­˜ï¼š11%ï¼Œæœ‰ç¼“å­˜ï¼š7%ï¼‰
        current_progress = 11 if not has_cached_mos else 7
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨ç­›é€‰å’Œæ‹¼æ¥è¯´è¯äººéŸ³é¢‘...",
            "progress": current_progress
        }

        # 6. ç­›é€‰ã€æ’åºã€æ‹¼æ¥éŸ³é¢‘
        audio_processor = SpeakerAudioProcessor(target_duration=10.0, silence_duration=1.0)
        # ä½¿ç”¨audio_dirå¯¹åº”çš„referencesç›®å½•
        reference_output_dir = os.path.join(audio_dir, "references")
        speaker_audio_results = audio_processor.process_all_speakers(
            scored_segments, reference_output_dir
        )

        # æ›´æ–°çŠ¶æ€ï¼šæå–å­—å¹•æ–‡æœ¬ï¼ˆæ— ç¼“å­˜ï¼š13%ï¼Œæœ‰ç¼“å­˜ï¼š10%ï¼‰
        current_progress = 13 if not has_cached_mos else 10
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æå–å‚è€ƒå­—å¹•æ–‡æœ¬...",
            "progress": current_progress
        }

        # 7. æå–å­—å¹•æ–‡æœ¬
        text_extractor = SubtitleTextExtractor()
        speaker_segments_for_text = {
            speaker_id: selected_segments
            for speaker_id, (_, selected_segments) in speaker_audio_results.items()
        }
        speaker_texts = text_extractor.process_all_speakers(
            speaker_segments_for_text, source_subtitle_path
        )

        # 8. ä¿å­˜è¯´è¯äººå‚è€ƒæ•°æ®
        speaker_references = {}
        for speaker_id in speaker_audio_results.keys():
            audio_path, _ = speaker_audio_results[speaker_id]
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            audio_path = os.path.abspath(audio_path)
            reference_text = speaker_texts.get(speaker_id, "")
            speaker_name = speaker_name_mapping.get(speaker_id, f"è¯´è¯äºº{speaker_id}")
            gender = gender_dict.get(speaker_id, "unknown")

            speaker_references[speaker_id] = {
                "reference_audio": audio_path,
                "reference_text": reference_text,
                "target_language": target_language,
                "speaker_name": speaker_name,
                "gender": gender
            }

        # ä¿å­˜åˆ°çŠ¶æ€ä¸­
        voice_cloning_status[task_id]["speaker_references"] = speaker_references

        # ========== å¼€å§‹è¯­éŸ³å…‹éš†æµç¨‹ï¼ˆæ‰¹é‡å¤„ç†ï¼‰ ==========
        await asyncio.sleep(1)  # ç»™å‰ç«¯æ—¶é—´è½®è¯¢

        # ä½¿ç”¨æ–°çš„ç®€å•æ‰¹é‡å…‹éš†å™¨ï¼ˆå‚ç…§ batch_inference.pyï¼‰
        # ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ä»¥è·å¾—å‡†ç¡®çš„è¿›åº¦ä¿¡æ¯
        print("[Voice Clone] Using simple batch cloner (single-process mode for accurate progress)")
        from fish_simple_cloner import SimpleFishCloner
        batch_cloner = SimpleFishCloner(use_multiprocess=False)

        # 9. æ‰¹é‡ç¼–ç æ‰€æœ‰è¯´è¯äººçš„å‚è€ƒéŸ³é¢‘ï¼ˆæ— ç¼“å­˜ï¼š15%ï¼Œæœ‰ç¼“å­˜ï¼š13%ï¼‰
        current_progress = 15 if not has_cached_mos else 13
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æ‰¹é‡ç¼–ç è¯´è¯äººå‚è€ƒéŸ³é¢‘...",
            "progress": current_progress
        }
        await asyncio.sleep(0.5)

        encode_output_dir = os.path.join(audio_dir, "encoded")
        os.makedirs(encode_output_dir, exist_ok=True)

        # å¤„ç†éŸ³è‰²æ˜ å°„ï¼šä½¿ç”¨é»˜è®¤éŸ³è‰²æˆ–è¯´è¯äººè‡ªå·±çš„éŸ³è‰²ï¼ˆå·²é€šè¿‡å‡½æ•°å‚æ•°ä¼ å…¥ï¼‰
        print(f"\nğŸš€ æ‰¹é‡ç¼–ç  {len(speaker_references)} ä¸ªè¯´è¯äººçš„å‚è€ƒéŸ³é¢‘...")
        print(f"   éŸ³è‰²æ˜ å°„: {speaker_voice_mapping}")

        # åˆ†ç¦»éœ€è¦ç¼–ç çš„è¯´è¯äººå’Œä½¿ç”¨é»˜è®¤éŸ³è‰²çš„è¯´è¯äºº
        speakers_to_encode = {}
        speaker_npy_files = {}

        print(f"\nğŸ“‹ å¤„ç†éŸ³è‰²æ˜ å°„ï¼š")
        for speaker_id, ref_data in speaker_references.items():
            # speaker_idæ˜¯æ•´æ•°ï¼Œéœ€è¦è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ¥æŸ¥æ‰¾æ˜ å°„
            speaker_id_str = str(speaker_id)
            selected_voice = speaker_voice_mapping.get(speaker_id_str, "default")
            print(f"  è¯´è¯äºº {speaker_id}: æ˜ å°„key='{speaker_id_str}', é€‰æ‹©éŸ³è‰²='{selected_voice}'")

            if selected_voice == "default":
                # ä½¿ç”¨è¯´è¯äººè‡ªå·±çš„éŸ³è‰²ï¼Œéœ€è¦ç¼–ç 
                speakers_to_encode[speaker_id] = ref_data
                print(f"    â†’ ä½¿ç”¨åŸéŸ³è‰²ï¼Œéœ€è¦ç¼–ç ")
            else:
                # ä½¿ç”¨é»˜è®¤éŸ³è‰²åº“ä¸­çš„éŸ³è‰²
                default_voice = next((v for v in DEFAULT_VOICES if v["id"] == selected_voice), None)
                if default_voice:
                    npy_path = str(DEFAULT_VOICES_DIR / default_voice["npy_file"])
                    speaker_npy_files[speaker_id] = npy_path
                    print(f"    â†’ ä½¿ç”¨é»˜è®¤éŸ³è‰²: {default_voice['name']}")
                    print(f"    â†’ NPYæ–‡ä»¶: {npy_path}")
                    # æ›´æ–°å‚è€ƒæ–‡æœ¬ä¸ºé»˜è®¤éŸ³è‰²çš„å‚è€ƒæ–‡æœ¬
                    speaker_references[speaker_id]["reference_text"] = default_voice["reference_text"]
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šçš„é»˜è®¤éŸ³è‰²ï¼Œå›é€€åˆ°è¯´è¯äººè‡ªå·±çš„éŸ³è‰²
                    print(f"    âš ï¸ æœªæ‰¾åˆ°éŸ³è‰² {selected_voice}ï¼Œä½¿ç”¨åŸéŸ³è‰²")
                    speakers_to_encode[speaker_id] = ref_data

        # æ‰¹é‡ç¼–ç éœ€è¦ç¼–ç çš„è¯´è¯äºº
        print(f"\nğŸ“Š å¤„ç†ç»“æœï¼š")
        print(f"  ä½¿ç”¨é»˜è®¤éŸ³è‰²: {len(speaker_npy_files)} ä¸ªè¯´è¯äºº")
        print(f"  éœ€è¦ç¼–ç : {len(speakers_to_encode)} ä¸ªè¯´è¯äºº")

        if speakers_to_encode:
            encoded_npy_files = batch_cloner.batch_encode_speakers(
                speakers_to_encode,
                encode_output_dir
            )
            speaker_npy_files.update(encoded_npy_files)
        else:
            print(f"  æ‰€æœ‰è¯´è¯äººéƒ½ä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼Œæ— éœ€ç¼–ç ")

        # 10. è¯»å–ç›®æ ‡è¯­è¨€å­—å¹•ï¼ˆæ— ç¼“å­˜ï¼š18%ï¼Œæœ‰ç¼“å­˜ï¼š17%ï¼‰
        current_progress = 18 if not has_cached_mos else 17
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨è¯»å–ç›®æ ‡è¯­è¨€å­—å¹•...",
            "progress": current_progress
        }
        await asyncio.sleep(0.5)

        from srt_parser import SRTParser
        srt_parser = SRTParser()
        target_subtitles = srt_parser.parse_srt(target_subtitle_path)
        source_subtitles = srt_parser.parse_srt(source_subtitle_path)

        # 10.5 éªŒè¯è¯‘æ–‡é•¿åº¦å¹¶æ‰¹é‡é‡æ–°ç¿»è¯‘è¶…é•¿æ–‡æœ¬ï¼ˆä¿æŒåœ¨åŒä¸€è¿›åº¦ï¼‰
        # current_progress å·²åœ¨ä¸Šä¸€æ­¥è®¾ç½®ï¼Œè¿™é‡Œä¸å†æ›´æ–°è¿›åº¦
        voice_cloning_status[task_id]["message"] = "æ­£åœ¨éªŒè¯è¯‘æ–‡é•¿åº¦..."
        await asyncio.sleep(0.5)

        from text_utils import check_translation_length, contains_chinese_characters

        # æ£€æŸ¥æ¯å¥è¯‘æ–‡é•¿åº¦
        # æ—¥è¯­ã€éŸ©è¯­å› ä¸ºä½¿ç”¨å‡å/è°šæ–‡ï¼Œå­—ç¬¦æ•°ä¼šæ¯”æ±‰å­—å¤šï¼Œæ‰€ä»¥æ”¾å®½é™åˆ¶
        # æ³•è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ç­‰æ¬§æ´²è¯­è¨€ä¹Ÿéœ€è¦é€‚å½“æ”¾å®½ï¼Œå› ä¸ºæ‹‰ä¸å­—æ¯è¡¨è¾¾ç›¸åŒæ„æ€éœ€è¦æ›´å¤šå­—ç¬¦
        target_language_lower = target_language.lower()
        is_japanese = ('æ—¥' in target_language or 'ja' in target_language_lower)
        is_korean = ('éŸ©' in target_language or 'ko' in target_language_lower or 'í•œêµ­' in target_language)
        is_french = ('æ³•' in target_language or 'fr' in target_language_lower or 'franÃ§ais' in target_language_lower)
        is_german = ('å¾·' in target_language or 'de' in target_language_lower or 'deutsch' in target_language_lower)
        is_spanish = ('è¥¿ç­ç‰™' in target_language or 'es' in target_language_lower or 'espaÃ±ol' in target_language_lower or 'spanish' in target_language_lower)

        # ä¸åŒè¯­è¨€ä½¿ç”¨ä¸åŒçš„é•¿åº¦æ¯”ä¾‹é™åˆ¶
        if is_japanese or is_korean:
            max_ratio = 3  # æ—¥è¯­/éŸ©è¯­ï¼šå‡å/è°šæ–‡å­—ç¬¦å¤š
        elif is_french or is_german or is_spanish:
            max_ratio = 1.5  # æ³•è¯­/å¾·è¯­/è¥¿ç­ç‰™è¯­ï¼šæ‹‰ä¸å­—æ¯æ¯”è‹±è¯­ç•¥é•¿
        else:
            max_ratio = 1.2  # è‹±è¯­ç­‰å…¶ä»–è¯­è¨€

        too_long_items = []
        chinese_replacement_items = []

        for idx, (source_sub, target_sub) in enumerate(zip(source_subtitles, target_subtitles)):
            source_text = source_sub["text"]
            target_text = target_sub["text"]

            is_too_long, source_len, target_len, ratio = check_translation_length(
                source_text, target_text, target_language, max_ratio=max_ratio
            )

            # æ±‰å­—æ£€æµ‹è§„åˆ™ï¼šæ‰€æœ‰éä¸­æ–‡è¯­è¨€çš„è¯‘æ–‡éƒ½ä¸åº”åŒ…å«æ±‰å­—
            # è¿™å¯¹äºè¯­éŸ³å…‹éš†éå¸¸é‡è¦ï¼Œå› ä¸ºæ±‰å­—ä¼šå½±å“å‘éŸ³å‡†ç¡®æ€§
            has_chinese = contains_chinese_characters(target_text)

            if is_too_long:
                # å¦‚æœè¿‡é•¿ï¼Œéœ€è¦å®Œå…¨é‡æ–°ç¿»è¯‘
                too_long_items.append({
                    "index": idx,
                    "source": source_text,
                    "target": target_text,
                    "source_length": source_len,
                    "target_length": target_len,
                    "ratio": ratio,
                    "reason": "too_long"
                })
                language_display = target_language if target_language else "ç›®æ ‡è¯­è¨€"
                print(f"  [é•¿åº¦æ£€æŸ¥] ç¬¬ {idx} æ¡ {language_display} è¯‘æ–‡è¿‡é•¿ï¼Œéœ€è¦é‡æ–°ç¿»è¯‘: {target_len}/{source_len} = {ratio:.1f}x")
            elif has_chinese:
                # å¦‚æœåªæ˜¯åŒ…å«ä¸­æ–‡ï¼Œåªéœ€è¦æ›¿æ¢ä¸­æ–‡éƒ¨åˆ†
                chinese_replacement_items.append({
                    "index": idx,
                    "target": target_text
                })
                language_display = target_language if target_language else "ç›®æ ‡è¯­è¨€"
                print(f"  [æ±‰å­—æ£€æŸ¥] ç¬¬ {idx} æ¡ {language_display} è¯‘æ–‡åŒ…å«æ±‰å­—ï¼Œå°†æ›¿æ¢ä¸­æ–‡éƒ¨åˆ†: '{target_text}'")

        # å¦‚æœæœ‰è¶…é•¿è¯‘æ–‡ï¼Œè¿›è¡Œæ‰¹é‡é‡æ–°ç¿»è¯‘
        if too_long_items:
            print(f"\nâš ï¸  å‘ç° {len(too_long_items)} æ¡è¶…é•¿è¯‘æ–‡ï¼Œå‡†å¤‡æ‰¹é‡é‡æ–°ç¿»è¯‘...")

            # æ— ç¼“å­˜ï¼š19%ï¼Œæœ‰ç¼“å­˜ï¼š18%
            current_progress = 19 if not has_cached_mos else 18
            voice_cloning_status[task_id] = {
                "status": "processing",
                "message": f"æ­£åœ¨æ‰¹é‡é‡æ–°ç¿»è¯‘ {len(too_long_items)} æ¡è¶…é•¿æ–‡æœ¬...",
                "progress": current_progress
            }
            await asyncio.sleep(0.5)

            # å‡†å¤‡é‡æ–°ç¿»è¯‘ä»»åŠ¡
            import tempfile
            import json
            import subprocess

            # å°†è¯­è¨€ä»£ç è½¬æ¢ä¸ºä¸­æ–‡åç§°ï¼ˆç”¨äºLLM promptï¼‰
            target_language_name = get_language_name(target_language)

            retranslate_tasks = []
            for item in too_long_items:
                retranslate_tasks.append({
                    "task_id": f"retrans-{item['index']}",
                    "source": item["source"],
                    "target_language": target_language_name
                })

            # å†™å…¥é…ç½®æ–‡ä»¶
            config_file = os.path.join(audio_dir, "retranslate_config.json")

            # ä¸æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œè®© batch_retranslate.py æ ¹æ® GPU æ˜¾å­˜è‡ªåŠ¨é€‰æ‹©
            # ä¼šåœ¨ Qwen3-4B-FP8, Qwen3-4B, Qwen3-1.7B ä¸­é€‰æ‹©
            retranslate_config = {
                "tasks": retranslate_tasks,
                "num_processes": 1  # ä½¿ç”¨å•è¿›ç¨‹ï¼Œé¿å…æ˜¾å­˜å†²çª
            }

            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(retranslate_config, f, ensure_ascii=False, indent=2)

            # è°ƒç”¨æ‰¹é‡é‡æ–°ç¿»è¯‘è„šæœ¬
            # ä½¿ç”¨ ui conda ç¯å¢ƒï¼ˆOllama æ–¹æ¡ˆï¼‰
            ui_env_python = os.environ.get("UI_PYTHON")
            if not ui_env_python:
                # é»˜è®¤è·¯å¾„
                import platform
                if platform.system() == "Windows":
                    ui_env_python = r"C:\Users\7\miniconda3\envs\ui\python.exe"
                else:
                    ui_env_python = os.path.expanduser("~/miniconda3/envs/ui/bin/python")

            batch_retranslate_script = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "batch_retranslate_ollama.py"
            )

            print(f"[Retranslate] ä½¿ç”¨ Python: {ui_env_python}")
            print(f"[Retranslate] è„šæœ¬: {batch_retranslate_script}")
            print(f"[Retranslate] é…ç½®: {config_file}")
            print(f"[Retranslate] æ¨¡å‹: Ollama qwen3:4bï¼ˆå¼‚æ­¥å¹¶å‘ï¼‰")

            # æ£€æŸ¥ Python ç¯å¢ƒæ˜¯å¦å­˜åœ¨
            if not os.path.exists(ui_env_python):
                print(f"âš ï¸  UI Python ç¯å¢ƒä¸å­˜åœ¨: {ui_env_python}")
                print(f"ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
            else:
                try:
                    print(f"[Retranslate] å¯åŠ¨æ‰¹é‡é‡æ–°ç¿»è¯‘è¿›ç¨‹...\n")
                    print(f"[Retranslate] å‘½ä»¤: {ui_env_python} {batch_retranslate_script} {config_file}\n")

                    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œé‡æ–°ç¿»è¯‘subprocessï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                    def run_retranslation_subprocess():
                        """åœ¨çº¿ç¨‹ä¸­è¿è¡Œé‡æ–°ç¿»è¯‘å­è¿›ç¨‹"""
                        import subprocess
                        import time

                        try:
                            process = subprocess.Popen(
                                [ui_env_python, batch_retranslate_script, config_file],
                                stdout=subprocess.PIPE,
                                stderr=subprocess.STDOUT,  # åˆå¹¶ stderr åˆ° stdout
                                text=True,  # æ–‡æœ¬æ¨¡å¼
                                encoding='utf-8',
                                errors='replace',  # å¿½ç•¥è§£ç é”™è¯¯
                                bufsize=1,  # è¡Œç¼“å†²
                                universal_newlines=True
                            )
                            print(f"[Retranslate] è¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {process.pid}\n")
                        except Exception as e:
                            print(f"âŒ å¯åŠ¨è¿›ç¨‹å¤±è´¥: {e}")
                            raise

                        # å®æ—¶è¯»å–è¾“å‡º
                        stdout_lines = []
                        print("[Retranslate] ===== å¼€å§‹å®æ—¶è¾“å‡º =====")

                        try:
                            start_time = time.time()
                            timeout = 600  # 10åˆ†é’Ÿè¶…æ—¶

                            while True:
                                # æ£€æŸ¥è¶…æ—¶
                                if time.time() - start_time > timeout:
                                    process.kill()
                                    print("\nâš ï¸  é‡æ–°ç¿»è¯‘è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
                                    break

                                # è¯»å–ä¸€è¡Œ
                                line = process.stdout.readline()

                                if line:
                                    # å®æ—¶æ‰“å°
                                    print(line, end='', flush=True)
                                    stdout_lines.append(line)
                                else:
                                    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç»“æŸ
                                    if process.poll() is not None:
                                        break
                                    time.sleep(0.1)

                            # è¯»å–å‰©ä½™è¾“å‡º
                            remaining = process.stdout.read()
                            if remaining:
                                print(remaining, end='', flush=True)
                                stdout_lines.append(remaining)

                            returncode = process.wait()
                            stdout = ''.join(stdout_lines)

                        except Exception as e:
                            process.kill()
                            print(f"\nâš ï¸  è¯»å–è¾“å‡ºæ—¶å‡ºé”™: {e}")
                            stdout = ''.join(stdout_lines)
                            returncode = -1

                        print("[Retranslate] ===== å®æ—¶è¾“å‡ºç»“æŸ =====\n")
                        return returncode, stdout

                    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
                    loop = asyncio.get_event_loop()
                    returncode, stdout = await loop.run_in_executor(
                        None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
                        run_retranslation_subprocess
                    )

                    if returncode == 0 and stdout:
                        # è§£æè¾“å‡ºä¸­çš„ JSON ç»“æœ
                        output_lines = stdout.strip().split('\n')
                        # æŸ¥æ‰¾æœ€åä¸€ä¸ª JSON å—
                        json_start = -1
                        for i in range(len(output_lines) - 1, -1, -1):
                            if output_lines[i].strip().startswith('['):
                                json_start = i
                                break

                        if json_start >= 0:
                            json_output = '\n'.join(output_lines[json_start:])
                            retranslate_results = json.loads(json_output)

                            print(f"\n[Retranslate] è§£æåˆ° {len(retranslate_results)} æ¡é‡æ–°ç¿»è¯‘ç»“æœ:")
                            print(json.dumps(retranslate_results, ensure_ascii=False, indent=2))

                            # æ›´æ–°ç›®æ ‡å­—å¹•
                            for result_item in retranslate_results:
                                task_id_str = result_item["task_id"]
                                # æå–ç´¢å¼•: "retrans-123" -> 123
                                idx = int(task_id_str.split('-')[1])
                                new_translation = result_item["translation"]

                                old_translation = target_subtitles[idx]["text"]

                                # å¦‚æœæ–°ç¿»è¯‘ä¸ºç©ºï¼Œä¿ç•™æ—§ç¿»è¯‘
                                if not new_translation or new_translation.strip() == "":
                                    print(f"  [æ›´æ–° {idx}] âš ï¸  ç¿»è¯‘ç»“æœä¸ºç©ºï¼Œä¿ç•™åŸè¯‘æ–‡")
                                    print(f"    åŸè¯‘æ–‡: '{old_translation}'")
                                    # ä¸æ›´æ–°ï¼Œä¿æŒåŸæ–‡
                                else:
                                    target_subtitles[idx]["text"] = new_translation
                                    print(f"  [æ›´æ–° {idx}]")
                                    print(f"    æ—§: '{old_translation}'")
                                    print(f"    æ–°: '{new_translation}'")

                            print(f"\nâœ… æˆåŠŸé‡æ–°ç¿»è¯‘ {len(retranslate_results)} æ¡æ–‡æœ¬")

                            # ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°æ–‡ä»¶
                            print(f"\n[Retranslate] ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°: {target_subtitle_path}")
                            srt_parser.save_srt(target_subtitles, target_subtitle_path)
                            print(f"âœ… å­—å¹•æ–‡ä»¶å·²æ›´æ–°")

                            # éªŒè¯ä¿å­˜ï¼šè¯»å–æ–‡ä»¶æŸ¥çœ‹æ˜¯å¦çœŸçš„æ›´æ–°äº†
                            print(f"\n[Retranslate] éªŒè¯ä¿å­˜ç»“æœ...")
                            print(f"[Retranslate] è¯»å–æ–‡ä»¶: {target_subtitle_path}")
                            saved_subtitles = srt_parser.parse_srt(target_subtitle_path)
                            print(f"[Retranslate] æ–‡ä»¶ä¸­å…±æœ‰ {len(saved_subtitles)} æ¡å­—å¹•")
                            for result_item in retranslate_results:
                                idx = int(result_item["task_id"].split('-')[1])
                                if idx < len(saved_subtitles):
                                    saved_text = saved_subtitles[idx]["text"]
                                    expected_text = result_item["translation"]
                                    match = "âœ…" if saved_text == expected_text else "âŒ"
                                    print(f"  {match} [{idx}]")
                                    print(f"      æœŸå¾…: '{expected_text}'")
                                    print(f"      æ–‡ä»¶: '{saved_text}'")
                                else:
                                    print(f"  âŒ [{idx}] ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼ˆæ–‡ä»¶åªæœ‰ {len(saved_subtitles)} æ¡ï¼‰")
                        else:
                            print("âš ï¸  æœªæ‰¾åˆ°é‡æ–°ç¿»è¯‘ç»“æœï¼Œä½¿ç”¨åŸè¯‘æ–‡")
                    elif returncode != 0:
                        print(f"âš ï¸  é‡æ–°ç¿»è¯‘å¤±è´¥ (è¿”å›ç : {returncode})")
                        if stdout and stdout.strip():
                            print(f"[Retranslate] stdout:\n{stdout[:500]}")  # åªæ‰“å°å‰500å­—ç¬¦
                        print("ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")
                    else:
                        print("âš ï¸  é‡æ–°ç¿»è¯‘è¿”å›æˆåŠŸä½†æ²¡æœ‰è¾“å‡ºï¼Œä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")

                except Exception as e:
                    print(f"âš ï¸  é‡æ–°ç¿»è¯‘å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    print("ä½¿ç”¨åŸè¯‘æ–‡ç»§ç»­...")

        # 10.4. ä¸­æ–‡æ›¿æ¢ï¼šå°†è¯‘æ–‡ä¸­çš„ä¸­æ–‡éƒ¨åˆ†æ›¿æ¢ä¸ºç›®æ ‡è¯­è¨€
        if chinese_replacement_items:
            print(f"\n[ä¸­æ–‡æ›¿æ¢] å‘ç° {len(chinese_replacement_items)} æ¡åŒ…å«ä¸­æ–‡çš„è¯‘æ–‡ï¼Œå‡†å¤‡æ›¿æ¢...")

            from text_utils import extract_and_replace_chinese

            # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¥è¯­
            is_japanese = ('æ—¥' in target_language or 'ja' in target_language.lower())

            replaced_count = 0
            for item in chinese_replacement_items:
                idx = item["index"]
                original_text = item["target"]

                # æå–å¹¶æ›¿æ¢ä¸­æ–‡éƒ¨åˆ†
                replaced_text = extract_and_replace_chinese(
                    original_text,
                    target_language,
                    to_kana=is_japanese  # å¦‚æœæ˜¯æ—¥è¯­ï¼Œè½¬æ¢ä¸ºå‡å
                )

                if replaced_text != original_text:
                    target_subtitles[idx]["text"] = replaced_text
                    replaced_count += 1
                    print(f"  [{idx}] '{original_text}' -> '{replaced_text}'")

            if replaced_count > 0:
                print(f"\nâœ… æˆåŠŸæ›¿æ¢ {replaced_count} æ¡è¯‘æ–‡ä¸­çš„ä¸­æ–‡")
                # ä¿å­˜æ›´æ–°åçš„å­—å¹•æ–‡ä»¶
                print(f"[ä¸­æ–‡æ›¿æ¢] ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°: {target_subtitle_path}")
                srt_parser.save_srt(target_subtitles, target_subtitle_path)
                print(f"âœ… å­—å¹•æ–‡ä»¶å·²æ›´æ–°")
            else:
                print(f"â„¹ï¸  æ‰€æœ‰ä¸­æ–‡éƒ½å·²æˆåŠŸæ›¿æ¢")

        # 10.4.5. è‹±æ–‡æ£€æµ‹ï¼šå¦‚æœç›®æ ‡è¯­è¨€æ˜¯æ—¥è¯­æˆ–éŸ©è¯­ï¼Œæ£€æµ‹çº¯è‹±æ–‡å¥å­å¹¶è½¬æ¢
        is_japanese = ('æ—¥' in target_language or 'ja' in target_language.lower())
        is_korean = ('éŸ©' in target_language or 'ko' in target_language.lower())

        if is_japanese or is_korean:
            print(f"\n[è‹±æ–‡æ£€æµ‹] æ£€æŸ¥è¯‘æ–‡ä¸­çš„çº¯è‹±æ–‡å¥å­...")
            from text_utils import is_english_text, batch_translate_english_to_kana, batch_translate_english_to_korean

            # æ”¶é›†æ‰€æœ‰çº¯è‹±æ–‡å¥å­
            english_items = []
            for idx, target_sub in enumerate(target_subtitles):
                target_text = target_sub.get("text", "").strip()
                if is_english_text(target_text):
                    english_items.append({
                        "index": idx,
                        "text": target_text
                    })

            if english_items:
                print(f"[è‹±æ–‡æ£€æµ‹] å‘ç° {len(english_items)} æ¡çº¯è‹±æ–‡å¥å­ï¼Œå‡†å¤‡è½¬æ¢...")

                # æå–æ‰€æœ‰è‹±æ–‡æ–‡æœ¬å¹¶å»é‡
                english_texts = [item["text"] for item in english_items]
                unique_english = list(dict.fromkeys(english_texts))  # ä¿æŒé¡ºåºçš„å»é‡

                # æ‰¹é‡è½¬æ¢
                if is_japanese:
                    print(f"[è‹±æ–‡æ£€æµ‹] æ‰¹é‡è½¬æ¢ä¸ºæ—¥è¯­å‡å...")
                    translation_map = batch_translate_english_to_kana(unique_english)
                else:  # is_korean
                    print(f"[è‹±æ–‡æ£€æµ‹] æ‰¹é‡è½¬æ¢ä¸ºéŸ©æ–‡...")
                    translation_map = batch_translate_english_to_korean(unique_english)

                # æ›¿æ¢æ‰€æœ‰è‹±æ–‡å¥å­
                converted_count = 0
                for item in english_items:
                    idx = item["index"]
                    original_text = item["text"]

                    converted_text = translation_map.get(original_text, original_text)

                    if converted_text != original_text:
                        target_subtitles[idx]["text"] = converted_text
                        converted_count += 1
                        print(f"  [{idx}] '{original_text}' -> '{converted_text}'")

                if converted_count > 0:
                    print(f"\nâœ… æˆåŠŸè½¬æ¢ {converted_count} æ¡çº¯è‹±æ–‡å¥å­")
                    # ä¿å­˜æ›´æ–°åçš„å­—å¹•æ–‡ä»¶
                    print(f"[è‹±æ–‡æ£€æµ‹] ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°: {target_subtitle_path}")
                    srt_parser.save_srt(target_subtitles, target_subtitle_path)
                    print(f"âœ… å­—å¹•æ–‡ä»¶å·²æ›´æ–°")
                else:
                    print(f"â„¹ï¸  æ‰€æœ‰è‹±æ–‡å¥å­éƒ½å·²æˆåŠŸè½¬æ¢")
            else:
                print(f"[è‹±æ–‡æ£€æµ‹] æœªå‘ç°çº¯è‹±æ–‡å¥å­")

        # 10.5. æ•°å­—æ›¿æ¢ï¼šå°†é˜¿æ‹‰ä¼¯æ•°å­—è½¬æ¢ä¸ºç›®æ ‡è¯­è¨€çš„å‘éŸ³
        print(f"\n[æ•°å­—æ›¿æ¢] å¼€å§‹æ£€æµ‹å¹¶æ›¿æ¢è¯‘æ–‡ä¸­çš„é˜¿æ‹‰ä¼¯æ•°å­—...")
        from text_utils import replace_digits_in_text

        # è·å–ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆä»è¯­è¨€åç§°æ˜ å°„å›ä»£ç ï¼‰
        language_code_map = {
            'è‹±è¯­': 'en',
            'éŸ©è¯­': 'ko',
            'æ—¥è¯­': 'ja',
            'æ³•è¯­': 'fr',
            'å¾·è¯­': 'de',
            'è¥¿ç­ç‰™è¯­': 'es'
        }
        target_lang_code = language_code_map.get(target_language, target_language.lower())

        # éå†æ‰€æœ‰è¯‘æ–‡ï¼Œæ£€æµ‹å¹¶æ›¿æ¢æ•°å­—
        digits_replaced_count = 0
        for idx, subtitle in enumerate(target_subtitles):
            original_text = subtitle["text"]
            replaced_text = replace_digits_in_text(original_text, target_lang_code)

            if replaced_text != original_text:
                subtitle["text"] = replaced_text
                digits_replaced_count += 1
                print(f"  [{idx}] '{original_text}' -> '{replaced_text}'")

        if digits_replaced_count > 0:
            print(f"\nâœ… æˆåŠŸæ›¿æ¢ {digits_replaced_count} æ¡è¯‘æ–‡ä¸­çš„æ•°å­—")
            # ä¿å­˜æ›´æ–°åçš„å­—å¹•æ–‡ä»¶
            print(f"[æ•°å­—æ›¿æ¢] ä¿å­˜æ›´æ–°åçš„å­—å¹•åˆ°: {target_subtitle_path}")
            srt_parser.save_srt(target_subtitles, target_subtitle_path)
            print(f"âœ… å­—å¹•æ–‡ä»¶å·²æ›´æ–°")
        else:
            print(f"â„¹ï¸  æœªå‘ç°éœ€è¦æ›¿æ¢çš„æ•°å­—")

        # 11. å‡†å¤‡æ‰¹é‡ç”Ÿæˆä»»åŠ¡
        voice_cloning_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨æ‰¹é‡ç”Ÿæˆå…‹éš†è¯­éŸ³...",
            "progress": 20
        }
        await asyncio.sleep(0.5)

        cloned_audio_dir = os.path.join("exports", f"cloned_{task_id}")
        os.makedirs(cloned_audio_dir, exist_ok=True)

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        cloned_results = []

        print(f"\n[DEBUG] å‡†å¤‡ä»»åŠ¡åˆ—è¡¨")
        print(f"  speaker_labels é•¿åº¦: {len(speaker_labels)}")
        print(f"  target_subtitles é•¿åº¦: {len(target_subtitles)}")
        print(f"  target_subtitles ä¸­å‰3æ¡æ–‡æœ¬:")
        for i in range(min(3, len(target_subtitles))):
            print(f"    [{i}] {target_subtitles[i]['text']}")

        # æ£€æŸ¥é•¿åº¦ä¸ä¸€è‡´çš„æƒ…å†µ
        if len(speaker_labels) != len(target_subtitles):
            error_msg = (
                f"âŒ å­—å¹•æ–‡ä»¶è¡Œæ•°ä¸åŒ¹é…ï¼\n"
                f"   åŸè¯­è¨€å­—å¹•: {len(speaker_labels)} æ¡\n"
                f"   ç›®æ ‡è¯­è¨€å­—å¹•: {len(target_subtitles)} æ¡\n"
                f"   ğŸ’¡ è¯·ç¡®ä¿ä¸¤ä¸ªå­—å¹•æ–‡ä»¶çš„è¡Œæ•°å®Œå…¨ä¸€è‡´ï¼ˆæ¯ä¸€è¡ŒåŸæ–‡å¯¹åº”ä¸€è¡Œè¯‘æ–‡ï¼‰"
            )
            print(f"\n{error_msg}")

            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            voice_cloning_status[task_id] = {
                "status": "failed",
                "message": f"å­—å¹•æ–‡ä»¶è¡Œæ•°ä¸åŒ¹é…: åŸæ–‡{len(speaker_labels)}æ¡ vs è¯‘æ–‡{len(target_subtitles)}æ¡",
                "progress": 0
            }

            raise ValueError(error_msg)

        for idx, (speaker_id, target_sub) in enumerate(zip(speaker_labels, target_subtitles)):
            target_text = target_sub["text"]

            if speaker_id is None or speaker_id not in speaker_npy_files:
                # æ²¡æœ‰åˆ†é…è¯´è¯äººæˆ–è¯´è¯äººç¼–ç å¤±è´¥çš„ç‰‡æ®µï¼Œè®°å½•ä½†ä¸ç”Ÿæˆ
                cloned_results.append({
                    "index": idx,
                    "speaker_id": speaker_id,
                    "target_text": target_text,
                    "cloned_audio_path": None,
                    "start_time": target_sub.get("start_time", 0),
                    "end_time": target_sub.get("end_time", 0)
                })
            else:
                # æ·»åŠ åˆ°æ‰¹é‡ç”Ÿæˆä»»åŠ¡
                tasks.append({
                    "speaker_id": speaker_id,
                    "target_text": target_text,
                    "segment_index": idx,
                    "start_time": target_sub.get("start_time", 0),
                    "end_time": target_sub.get("end_time", 0)
                })

        # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è¯­éŸ³
        print(f"\nğŸš€ æ‰¹é‡ç”Ÿæˆ {len(tasks)} ä¸ªè¯­éŸ³ç‰‡æ®µ...")

        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        def voice_cloning_progress_callback(current, total):
            # 20-95% çš„è¿›åº¦ç”¨äºè¯­éŸ³ç”Ÿæˆï¼ˆå‰20%ç»™å‰ç½®æ“ä½œï¼Œå80%ç»™å…‹éš†ï¼‰
            progress = 20 + int((current / total) * 75)
            voice_cloning_status[task_id]["progress"] = progress
            voice_cloning_status[task_id]["message"] = f"æ­£åœ¨ç”Ÿæˆè¯­éŸ³... ({current}/{total})"
            # è°ƒè¯•æ—¥å¿—å·²ç§»é™¤ - å‡å°‘æ—¥å¿—è¾“å‡º

        # å°†ç”Ÿæˆè„šæœ¬ä¿å­˜åˆ°audio_dirä¸‹çš„scriptsç›®å½•ï¼Œé¿å…è§¦å‘uvicorn reload
        script_dir = os.path.join(audio_dir, "scripts")

        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œè¯­éŸ³ç”Ÿæˆï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        def run_batch_generation():
            return batch_cloner.batch_generate_audio(
                tasks,
                speaker_npy_files,
                speaker_references,
                cloned_audio_dir,
                script_dir=script_dir,
                progress_callback=voice_cloning_progress_callback
            )

        loop = asyncio.get_event_loop()
        generated_audio_files = await loop.run_in_executor(
            None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
            run_batch_generation
        )

        # è°ƒè¯•ï¼šæ‰“å°ç”Ÿæˆç»“æœ
        print(f"\n[DEBUG] generated_audio_files ç±»å‹: {type(generated_audio_files)}")
        print(f"[DEBUG] generated_audio_files é”®ç¤ºä¾‹ (å‰3ä¸ª): {list(generated_audio_files.keys())[:3]}")
        print(f"[DEBUG] generated_audio_files ç¤ºä¾‹:")
        for key in list(generated_audio_files.keys())[:3]:
            print(f"  key={key} (type={type(key)}), value={generated_audio_files[key]}")

        # æ›´æ–°ç»“æœï¼Œæ·»åŠ ç”ŸæˆæˆåŠŸçš„éŸ³é¢‘è·¯å¾„
        for task in tasks:
            segment_index = task["segment_index"]
            if segment_index in generated_audio_files:
                # ç”ŸæˆAPIè·¯å¾„ï¼ˆä¸ fish_simple_cloner.py ä¸­çš„æ–‡ä»¶åæ ¼å¼ä¸€è‡´ï¼‰
                audio_filename = f"segment_{segment_index}.wav"
                api_path = f"/cloned-audio/{task_id}/{audio_filename}"

                cloned_results.append({
                    "index": segment_index,
                    "speaker_id": task["speaker_id"],
                    "target_text": task["target_text"],
                    "cloned_audio_path": api_path,
                    "start_time": task.get("start_time", 0),
                    "end_time": task.get("end_time", 0)
                })
            else:
                cloned_results.append({
                    "index": segment_index,
                    "speaker_id": task["speaker_id"],
                    "target_text": task["target_text"],
                    "cloned_audio_path": None,
                    "error": "ç”Ÿæˆå¤±è´¥",
                    "start_time": task.get("start_time", 0),
                    "end_time": task.get("end_time", 0)
                })

        # æŒ‰ç´¢å¼•æ’åºç»“æœ
        cloned_results.sort(key=lambda x: x["index"])

        # è°ƒè¯•ï¼šæ‰“å°å‰å‡ ä¸ªç»“æœï¼ˆåŒ…å« target_textï¼‰
        print(f"\n[DEBUG] cloned_results ç¤ºä¾‹ (å‰3ä¸ª):")
        for i, result in enumerate(cloned_results[:3]):
            print(f"  [{i}] index={result['index']}, speaker_id={result['speaker_id']}")
            print(f"      target_text='{result['target_text']}'")
            print(f"      cloned_audio_path={result.get('cloned_audio_path', 'None')}")

        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        def format_duration(seconds):
            """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´å­—ç¬¦ä¸²"""
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(total_duration)

        # åˆ›å»ºå®Œæ•´çš„åˆå§‹éŸ³è‰²æ˜ å°„ï¼ˆä¸ºæ‰€æœ‰è¯´è¯äººè®¾ç½®é»˜è®¤å€¼ï¼‰
        complete_initial_mapping = {}
        for speaker_id in speaker_references.keys():
            speaker_id_str = str(speaker_id)
            complete_initial_mapping[speaker_id_str] = speaker_voice_mapping.get(speaker_id_str, "default")

        # æ›´æ–°çŠ¶æ€ï¼šå®Œæˆ
        voice_cloning_status[task_id] = {
            "status": "completed",
            "message": f"è¯­éŸ³å…‹éš†å®Œæˆ (è€—æ—¶: {duration_str})",
            "progress": 100,
            "speaker_references": speaker_references,
            "unique_speakers": len(speaker_references),
            "speaker_name_mapping": speaker_name_mapping,
            "gender_dict": gender_dict,
            "cloned_results": cloned_results,
            "audio_dir": audio_dir,  # ä¿å­˜éŸ³é¢‘ç‰‡æ®µç›®å½•
            "cloned_audio_dir": cloned_audio_dir,  # ä¿å­˜å…‹éš†éŸ³é¢‘ç›®å½•
            "initial_speaker_voice_mapping": complete_initial_mapping,  # ä¿å­˜å®Œæ•´çš„åˆå§‹éŸ³è‰²æ˜ å°„
            "total_duration": total_duration,  # åŸå§‹ç§’æ•°
            "duration_str": duration_str  # æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        }

        print(f"\nè¯­éŸ³å…‹éš†å‡†å¤‡å®Œæˆï¼")
        print(f"è¯†åˆ«åˆ° {len(speaker_references)} ä¸ªè¯´è¯äºº")
        for speaker_id, ref_data in speaker_references.items():
            print(f"\n{ref_data['speaker_name']} (ID: {speaker_id}, æ€§åˆ«: {ref_data['gender']}):")
            print(f"  å‚è€ƒéŸ³é¢‘: {ref_data['reference_audio']}")
            print(f"  å‚è€ƒæ–‡æœ¬: {ref_data['reference_text'][:100]}...")

        print(f"\nâœ… è¯­éŸ³å…‹éš†ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")
        return  # æ˜¾å¼è¿”å›ï¼Œç¡®ä¿å‡½æ•°æ­£å¸¸ç»“æŸ

    except Exception as e:
        # è®¡ç®—å¤±è´¥æ—¶çš„è€—æ—¶
        end_time = time.time()
        total_duration = end_time - start_time

        # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        import traceback
        error_detail = traceback.format_exc()
        print(f"è¯­éŸ³å…‹éš†å¤„ç†å¤±è´¥: {error_detail}")
        print(f"â±ï¸  å¤±è´¥å‰è€—æ—¶: {total_duration:.1f}ç§’")

        voice_cloning_status[task_id] = {
            "status": "failed",
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "progress": 0,
            "total_duration": total_duration,
            "duration_str": f"{total_duration:.1f}ç§’"
        }


@app.get("/voice-cloning/status/{task_id}")
async def get_voice_cloning_status(task_id: str):
    """è·å–è¯­éŸ³å…‹éš†å¤„ç†çŠ¶æ€"""
    if task_id not in voice_cloning_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    status = voice_cloning_status[task_id]
    # è°ƒè¯•æ—¥å¿—å·²ç§»é™¤ - å‡å°‘æ—¥å¿—è¾“å‡º
    return status


@app.get("/voice-cloning/default-voices")
async def get_default_voices():
    """è·å–é»˜è®¤éŸ³è‰²åº“åˆ—è¡¨"""
    voices = []
    for voice in DEFAULT_VOICES:
        voice_info = {
            "id": voice["id"],
            "name": voice["name"],
            "audio_url": f"/default-voices/{voice['audio_file']}",
            "reference_text": voice["reference_text"]
        }
        voices.append(voice_info)
    return {"voices": voices}


@app.get("/default-voices/{filename}")
async def serve_default_voice_audio(filename: str):
    """æä¾›é»˜è®¤éŸ³è‰²çš„éŸ³é¢‘æ–‡ä»¶"""
    file_path = DEFAULT_VOICES_DIR / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")

    return FileResponse(file_path, media_type="audio/wav")


@app.get("/cloned-audio/{task_id}/{filename}")
async def serve_cloned_audio(task_id: str, filename: str, request: Request):
    """æä¾›å…‹éš†éŸ³é¢‘æ–‡ä»¶çš„æµå¼ä¼ è¾“ï¼Œæ”¯æŒ HTTP Range è¯·æ±‚"""
    file_path = EXPORTS_DIR / f"cloned_{task_id}" / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")

    file_size = file_path.stat().st_size
    range_header = request.headers.get("range")

    # å¦‚æœæ²¡æœ‰ Range è¯·æ±‚å¤´ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
    if not range_header:
        return FileResponse(
            file_path,
            media_type="audio/wav",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )

    # è§£æ Range è¯·æ±‚å¤´
    range_match = re.match(r"bytes=(\d+)-(\d*)", range_header)
    if not range_match:
        raise HTTPException(status_code=416, detail="Invalid range")

    start = int(range_match.group(1))
    end = int(range_match.group(2)) if range_match.group(2) else file_size - 1

    # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
    if start >= file_size or end >= file_size or start > end:
        raise HTTPException(status_code=416, detail="Range not satisfiable")

    chunk_size = end - start + 1

    # è¯»å–æ–‡ä»¶çš„æŒ‡å®šèŒƒå›´
    async def iterfile():
        # å»¶è¿Ÿä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
        import asyncio
        await asyncio.sleep(0.01)

        # é‡æ–°æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œé˜²æ­¢æ–‡ä»¶è¿˜åœ¨å†™å…¥
        current_size = file_path.stat().st_size
        if current_size != file_size:
            print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ {filename} å¤§å°å˜åŒ–: {file_size} -> {current_size}")

        with open(file_path, "rb") as f:
            f.seek(start)
            remaining = chunk_size
            while remaining > 0:
                chunk = f.read(min(8192, remaining))
                if not chunk:
                    break
                remaining -= len(chunk)
                yield chunk

    # è¿”å› 206 Partial Content
    return StreamingResponse(
        iterfile(),
        status_code=206,
        media_type="audio/wav",
        headers={
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Accept-Ranges": "bytes",
            "Content-Length": str(chunk_size),
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )


class RegenerateSegmentRequest(BaseModel):
    task_id: str
    segment_index: int
    new_speaker_id: int
    new_text: Optional[str] = None  # æ–°çš„åŸæ–‡ï¼ˆå¦‚æœä¿®æ”¹äº†ï¼‰
    new_target_text: Optional[str] = None  # æ–°çš„è¯‘æ–‡ï¼ˆå¦‚æœä¿®æ”¹äº†ï¼‰


class TranslateTextRequest(BaseModel):
    text: str
    target_language: str


class BatchTranslateRequest(BaseModel):
    source_subtitle_filename: str
    target_language: str


class StitchAudioRequest(BaseModel):
    task_id: str


class RegenerateVoicesRequest(BaseModel):
    task_id: str
    speaker_voice_mapping: Dict[str, str]  # {speaker_id: voice_id}


@app.post("/voice-cloning/regenerate-voices")
async def regenerate_voices_with_new_mapping(request: RegenerateVoicesRequest):
    """é‡æ–°ç”Ÿæˆä½¿ç”¨äº†ä¸åŒéŸ³è‰²çš„è¯´è¯äººçš„æ‰€æœ‰è¯­éŸ³ç‰‡æ®µ"""
    try:
        import asyncio
        from fish_batch_cloner import FishBatchCloner
        import time

        task_id = request.task_id

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if task_id not in voice_cloning_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        status = voice_cloning_status[task_id]
        cloned_results = status.get("cloned_results", [])
        speaker_references = status.get("speaker_references", {})

        if not cloned_results or not speaker_references:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰å¯é‡æ–°ç”Ÿæˆçš„è¯­éŸ³æ•°æ®")

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # è®¾ç½®çŠ¶æ€ä¸ºé‡æ–°ç”Ÿæˆä¸­
        voice_cloning_status[task_id]["status"] = "regenerating"
        voice_cloning_status[task_id]["message"] = "æ­£åœ¨é‡æ–°ç”Ÿæˆè¯­éŸ³..."
        voice_cloning_status[task_id]["progress"] = 0

        # è·å–éŸ³é¢‘ç›®å½•
        audio_dir = status.get("audio_dir")
        cloned_audio_dir = status.get("cloned_audio_dir")

        print(f"\n[é‡æ–°ç”Ÿæˆ] å¼€å§‹é‡æ–°ç”Ÿæˆä»»åŠ¡ {task_id} çš„è¯­éŸ³...")
        print(f"[é‡æ–°ç”Ÿæˆ] æ–°éŸ³è‰²æ˜ å°„: {request.speaker_voice_mapping}")

        # è·å–åˆå§‹éŸ³è‰²æ˜ å°„
        initial_mapping = status.get("initial_speaker_voice_mapping", {})
        print(f"[é‡æ–°ç”Ÿæˆ] åˆå§‹éŸ³è‰²æ˜ å°„: {initial_mapping}")

        # åˆ†æéœ€è¦é‡æ–°ç”Ÿæˆçš„è¯´è¯äººï¼ˆå¯¹æ¯”åˆå§‹æ˜ å°„å’Œæ–°æ˜ å°„ï¼‰
        speakers_to_regenerate = set()
        for speaker_id_str in speaker_references.keys():
            speaker_id_str_key = str(speaker_id_str)
            initial_voice = initial_mapping.get(speaker_id_str_key, "default")
            new_voice = request.speaker_voice_mapping.get(speaker_id_str_key, "default")

            if initial_voice != new_voice:
                speakers_to_regenerate.add(int(speaker_id_str))
                print(f"  è¯´è¯äºº {speaker_id_str}: {initial_voice} -> {new_voice} (éœ€è¦é‡æ–°ç”Ÿæˆ)")
            else:
                print(f"  è¯´è¯äºº {speaker_id_str}: {initial_voice} (æ— å˜åŒ–)")

        if not speakers_to_regenerate:
            print(f"[é‡æ–°ç”Ÿæˆ] æ²¡æœ‰éœ€è¦é‡æ–°ç”Ÿæˆçš„è¯´è¯äºº")
            voice_cloning_status[task_id]["status"] = "completed"
            return {"success": True, "message": "æ²¡æœ‰éœ€è¦é‡æ–°ç”Ÿæˆçš„è¯´è¯äºº"}

        print(f"\n[é‡æ–°ç”Ÿæˆ] éœ€è¦é‡æ–°ç”Ÿæˆçš„è¯´è¯äºº: {speakers_to_regenerate}")

        # æ”¶é›†éœ€è¦é‡æ–°ç”Ÿæˆçš„ä»»åŠ¡ï¼ˆæ ¼å¼ä¸åˆå§‹å…‹éš†æ—¶ä¸€è‡´ï¼‰
        tasks_to_regenerate = []
        for idx, result in enumerate(cloned_results):
            if result["speaker_id"] in speakers_to_regenerate:
                tasks_to_regenerate.append({
                    "speaker_id": result["speaker_id"],
                    "target_text": result["target_text"],
                    "segment_index": idx,
                    "start_time": result.get("start_time", 0),
                    "end_time": result.get("end_time", 0)
                })

        print(f"[é‡æ–°ç”Ÿæˆ] æ€»å…±éœ€è¦é‡æ–°ç”Ÿæˆ {len(tasks_to_regenerate)} ä¸ªç‰‡æ®µ")

        # å‡†å¤‡npyæ–‡ä»¶
        encode_output_dir = os.path.join(audio_dir, "encoded")
        os.makedirs(encode_output_dir, exist_ok=True)

        batch_cloner = FishBatchCloner()
        speaker_npy_files = {}

        for speaker_id in speakers_to_regenerate:
            speaker_id_str = str(speaker_id)
            selected_voice = request.speaker_voice_mapping.get(speaker_id_str, "default")

            if selected_voice == "default":
                # ä½¿ç”¨è¯´è¯äººè‡ªå·±çš„éŸ³è‰²
                ref_data = speaker_references[speaker_id]
                speakers_dict = {speaker_id: ref_data}
                encoded_npy = batch_cloner.batch_encode_speakers(speakers_dict, encode_output_dir)
                speaker_npy_files[speaker_id] = encoded_npy[speaker_id]
                print(f"  âœ… è¯´è¯äºº {speaker_id} ä½¿ç”¨è‡ªå·±çš„éŸ³è‰²")
            else:
                # ä½¿ç”¨é»˜è®¤éŸ³è‰²
                default_voice = next((v for v in DEFAULT_VOICES if v["id"] == selected_voice), None)
                if default_voice:
                    npy_path = str(DEFAULT_VOICES_DIR / default_voice["npy_file"])
                    speaker_npy_files[speaker_id] = npy_path
                    print(f"  âœ… è¯´è¯äºº {speaker_id} ä½¿ç”¨é»˜è®¤éŸ³è‰²: {default_voice['name']}")
                    # æ›´æ–°å‚è€ƒæ–‡æœ¬
                    speaker_references[speaker_id]["reference_text"] = default_voice["reference_text"]

        # è·å–è„šæœ¬ç›®å½•
        script_dir = os.path.join(audio_dir, "scripts")

        # æ‰¹é‡ç”Ÿæˆè¯­éŸ³
        print(f"\n[é‡æ–°ç”Ÿæˆ] å¼€å§‹æ‰¹é‡ç”Ÿæˆ...")
        generated_audio_files = batch_cloner.batch_generate_audio(
            tasks_to_regenerate,
            speaker_npy_files,
            speaker_references,
            cloned_audio_dir,
            script_dir=script_dir
        )

        # æ›´æ–° cloned_results
        print(f"\n[é‡æ–°ç”Ÿæˆ] æ›´æ–° cloned_results...")
        import time
        timestamp = int(time.time() * 1000)  # æ¯«ç§’çº§æ—¶é—´æˆ³
        for task in tasks_to_regenerate:
            segment_index = task["segment_index"]
            if segment_index in generated_audio_files:
                # ç”ŸæˆAPIè·¯å¾„ï¼Œæ·»åŠ æ—¶é—´æˆ³å‚æ•°ç ´åæµè§ˆå™¨ç¼“å­˜
                audio_filename = f"segment_{segment_index}.wav"
                api_path = f"/cloned-audio/{task_id}/{audio_filename}?t={timestamp}"

                # æ›´æ–°è¯¥ç‰‡æ®µçš„ä¿¡æ¯
                old_path = cloned_results[segment_index].get("cloned_audio_path")
                cloned_results[segment_index]["cloned_audio_path"] = api_path
                print(f"  âœ… ç‰‡æ®µ {segment_index}: {old_path} -> {api_path}")
            else:
                print(f"  âŒ ç‰‡æ®µ {segment_index} é‡æ–°ç”Ÿæˆå¤±è´¥")

        voice_cloning_status[task_id]["cloned_results"] = cloned_results
        print(f"[é‡æ–°ç”Ÿæˆ] cloned_results å·²æ›´æ–°åˆ° voice_cloning_status")

        # è®¡ç®—è€—æ—¶
        end_time = time.time()
        duration = end_time - start_time

        def format_duration(seconds):
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(duration)

        voice_cloning_status[task_id]["status"] = "completed"
        voice_cloning_status[task_id]["message"] = f"é‡æ–°ç”Ÿæˆå®Œæˆ (è€—æ—¶: {duration_str})"
        voice_cloning_status[task_id]["progress"] = 100

        # åˆ›å»ºå®Œæ•´çš„æ–°éŸ³è‰²æ˜ å°„ï¼ˆä¸ºæ‰€æœ‰è¯´è¯äººè®¾ç½®é»˜è®¤å€¼ï¼‰
        complete_new_mapping = {}
        for speaker_id in speaker_references.keys():
            speaker_id_str = str(speaker_id)
            complete_new_mapping[speaker_id_str] = request.speaker_voice_mapping.get(speaker_id_str, "default")

        # æ›´æ–°åˆå§‹éŸ³è‰²æ˜ å°„ä¸ºæ–°çš„æ˜ å°„
        voice_cloning_status[task_id]["initial_speaker_voice_mapping"] = complete_new_mapping

        print(f"\nâœ… é‡æ–°ç”Ÿæˆä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")

        return {
            "success": True,
            "message": f"æˆåŠŸé‡æ–°ç”Ÿæˆ {len(tasks_to_regenerate)} ä¸ªç‰‡æ®µ",
            "regenerated_count": len(tasks_to_regenerate),
            "duration": duration_str
        }

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[é‡æ–°ç”Ÿæˆ] å¤±è´¥: {error_detail}")

        voice_cloning_status[task_id]["status"] = "failed"
        voice_cloning_status[task_id]["message"] = f"é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}"

        raise HTTPException(status_code=500, detail=str(e))


@app.post("/translate-text")
async def translate_text(request: TranslateTextRequest):
    """ä½¿ç”¨LLMç¿»è¯‘æ–‡æœ¬"""
    print(f"\n[ç¿»è¯‘API] æ”¶åˆ°è¯·æ±‚")
    print(f"[ç¿»è¯‘API] åŸæ–‡: {request.text}")
    print(f"[ç¿»è¯‘API] ç›®æ ‡è¯­è¨€: {request.target_language}")

    try:
        import json
        import subprocess
        import tempfile
        import os

        # å°†è¯­è¨€ä»£ç è½¬æ¢ä¸ºä¸­æ–‡åç§°ï¼ˆç”¨äºLLM promptï¼‰
        target_language_name = get_language_name(request.target_language)
        print(f"[ç¿»è¯‘API] è¯­è¨€ä»£ç : {request.target_language} -> {target_language_name}")

        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨ Ollamaï¼‰
        config_data = {
            "tasks": [{
                "task_id": "translate-1",
                "source": request.text,
                "target_language": target_language_name
            }],
            "model": "qwen2.5:7b"  # ä½¿ç”¨ qwen2.5:7b é¿å… qwen3 çš„æ€è€ƒå»¶è¿Ÿ
        }

        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False)
            config_file = f.name

        print(f"[ç¿»è¯‘API] åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶: {config_file}")

        try:
            # ä½¿ç”¨ ui conda ç¯å¢ƒï¼ˆOllama æ–¹æ¡ˆï¼‰
            ui_env_python = os.environ.get("UI_PYTHON")
            if not ui_env_python:
                import platform
                if platform.system() == "Windows":
                    ui_env_python = r"C:\Users\7\miniconda3\envs\ui\python.exe"
                else:
                    ui_env_python = os.path.expanduser("~/miniconda3/envs/ui/bin/python")

            # è°ƒç”¨ Ollama æ‰¹é‡ç¿»è¯‘è„šæœ¬
            batch_retranslate_script = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "batch_retranslate_ollama.py"
            )

            print(f"[ç¿»è¯‘API] è°ƒç”¨ç¿»è¯‘è„šæœ¬...")
            print(f"[ç¿»è¯‘API] Pythonå¯æ‰§è¡Œæ–‡ä»¶: {ui_env_python}")
            print(f"[ç¿»è¯‘API] ç¿»è¯‘è„šæœ¬: {batch_retranslate_script}")
            print(f"[ç¿»è¯‘API] å·¥ä½œç›®å½•: {os.path.dirname(__file__)}")

            # ä½¿ç”¨ Popen ä»¥å®æ—¶è·å–è¾“å‡º
            import sys
            import threading
            import time as time_module

            process = subprocess.Popen(
                [ui_env_python, batch_retranslate_script, config_file],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                cwd=os.path.dirname(__file__),
                bufsize=1  # è¡Œç¼“å†²
            )

            print(f"[ç¿»è¯‘API] è¿›ç¨‹å·²å¯åŠ¨ PID={process.pid}ï¼Œç­‰å¾…è¾“å‡º...")

            # å®æ—¶è¯»å–è¾“å‡ºï¼ˆä½¿ç”¨çº¿ç¨‹ï¼‰
            stdout_lines = []
            stderr_lines = []

            def read_stdout():
                for line in process.stdout:
                    line = line.rstrip('\n')
                    print(f"[ç¿»è¯‘è„šæœ¬] {line}")
                    stdout_lines.append(line)
                    sys.stdout.flush()

            def read_stderr():
                for line in process.stderr:
                    line = line.rstrip('\n')
                    print(f"[ç¿»è¯‘è„šæœ¬ STDERR] {line}")
                    stderr_lines.append(line)
                    sys.stdout.flush()

            # å¯åŠ¨è¯»å–çº¿ç¨‹
            stdout_thread = threading.Thread(target=read_stdout)
            stderr_thread = threading.Thread(target=read_stderr)
            stdout_thread.daemon = True
            stderr_thread.daemon = True
            stdout_thread.start()
            stderr_thread.start()

            # ç­‰å¾…è¿›ç¨‹ç»“æŸï¼ˆå¸¦è¶…æ—¶ï¼‰
            try:
                return_code = process.wait(timeout=300)
            except subprocess.TimeoutExpired:
                print(f"[ç¿»è¯‘API] è¶…æ—¶ï¼æ­£åœ¨ç»ˆæ­¢è¿›ç¨‹...")
                process.kill()
                process.wait()
                raise

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            stdout_thread.join(timeout=5)
            stderr_thread.join(timeout=5)

            # æ„å»ºç»“æœå¯¹è±¡
            class Result:
                def __init__(self, returncode, stdout, stderr):
                    self.returncode = returncode
                    self.stdout = stdout
                    self.stderr = stderr

            result = Result(
                return_code,
                '\n'.join(stdout_lines),
                '\n'.join(stderr_lines)
            )

            print(f"[ç¿»è¯‘API] è¿›ç¨‹ç»“æŸï¼Œè¿”å›ç ={result.returncode}")

            if result.returncode != 0:
                print(f"[ç¿»è¯‘API] ç¿»è¯‘è„šæœ¬stderr: {result.stderr}")
                print(f"[ç¿»è¯‘API] ç¿»è¯‘è„šæœ¬stdout: {result.stdout}")
                raise HTTPException(status_code=500, detail=f"ç¿»è¯‘è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}")

            # è§£æè¾“å‡ºä¸­çš„JSONç»“æœ
            print(f"[ç¿»è¯‘API] è§£æç¿»è¯‘ç»“æœ...")
            output_lines = result.stdout.split('\n')
            json_started = False
            json_lines = []

            for line in output_lines:
                if 'FINAL RESULTS (JSON)' in line:
                    json_started = True
                    continue
                if json_started:
                    # è·³è¿‡åˆ†éš”çº¿
                    if line.strip().startswith('='):
                        continue
                    # å¼€å§‹æ”¶é›†JSONï¼ˆä» [ å¼€å§‹ï¼‰
                    if line.strip().startswith('['):
                        json_lines.append(line)
                    elif len(json_lines) > 0:
                        # å·²ç»å¼€å§‹æ”¶é›†äº†ï¼Œç»§ç»­æ·»åŠ 
                        json_lines.append(line)

            json_text = '\n'.join(json_lines).strip()
            print(f"[ç¿»è¯‘API] JSONæ–‡æœ¬: {json_text[:200]}...")

            results = json.loads(json_text)
            print(f"[ç¿»è¯‘API] è§£æç»“æœæ•°é‡: {len(results)}")

            if results and len(results) > 0:
                translation = results[0].get('translation', request.text)
                print(f"[ç¿»è¯‘API] ç¿»è¯‘æˆåŠŸ: {translation}")
                return {"translation": translation}
            else:
                print(f"[ç¿»è¯‘API] è­¦å‘Š: æ²¡æœ‰ç¿»è¯‘ç»“æœï¼Œè¿”å›åŸæ–‡")
                return {"translation": request.text}

        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(config_file):
                os.remove(config_file)
                print(f"[ç¿»è¯‘API] åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {config_file}")

    except subprocess.TimeoutExpired:
        print(f"[ç¿»è¯‘API] è¶…æ—¶: ç¿»è¯‘è€—æ—¶è¶…è¿‡300ç§’")
        # è¶…æ—¶æ—¶è¿”å›åŸæ–‡ï¼Œä¸æŠ›å‡ºå¼‚å¸¸
        return {"translation": request.text, "error": "timeout"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ç¿»è¯‘API] å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        # å¼‚å¸¸æ—¶è¿”å›åŸæ–‡ï¼Œä¸æŠ›å‡ºHTTPå¼‚å¸¸
        return {"translation": request.text, "error": str(e)}


@app.post("/translate/batch")
async def batch_translate_subtitles(request: BatchTranslateRequest, background_tasks: BackgroundTasks):
    """æ‰¹é‡ç¿»è¯‘å­—å¹•æ–‡ä»¶"""
    print(f"\n[æ‰¹é‡ç¿»è¯‘] æ”¶åˆ°è¯·æ±‚")
    print(f"[æ‰¹é‡ç¿»è¯‘] åŸæ–‡å­—å¹•: {request.source_subtitle_filename}")
    print(f"[æ‰¹é‡ç¿»è¯‘] ç›®æ ‡è¯­è¨€: {request.target_language}")

    try:
        import uuid

        # ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
        task_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ç¿»è¯‘çŠ¶æ€
        translation_status[task_id] = {
            "status": "processing",
            "message": "æ­£åœ¨å‡†å¤‡ç¿»è¯‘...",
            "progress": 0,
            "source_subtitle_filename": request.source_subtitle_filename,
            "target_language": request.target_language
        }

        # åœ¨åå°æ‰§è¡Œç¿»è¯‘ä»»åŠ¡
        print(f"[æ‰¹é‡ç¿»è¯‘] æ·»åŠ åå°ä»»åŠ¡: {task_id}", flush=True)
        background_tasks.add_task(
            run_batch_translation,
            task_id,
            request.source_subtitle_filename,
            request.target_language
        )

        print(f"[æ‰¹é‡ç¿»è¯‘] è¿”å›å“åº”ç»™å‰ç«¯: {task_id}", flush=True)
        return {"task_id": task_id, "message": "ç¿»è¯‘ä»»åŠ¡å·²å¯åŠ¨"}

    except Exception as e:
        print(f"[æ‰¹é‡ç¿»è¯‘] å¯åŠ¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/translate/status/{task_id}")
async def get_translation_status(task_id: str):
    """è·å–ç¿»è¯‘çŠ¶æ€"""
    if task_id not in translation_status:
        raise HTTPException(status_code=404, detail="ç¿»è¯‘ä»»åŠ¡ä¸å­˜åœ¨")

    status = translation_status[task_id]
    # è°ƒè¯•æ—¥å¿—å·²ç§»é™¤ - å‡å°‘æ—¥å¿—è¾“å‡º
    return status


async def run_batch_translation(task_id: str, source_subtitle_filename: str, target_language: str):
    """æ‰§è¡Œæ‰¹é‡ç¿»è¯‘ä»»åŠ¡ï¼ˆåå°ä»»åŠ¡ï¼‰"""
    try:
        import json
        import subprocess
        import tempfile
        import os
        import re

        print(f"\n[æ‰¹é‡ç¿»è¯‘-{task_id}] å¼€å§‹ç¿»è¯‘ä»»åŠ¡")

        # æ›´æ–°çŠ¶æ€
        translation_status[task_id]["message"] = "æ­£åœ¨è¯»å–åŸæ–‡å­—å¹•..."
        translation_status[task_id]["progress"] = 5

        # è¯»å–åŸæ–‡å­—å¹•
        source_srt_path = UPLOADS_DIR / source_subtitle_filename

        if not os.path.exists(source_srt_path):
            raise FileNotFoundError(f"åŸæ–‡å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {source_srt_path}")

        # è§£æSRTæ–‡ä»¶
        with open(source_srt_path, 'r', encoding='utf-8') as f:
            source_content = f.read()

        # æå–æ‰€æœ‰å­—å¹•æ–‡æœ¬
        subtitle_pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:.*\n?)+?)(?=\n\d+\n|\n*$)'
        matches = re.findall(subtitle_pattern, source_content)

        if not matches:
            raise ValueError("æ— æ³•è§£æSRTæ–‡ä»¶")

        subtitles = []
        for index, start_time, end_time, text in matches:
            text = text.strip()
            subtitles.append({
                "index": int(index) - 1,  # è½¬ä¸º0åŸºç´¢å¼•
                "start_time": start_time,
                "end_time": end_time,
                "text": text
            })

        print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] å…± {len(subtitles)} æ¡å­—å¹•éœ€è¦ç¿»è¯‘")

        # è®°å½•å¼€å§‹æ—¶é—´
        translation_start_time = time.time()

        # æ›´æ–°çŠ¶æ€
        translation_status[task_id]["message"] = f"æ­£åœ¨ç¿»è¯‘ {len(subtitles)} æ¡å­—å¹•..."
        translation_status[task_id]["progress"] = 10

        # å°†è¯­è¨€ä»£ç è½¬æ¢ä¸ºä¸­æ–‡åç§°
        target_language_name = get_language_name(target_language)
        print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] ç›®æ ‡è¯­è¨€: {target_language} -> {target_language_name}")

        # åˆ›å»ºç¿»è¯‘ä»»åŠ¡åˆ—è¡¨
        translate_tasks = []
        for sub in subtitles:
            translate_tasks.append({
                "task_id": f"tr-{sub['index']}",
                "source": sub["text"],
                "target_language": target_language_name
            })

        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        config_data = {
            "tasks": translate_tasks,
            "model": "qwen2.5:7b"  # ä½¿ç”¨ qwen2.5:7b é¿å… qwen3 çš„æ€è€ƒå»¶è¿Ÿ
        }

        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False)
            config_file = f.name

        print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] é…ç½®æ–‡ä»¶: {config_file}")

        try:
            # è·å–Pythonå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
            ui_env_python = os.environ.get("UI_PYTHON")
            if not ui_env_python:
                import platform
                if platform.system() == "Windows":
                    ui_env_python = r"C:\Users\7\miniconda3\envs\ui\python.exe"
                else:
                    ui_env_python = os.path.expanduser("~/miniconda3/envs/ui/bin/python")

            # è°ƒç”¨ç¿»è¯‘è„šæœ¬
            batch_translate_script = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "batch_translate_ollama.py"
            )

            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] è°ƒç”¨ç¿»è¯‘è„šæœ¬...")
            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] Python: {ui_env_python}")
            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] è„šæœ¬: {batch_translate_script}")

            # å¯åŠ¨ç¿»è¯‘è¿›ç¨‹ï¼ˆä½¿ç”¨çº¿ç¨‹æ± é¿å…é˜»å¡ï¼‰
            import asyncio
            from concurrent.futures import ThreadPoolExecutor
            env = os.environ.copy()
            env['PYTHONUNBUFFERED'] = '1'

            def run_translation_subprocess():
                """åœ¨çº¿ç¨‹ä¸­è¿è¡Œç¿»è¯‘å­è¿›ç¨‹"""
                import subprocess
                process = subprocess.Popen(
                    [ui_env_python, batch_translate_script, config_file],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    encoding='utf-8',
                    cwd=os.path.dirname(__file__),
                    bufsize=1,
                    env=env
                )

                stdout_lines = []
                stderr_lines = []

                # å®æ—¶è¯»å–è¾“å‡ºå¹¶æ›´æ–°è¿›åº¦
                for line in process.stdout:
                    line = line.rstrip('\n')
                    print(f"[ç¿»è¯‘è„šæœ¬-{task_id}] {line}", flush=True)
                    stdout_lines.append(line)

                    # è§£æè¿›åº¦ - åŒ¹é…æ ¼å¼: [1/46] âœ“ tr-0: ...
                    if line.startswith('[') and '/' in line and ']' in line:
                        try:
                            # ä¾‹å¦‚: [5/30] âœ“ tr-4: ...
                            parts = line.split(']')[0].strip('[').split('/')
                            current = int(parts[0])
                            total = int(parts[1])
                            progress = 10 + int((current / total) * 70)  # 10-80%ï¼Œä¸ºè´¨é‡æ£€æŸ¥é¢„ç•™20%
                            translation_status[task_id]["progress"] = progress
                            translation_status[task_id]["message"] = f"æ­£åœ¨ç¿»è¯‘... ({current}/{total})"
                            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] æ›´æ–°è¿›åº¦: {current}/{total} -> {progress}%")
                        except Exception as e:
                            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] è§£æè¿›åº¦å¤±è´¥: {e}, è¡Œå†…å®¹: {line}")

                # ç­‰å¾…è¿›ç¨‹ç»“æŸå¹¶è·å–è¿”å›ç 
                return_code = process.wait()

                # å¦‚æœæœ‰é”™è¯¯ï¼Œè¯»å–stderr
                if return_code != 0:
                    stderr_output = process.stderr.read()
                    stderr_lines.append(stderr_output)

                return return_code, stdout_lines, stderr_lines

            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå­è¿›ç¨‹ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            loop = asyncio.get_event_loop()
            return_code, stdout_lines, stderr_lines = await loop.run_in_executor(
                None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
                run_translation_subprocess
            )

            if return_code != 0:
                stderr_output = '\n'.join(stderr_lines)
                print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] é”™è¯¯: {stderr_output}")
                raise Exception(f"ç¿»è¯‘è„šæœ¬å¤±è´¥: {stderr_output}")

            # æ›´æ–°çŠ¶æ€
            translation_status[task_id]["message"] = "æ­£åœ¨ä¿å­˜ç¿»è¯‘ç»“æœ..."
            translation_status[task_id]["progress"] = 80

            # è§£æç¿»è¯‘ç»“æœ
            output_text = '\n'.join(stdout_lines)

            # æŸ¥æ‰¾JSONç»“æœ
            json_started = False
            json_lines = []

            for line in stdout_lines:
                if 'ç¿»è¯‘ç»“æœï¼ˆJSONï¼‰' in line or 'FINAL RESULTS' in line:
                    json_started = True
                    continue
                if json_started:
                    if line.strip().startswith('='):
                        continue
                    if line.strip().startswith('['):
                        json_lines.append(line)
                    elif len(json_lines) > 0:
                        json_lines.append(line)
                        if line.strip().endswith(']'):
                            break

            json_text = '\n'.join(json_lines).strip()
            results = json.loads(json_text)

            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] è§£æåˆ° {len(results)} æ¡ç¿»è¯‘ç»“æœ")

            # åˆ›å»ºç¿»è¯‘åçš„SRTæ–‡ä»¶
            translated_subtitles = []
            for result in results:
                task_index = int(result["task_id"].split('-')[-1])
                original_sub = subtitles[task_index]

                translated_subtitles.append({
                    "index": original_sub["index"],
                    "start_time": original_sub["start_time"],
                    "end_time": original_sub["end_time"],
                    "text": result["translation"]
                })

            # æŒ‰ç´¢å¼•æ’åº
            translated_subtitles.sort(key=lambda x: x["index"])

            # ç”ŸæˆSRTå†…å®¹
            srt_content = ""
            for sub in translated_subtitles:
                srt_content += f"{sub['index'] + 1}\n"
                srt_content += f"{sub['start_time']} --> {sub['end_time']}\n"
                srt_content += f"{sub['text']}\n\n"

            # ä¿å­˜ç¿»è¯‘åçš„SRTæ–‡ä»¶
            target_srt_filename = f"translated_{target_language}_{os.path.splitext(source_subtitle_filename)[0]}.srt"
            target_srt_path = UPLOADS_DIR / target_srt_filename

            with open(target_srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)

            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] ç¿»è¯‘å®Œæˆï¼Œä¿å­˜åˆ°: {target_srt_path}")

            # ===== ç¬¬ä¸€éç¿»è¯‘åçš„è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ– =====
            print(f"\n[æ‰¹é‡ç¿»è¯‘-{task_id}] ===== å¼€å§‹è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ– =====")
            translation_status[task_id]["message"] = "æ­£åœ¨è¿›è¡Œè´¨é‡æ£€æŸ¥..."
            translation_status[task_id]["progress"] = 82

            from srt_parser import SRTParser
            from text_utils import check_translation_length, contains_chinese_characters, is_english_text
            from text_utils import extract_and_replace_chinese, batch_translate_english_to_kana, batch_translate_english_to_korean

            srt_parser = SRTParser()
            target_subtitles = srt_parser.parse_srt(target_srt_path)
            source_subtitles = srt_parser.parse_srt(source_srt_path)

            # 1. æ£€æŸ¥è¯‘æ–‡é•¿åº¦å’Œä¸­æ–‡å­—ç¬¦
            target_language_lower = target_language.lower()
            is_japanese = ('æ—¥' in target_language or 'ja' in target_language_lower)
            is_korean = ('éŸ©' in target_language or 'ko' in target_language_lower or 'í•œêµ­' in target_language)
            is_french = ('æ³•' in target_language or 'fr' in target_language_lower or 'franÃ§ais' in target_language_lower)
            is_german = ('å¾·' in target_language or 'de' in target_language_lower or 'deutsch' in target_language_lower)
            is_spanish = ('è¥¿ç­ç‰™' in target_language or 'es' in target_language_lower or 'espaÃ±ol' in target_language_lower or 'spanish' in target_language_lower)

            if is_japanese or is_korean:
                max_ratio = 3
            elif is_french or is_german or is_spanish:
                max_ratio = 1.5
            else:
                max_ratio = 1.2

            too_long_items = []
            chinese_replacement_items = []

            for idx, (source_sub, target_sub) in enumerate(zip(source_subtitles, target_subtitles)):
                source_text = source_sub["text"]
                target_text = target_sub["text"]

                is_too_long, source_len, target_len, ratio = check_translation_length(
                    source_text, target_text, target_language, max_ratio=max_ratio
                )
                has_chinese = contains_chinese_characters(target_text)

                if is_too_long:
                    too_long_items.append({
                        "index": idx,
                        "source": source_text,
                        "target": target_text,
                        "source_length": source_len,
                        "target_length": target_len,
                        "ratio": ratio,
                        "reason": "too_long"
                    })
                    print(f"  [é•¿åº¦æ£€æŸ¥] ç¬¬ {idx} æ¡è¯‘æ–‡è¿‡é•¿: {target_len}/{source_len} = {ratio:.1f}x")
                elif has_chinese:
                    chinese_replacement_items.append({
                        "index": idx,
                        "target": target_text
                    })
                    print(f"  [æ±‰å­—æ£€æŸ¥] ç¬¬ {idx} æ¡è¯‘æ–‡åŒ…å«æ±‰å­—: '{target_text}'")

            # 2. é‡æ–°ç¿»è¯‘è¶…é•¿æ–‡æœ¬
            if too_long_items:
                print(f"\n[æ‰¹é‡ç¿»è¯‘-{task_id}] å‘ç° {len(too_long_items)} æ¡è¶…é•¿è¯‘æ–‡ï¼Œæ‰¹é‡é‡æ–°ç¿»è¯‘...")
                translation_status[task_id]["message"] = f"æ­£åœ¨é‡æ–°ç¿»è¯‘ {len(too_long_items)} æ¡è¶…é•¿æ–‡æœ¬..."
                translation_status[task_id]["progress"] = 85

                retranslate_tasks = []
                for item in too_long_items:
                    retranslate_tasks.append({
                        "task_id": f"item-{item['index']}",
                        "source_text": item["source"],
                        "target_language": target_language,
                        "max_length": int(item["source_length"] * max_ratio * 0.8)
                    })

                retranslate_config = {
                    "tasks": retranslate_tasks,
                    "model": "qwen2.5:7b",
                    "output_file": target_srt_path
                }

                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
                    json.dump(retranslate_config, f, ensure_ascii=False, indent=2)
                    retranslate_config_file = f.name

                try:
                    retranslate_script = os.path.join(os.path.dirname(os.path.abspath(__file__)), "retranslate_ollama.py")
                    process = subprocess.Popen(
                        [ui_env_python, retranslate_script, retranslate_config_file],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        encoding='utf-8',
                        bufsize=1
                    )

                    stdout_lines = []
                    for line in process.stdout:
                        print(line, end='', flush=True)
                        stdout_lines.append(line)

                    returncode = process.wait()
                    stdout = ''.join(stdout_lines)

                    if returncode == 0 and stdout:
                        import re
                        results_match = re.search(r'\[Results\](.*?)\[/Results\]', stdout, re.DOTALL)
                        if results_match:
                            results_json = results_match.group(1).strip()
                            retranslate_results = json.loads(results_json)

                            for result_item in retranslate_results:
                                idx = int(result_item["task_id"].split('-')[1])
                                target_subtitles[idx]["text"] = result_item["translation"]

                            srt_parser.save_srt(target_subtitles, target_srt_path)
                            print(f"âœ… æˆåŠŸé‡æ–°ç¿»è¯‘ {len(retranslate_results)} æ¡æ–‡æœ¬")
                except Exception as e:
                    print(f"âš ï¸ é‡æ–°ç¿»è¯‘å‡ºé”™: {e}")
                finally:
                    if os.path.exists(retranslate_config_file):
                        os.remove(retranslate_config_file)

            # 3. æ›¿æ¢ä¸­æ–‡å­—ç¬¦
            if chinese_replacement_items:
                print(f"\n[æ‰¹é‡ç¿»è¯‘-{task_id}] å‘ç° {len(chinese_replacement_items)} æ¡åŒ…å«ä¸­æ–‡çš„è¯‘æ–‡ï¼Œå‡†å¤‡æ›¿æ¢...")
                translation_status[task_id]["message"] = f"æ­£åœ¨æ›¿æ¢ {len(chinese_replacement_items)} æ¡è¯‘æ–‡ä¸­çš„ä¸­æ–‡..."
                translation_status[task_id]["progress"] = 90

                replaced_count = 0
                for item in chinese_replacement_items:
                    idx = item["index"]
                    original_text = item["target"]

                    replaced_text = extract_and_replace_chinese(
                        original_text,
                        target_language,
                        to_kana=is_japanese
                    )

                    if replaced_text != original_text:
                        target_subtitles[idx]["text"] = replaced_text
                        replaced_count += 1
                        print(f"  [{idx}] '{original_text}' -> '{replaced_text}'")

                if replaced_count > 0:
                    srt_parser.save_srt(target_subtitles, target_srt_path)
                    print(f"âœ… æˆåŠŸæ›¿æ¢ {replaced_count} æ¡è¯‘æ–‡ä¸­çš„ä¸­æ–‡")

            # 4. è‹±æ–‡æ£€æµ‹å’Œè½¬æ¢ï¼ˆæ—¥è¯­/éŸ©è¯­ï¼‰
            if is_japanese or is_korean:
                print(f"\n[æ‰¹é‡ç¿»è¯‘-{task_id}] æ£€æŸ¥çº¯è‹±æ–‡å¥å­...")
                translation_status[task_id]["message"] = "æ­£åœ¨è½¬æ¢è‹±æ–‡å¥å­..."
                translation_status[task_id]["progress"] = 95

                # é‡æ–°è¯»å–æœ€æ–°çš„å­—å¹•ï¼ˆå¯èƒ½å·²è¢«ä¸Šä¸€æ­¥ä¿®æ”¹ï¼‰
                target_subtitles = srt_parser.parse_srt(target_srt_path)

                english_items = []
                for idx, target_sub in enumerate(target_subtitles):
                    target_text = target_sub.get("text", "").strip()
                    if is_english_text(target_text):
                        english_items.append({
                            "index": idx,
                            "text": target_text
                        })

                if english_items:
                    print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] å‘ç° {len(english_items)} æ¡çº¯è‹±æ–‡å¥å­ï¼Œå‡†å¤‡è½¬æ¢...")

                    english_texts = [item["text"] for item in english_items]
                    unique_english = list(dict.fromkeys(english_texts))

                    if is_japanese:
                        translation_map = batch_translate_english_to_kana(unique_english)
                    else:
                        translation_map = batch_translate_english_to_korean(unique_english)

                    converted_count = 0
                    for item in english_items:
                        idx = item["index"]
                        original_text = item["text"]
                        converted_text = translation_map.get(original_text, original_text)

                        if converted_text != original_text:
                            target_subtitles[idx]["text"] = converted_text
                            converted_count += 1
                            print(f"  [{idx}] '{original_text}' -> '{converted_text}'")

                    if converted_count > 0:
                        srt_parser.save_srt(target_subtitles, target_srt_path)
                        print(f"âœ… æˆåŠŸè½¬æ¢ {converted_count} æ¡çº¯è‹±æ–‡å¥å­")

            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] ===== è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–å®Œæˆ =====\n")

            # è®¡ç®—æ€»è€—æ—¶
            translation_elapsed = time.time() - translation_start_time
            print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] âœ“ ç¿»è¯‘å®Œæˆï¼æ€»è€—æ—¶: {translation_elapsed:.2f}ç§’")

            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            translation_status[task_id]["status"] = "completed"
            translation_status[task_id]["message"] = "ç¿»è¯‘å®Œæˆ"
            translation_status[task_id]["progress"] = 100
            translation_status[task_id]["target_srt_filename"] = target_srt_filename
            translation_status[task_id]["total_items"] = len(subtitles)
            translation_status[task_id]["elapsed_time"] = round(translation_elapsed, 2)
            translation_status[task_id]["avg_time"] = round(translation_elapsed / len(subtitles), 2) if len(subtitles) > 0 else 0

        finally:
            # åˆ é™¤ä¸´æ—¶é…ç½®æ–‡ä»¶
            if os.path.exists(config_file):
                os.remove(config_file)

    except Exception as e:
        print(f"[æ‰¹é‡ç¿»è¯‘-{task_id}] å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

        translation_status[task_id]["status"] = "failed"
        translation_status[task_id]["message"] = f"ç¿»è¯‘å¤±è´¥: {str(e)}"


@app.post("/voice-cloning/regenerate-segment")
async def regenerate_segment(request: RegenerateSegmentRequest):
    """é‡æ–°ç”Ÿæˆå•ä¸ªå­—å¹•ç‰‡æ®µçš„å…‹éš†è¯­éŸ³ï¼ˆä½¿ç”¨ä¸åŒçš„è¯´è¯äººéŸ³è‰²ï¼‰"""
    try:
        task_id = request.task_id
        segment_index = request.segment_index
        new_speaker_id = request.new_speaker_id

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if task_id not in voice_cloning_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        status = voice_cloning_status[task_id]
        if status["status"] != "completed":
            raise HTTPException(status_code=400, detail="è¯­éŸ³å…‹éš†ä»»åŠ¡å°šæœªå®Œæˆ")

        # è·å–å…‹éš†ç»“æœ
        cloned_results = status.get("cloned_results", [])
        if segment_index < 0 or segment_index >= len(cloned_results):
            raise HTTPException(status_code=400, detail="ç‰‡æ®µç´¢å¼•æ— æ•ˆ")

        # è·å–è¯´è¯äººå‚è€ƒæ•°æ®
        speaker_references = status.get("speaker_references", {})
        if new_speaker_id not in speaker_references:
            raise HTTPException(status_code=400, detail=f"è¯´è¯äºº {new_speaker_id} ä¸å­˜åœ¨")

        # è·å–ç›®æ ‡æ–‡æœ¬ - ä¼˜å…ˆä½¿ç”¨æ–°æ–‡æœ¬
        segment_data = cloned_results[segment_index]
        if request.new_target_text:
            target_text = request.new_target_text
            print(f"[é‡æ–°ç”Ÿæˆç‰‡æ®µ] ä½¿ç”¨æ–°çš„è¯‘æ–‡: {target_text}")
        else:
            target_text = segment_data["target_text"]
            print(f"[é‡æ–°ç”Ÿæˆç‰‡æ®µ] ä½¿ç”¨åŸè¯‘æ–‡: {target_text}")

        # æŸ¥æ‰¾éŸ³é¢‘æå–ç¼“å­˜ä»¥è·å–audio_dir
        audio_dir = None
        print(f"[DEBUG] æŸ¥æ‰¾ task_id={task_id} çš„ audio_dir...")
        print(f"[DEBUG] audio_extraction_cache ä¸­çš„ keys: {list(audio_extraction_cache.keys())}")

        for cache_key, cache_data in audio_extraction_cache.items():
            cache_task_id = cache_data.get("task_id")
            cache_audio_dir = cache_data.get("audio_dir", "")
            print(f"[DEBUG] æ£€æŸ¥ cache_key={cache_key}, task_id={cache_task_id}, audio_dir={cache_audio_dir}")

            if cache_task_id == task_id or task_id in cache_audio_dir:
                audio_dir = cache_data["audio_dir"]
                print(f"[DEBUG] âœ… æ‰¾åˆ°åŒ¹é…çš„ audio_dir: {audio_dir}")
                break

        if not audio_dir:
            # å¦‚æœæ‰¾ä¸åˆ°ç¼“å­˜ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„
            audio_dir = f"audio_segments/{task_id}"
            print(f"[DEBUG] âš ï¸  æœªæ‰¾åˆ°ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {audio_dir}")

            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(audio_dir):
                print(f"[DEBUG] âŒ é»˜è®¤è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨ backend ç›®å½•ä¸‹æŸ¥æ‰¾")
                backend_audio_dir = os.path.join("backend", audio_dir)
                if os.path.exists(backend_audio_dir):
                    audio_dir = backend_audio_dir
                    print(f"[DEBUG] âœ… æ‰¾åˆ°: {audio_dir}")
                else:
                    print(f"[DEBUG] âŒ backend ç›®å½•ä¸‹ä¹Ÿä¸å­˜åœ¨")

        from fish_voice_cloner import FishVoiceCloner
        cloner = FishVoiceCloner()

        # é¦–å…ˆåœ¨æ‰€æœ‰å¯èƒ½çš„ç›®å½•ä¸­æŸ¥æ‰¾å·²ç¼–ç çš„æ–‡ä»¶
        print(f"[æŸ¥æ‰¾ç¼–ç ] æŸ¥æ‰¾ speaker_{new_speaker_id} çš„ç¼–ç æ–‡ä»¶...")

        possible_dirs = [
            "audio_segments",
            "../audio_segments",
            "backend/audio_segments",
        ]

        # å¯èƒ½çš„ç¼–ç æ–‡ä»¶è·¯å¾„æ ¼å¼
        encoding_patterns = [
            ("encoded", f"speaker_{new_speaker_id}_codes.npy"),  # æ–°æ ¼å¼ï¼šæ‰¹é‡ç¼–ç 
            (f"speaker_{new_speaker_id}_encoded", "fake.npy"),   # æ—§æ ¼å¼ï¼šå•ç‹¬ç¼–ç 
        ]

        found_npy = None
        for base_dir in possible_dirs:
            if not os.path.exists(base_dir):
                continue

            # éå†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶å¤¹
            for task_folder in os.listdir(base_dir):
                task_path = os.path.join(base_dir, task_folder)
                if not os.path.isdir(task_path):
                    continue

                # å°è¯•ä¸åŒçš„ç¼–ç æ–‡ä»¶è·¯å¾„æ ¼å¼
                for subdir, filename in encoding_patterns:
                    encoded_path = os.path.join(task_path, subdir, filename)
                    if os.path.exists(encoded_path):
                        found_npy = encoded_path
                        print(f"[æŸ¥æ‰¾ç¼–ç ] âœ… æ‰¾åˆ°ç¼–ç æ–‡ä»¶: {encoded_path}")
                        break

                if found_npy:
                    break

            if found_npy:
                break

        # å¦‚æœæ‰¾åˆ°äº†ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä¸å¤åˆ¶ï¼ŒèŠ‚çœæ—¶é—´ï¼‰
        if found_npy:
            fake_npy_path = found_npy
            print(f"[ç¼–ç ] âœ… ä½¿ç”¨å·²å­˜åœ¨çš„ç¼–ç æ–‡ä»¶: {fake_npy_path}")
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œéœ€è¦é‡æ–°ç¼–ç 
            print(f"[æŸ¥æ‰¾ç¼–ç ] âŒ æœªæ‰¾åˆ°å·²æœ‰ç¼–ç ï¼Œéœ€è¦é‡æ–°ç¼–ç ...")

            # åˆ›å»ºç¼–ç ç›®å½•
            speaker_encoded_dir = os.path.join(audio_dir, f"speaker_{new_speaker_id}_encoded")
            os.makedirs(speaker_encoded_dir, exist_ok=True)

            ref_data = speaker_references[new_speaker_id]
            reference_audio_path = ref_data["reference_audio"]
            print(f"[ç¼–ç ] å‚è€ƒéŸ³é¢‘: {reference_audio_path}")
            print(f"[ç¼–ç ] è¾“å‡ºç›®å½•: {speaker_encoded_dir}")

            fake_npy_path = cloner.encode_reference_audio(
                reference_audio_path,
                speaker_encoded_dir
            )

        # è·å–å‚è€ƒæ–‡æœ¬
        ref_text = speaker_references[new_speaker_id]["reference_text"]

        # ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶åæ ¼å¼ï¼‰
        cloned_audio_dir = status.get("cloned_audio_dir", os.path.join("exports", f"cloned_{task_id}"))
        audio_filename = f"segment_{segment_index}.wav"  # ç»Ÿä¸€ä½¿ç”¨ç®€å•æ ¼å¼
        output_audio = os.path.join(cloned_audio_dir, audio_filename)
        work_dir = os.path.join(audio_dir, f"regen_{segment_index}_{new_speaker_id}")
        os.makedirs(work_dir, exist_ok=True)

        print(f"é‡æ–°ç”Ÿæˆç‰‡æ®µ {segment_index}: æ–°è¯´è¯äºº {new_speaker_id}, æ–‡æœ¬: {target_text[:30]}...")

        # æ­¥éª¤2: ç›´æ¥ç”Ÿæˆè¯­ä¹‰tokenï¼ˆä½¿ç”¨æ–°è¯´è¯äººçš„ç¼–ç ï¼‰
        # è¯´è¯äººæ”¹å˜æ—¶ï¼Œå³ä½¿æ–‡æœ¬ç›¸åŒä¹Ÿéœ€è¦é‡æ–°ç”Ÿæˆè¯­ä¹‰token
        print(f"[è¯­ä¹‰Token] ä½¿ç”¨è¯´è¯äºº{new_speaker_id}ç”Ÿæˆè¯­ä¹‰token...")
        codes_path = cloner.generate_semantic_tokens(
            target_text=target_text,
            ref_text=ref_text,
            fake_npy_path=fake_npy_path,
            output_dir=work_dir
        )

        # æ­¥éª¤3: è§£ç ä¸ºéŸ³é¢‘
        cloner.decode_to_audio(codes_path, output_audio)

        # ç”ŸæˆAPIè·¯å¾„
        api_path = f"/cloned-audio/{task_id}/{audio_filename}"

        # æ›´æ–°å…‹éš†ç»“æœ
        cloned_results[segment_index]["speaker_id"] = new_speaker_id
        cloned_results[segment_index]["cloned_audio_path"] = api_path
        voice_cloning_status[task_id]["cloned_results"] = cloned_results

        print(f"[é‡æ–°ç”Ÿæˆ] ç‰‡æ®µ {segment_index} å·²æ›´æ–°: speaker_id={new_speaker_id}, æ–‡ä»¶å·²è¦†ç›–: {output_audio}")

        return {
            "success": True,
            "segment_index": segment_index,
            "new_speaker_id": new_speaker_id,
            "cloned_audio_path": api_path,
            "target_text": target_text
        }

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"é‡æ–°ç”Ÿæˆç‰‡æ®µå¤±è´¥: {error_detail}")
        raise HTTPException(status_code=500, detail=str(e))


def _replan_audio_timeline(
    cloned_results: List[Dict],
    cloned_audio_dir: str,
    optimized_files: Dict[int, str]
) -> Dict[int, Dict]:
    """
    é‡æ–°è§„åˆ’éŸ³é¢‘æ—¶é—´è½´ï¼Œä¸ºè¶…é•¿ç‰‡æ®µå€Ÿç”¨ç›¸é‚»ç©ºé—²æ—¶é—´

    Args:
        cloned_results: å…‹éš†ç»“æœåˆ—è¡¨
        cloned_audio_dir: å…‹éš†éŸ³é¢‘ç›®å½•
        optimized_files: å·²ä¼˜åŒ–çš„æ–‡ä»¶å­—å…¸

    Returns:
        {segment_index: {'actual_start': float, 'actual_end': float, 'borrowed_before': float, 'borrowed_after': float}}
    """
    import soundfile as sf

    replanned = {}

    # æ„å»ºæ‰€æœ‰ç‰‡æ®µçš„æ—¶é—´ä¿¡æ¯
    segments_info = []
    for idx, result in enumerate(cloned_results):
        # ä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–åçš„æ–‡ä»¶
        if idx in optimized_files:
            audio_file_path = optimized_files[idx]
        else:
            audio_filename = f"segment_{idx}.wav"
            audio_file_path = os.path.join(cloned_audio_dir, audio_filename)

        if not os.path.exists(audio_file_path):
            continue

        try:
            audio_data, sr = sf.read(audio_file_path)
            actual_duration = len(audio_data) / sr

            start_time = result.get("start_time", 0)
            end_time = result.get("end_time", 0)
            target_duration = end_time - start_time

            segments_info.append({
                'index': idx,
                'start_time': start_time,
                'end_time': end_time,
                'target_duration': target_duration,
                'actual_duration': actual_duration,
                'audio_file_path': audio_file_path,
                'sr': sr
            })
        except Exception as e:
            print(f"[æ—¶é—´è½´è§„åˆ’] è¯»å–ç‰‡æ®µ {idx} å¤±è´¥: {e}")
            continue

    # æŒ‰æ—¶é—´æ’åº
    segments_info.sort(key=lambda x: x['start_time'])

    # ä¸ºæ¯ä¸ªè¶…é•¿ç‰‡æ®µè®¡ç®—å¯å€Ÿç”¨çš„æ—¶é—´
    for i, seg in enumerate(segments_info):
        excess = seg['actual_duration'] - seg['target_duration']

        # ä½¿ç”¨å°é˜ˆå€¼åˆ¤æ–­ï¼Œé¿å…æµ®ç‚¹è¯¯å·®å¯¼è‡´ä¸å¿…è¦çš„è°ƒæ•´
        if excess <= 0.001:
            continue  # ä¸è¶…é•¿ï¼Œä¸éœ€è¦è°ƒæ•´

        idx = seg['index']

        # è®¡ç®—æœ€å¤§å¯å€Ÿç”¨æ—¶é—´ï¼ˆåŸå­—å¹•æ—¶é•¿çš„30%ï¼‰
        max_borrow = seg['target_duration'] * 0.5

        # è®¡ç®—å‰åçš„å¯ç”¨ç©ºé—²æ—¶é—´
        gap_before = 0
        if i > 0:
            prev_seg = segments_info[i - 1]
            gap_before = seg['start_time'] - prev_seg['end_time']

        gap_after = 0
        if i < len(segments_info) - 1:
            next_seg = segments_info[i + 1]
            gap_after = next_seg['start_time'] - seg['end_time']

        # ä¼˜å…ˆç­–ç•¥ï¼šå‡åŒ€å€Ÿç”¨ï¼Œä½†ä¸è¶…è¿‡20%é™åˆ¶å’Œå¯ç”¨é—´éš™
        # 1. å…ˆå°è¯•å¹³å‡åˆ†é…
        half_excess = excess / 2
        borrow_before = min(gap_before, max_borrow, half_excess)
        borrow_after = min(gap_after, max_borrow, half_excess)

        # 2. å¦‚æœæ€»å€Ÿç”¨ä¸å¤Ÿï¼Œå°è¯•ä»æœ‰å‰©ä½™ç©ºé—´çš„ä¸€ä¾§å¤šå€Ÿ
        total_borrowed = borrow_before + borrow_after
        if total_borrowed < excess:
            remaining_needed = excess - total_borrowed

            # å‰é¢è¿˜æœ‰å¯å€Ÿç”¨ç©ºé—´
            can_borrow_more_before = min(gap_before - borrow_before, max_borrow - borrow_before)
            # åé¢è¿˜æœ‰å¯å€Ÿç”¨ç©ºé—´
            can_borrow_more_after = min(gap_after - borrow_after, max_borrow - borrow_after)

            if can_borrow_more_before > 0:
                extra_before = min(can_borrow_more_before, remaining_needed)
                borrow_before += extra_before
                remaining_needed -= extra_before

            if remaining_needed > 0 and can_borrow_more_after > 0:
                extra_after = min(can_borrow_more_after, remaining_needed)
                borrow_after += extra_after

        # è®°å½•è°ƒæ•´åçš„å®é™…æ—¶é—´ï¼ˆåªæœ‰çœŸæ­£å€Ÿç”¨äº†æ—¶é—´æ‰è®°å½•ï¼‰
        if borrow_before > 0.001 or borrow_after > 0.001:  # ä½¿ç”¨å°é˜ˆå€¼é¿å…æµ®ç‚¹è¯¯å·®
            actual_start = seg['start_time'] - borrow_before
            actual_end = seg['end_time'] + borrow_after
            replanned[idx] = {
                'actual_start': actual_start,
                'actual_end': actual_end,
                'actual_duration': actual_end - actual_start,
                'borrowed_before': borrow_before,
                'borrowed_after': borrow_after,
                'original_start': seg['start_time'],
                'original_end': seg['end_time']
            }

    return replanned


@app.post("/voice-cloning/stitch-audio")
async def stitch_cloned_audio(request: StitchAudioRequest):
    """
    æ‹¼æ¥æ‰€æœ‰å…‹éš†çš„éŸ³é¢‘ç‰‡æ®µä¸ºå®Œæ•´éŸ³é¢‘ï¼Œå¤„ç†æ—¶é•¿ä¸åŒ¹é…çš„æƒ…å†µ
    """
    try:
        import soundfile as sf
        import numpy as np
        import time

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        task_id = request.task_id

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if task_id not in voice_cloning_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        status = voice_cloning_status[task_id]
        cloned_results = status.get("cloned_results", [])

        if not cloned_results:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰å¯æ‹¼æ¥çš„éŸ³é¢‘ç‰‡æ®µ")

        # è·å–å…‹éš†éŸ³é¢‘ç›®å½•
        cloned_audio_dir = status.get("cloned_audio_dir", os.path.join("exports", f"cloned_{task_id}"))

        print(f"[éŸ³é¢‘æ‹¼æ¥] å¼€å§‹æ‹¼æ¥ä»»åŠ¡ {task_id} çš„éŸ³é¢‘ç‰‡æ®µ...")

        # æ­¥éª¤1: éŸ³é¢‘ä¼˜åŒ–ï¼ˆVAD å»é™¤é™éŸ³ï¼‰
        from audio_optimizer import AudioOptimizer

        print(f"[éŸ³é¢‘ä¼˜åŒ–] æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦ä¼˜åŒ–çš„ç‰‡æ®µ...")
        optimizer = AudioOptimizer()
        optimized_files = optimizer.optimize_segments_for_stitching(
            cloned_results=cloned_results,
            cloned_audio_dir=cloned_audio_dir,
            threshold_ratio=1.1  # è¶…è¿‡ç›®æ ‡é•¿åº¦10%çš„ç‰‡æ®µå°†è¢«ä¼˜åŒ–
        )

        if optimized_files:
            print(f"[éŸ³é¢‘ä¼˜åŒ–] æˆåŠŸä¼˜åŒ– {len(optimized_files)} ä¸ªç‰‡æ®µ")
        else:
            print(f"[éŸ³é¢‘ä¼˜åŒ–] æ— éœ€ä¼˜åŒ–")

        # æ­¥éª¤2: æ—¶é—´è½´é‡æ–°è§„åˆ’ï¼ˆVADåä»è¶…é•¿çš„ç‰‡æ®µå°è¯•å€Ÿç”¨ç›¸é‚»ç©ºé—²æ—¶é—´ï¼‰
        print(f"[æ—¶é—´è½´è§„åˆ’] å¼€å§‹è§„åˆ’éŸ³é¢‘æ—¶é—´è½´...")
        replanned_segments = _replan_audio_timeline(
            cloned_results=cloned_results,
            cloned_audio_dir=cloned_audio_dir,
            optimized_files=optimized_files
        )
        print(f"[æ—¶é—´è½´è§„åˆ’] å®Œæˆï¼Œå…±è°ƒæ•´ {len(replanned_segments)} ä¸ªç‰‡æ®µçš„æ—¶é—´è½´")

        # è·å–åŸè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæå–åŸå§‹éŸ³é¢‘éŸ³é‡
        video_file = status.get("video_file")
        original_audio_volumes = {}

        if video_file:
            video_path = os.path.join("uploads", video_file)
            if os.path.exists(video_path):
                try:
                    import subprocess
                    temp_audio_path = os.path.join("exports", f"temp_original_audio_{task_id}.wav")
                    cmd = [
                        'ffmpeg', '-i', video_path,
                        '-vn', '-acodec', 'pcm_s16le',
                        '-ar', '44100', '-ac', '1',
                        '-y', temp_audio_path
                    ]
                    subprocess.run(cmd, capture_output=True, check=True)

                    original_audio, orig_sr = sf.read(temp_audio_path)

                    for idx, result in enumerate(cloned_results):
                        start_time = result.get("start_time", 0)
                        end_time = result.get("end_time", 0)
                        start_sample = int(start_time * orig_sr)
                        end_sample = int(end_time * orig_sr)

                        if end_sample <= len(original_audio):
                            segment_audio = original_audio[start_sample:end_sample]
                            rms = np.sqrt(np.mean(segment_audio**2))
                            original_audio_volumes[idx] = rms

                    if os.path.exists(temp_audio_path):
                        os.remove(temp_audio_path)

                except Exception as e:
                    print(f"[éŸ³é¢‘æ‹¼æ¥] è­¦å‘Š: æ— æ³•æå–åŸè§†é¢‘éŸ³é¢‘éŸ³é‡: {e}")

        # è¯»å–æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
        segments_with_timing = []
        sample_rate = None

        for idx, result in enumerate(cloned_results):
            cloned_audio_path = result.get("cloned_audio_path")
            if not cloned_audio_path:
                print(f"[éŸ³é¢‘æ‹¼æ¥] è·³è¿‡ç‰‡æ®µ {idx}: æ²¡æœ‰å…‹éš†éŸ³é¢‘")
                continue

            # ä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–åçš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹æ–‡ä»¶
            if idx in optimized_files:
                audio_file_path = optimized_files[idx]
            else:
                # æ„å»ºå®é™…æ–‡ä»¶è·¯å¾„
                audio_filename = f"segment_{idx}.wav"
                audio_file_path = os.path.join(cloned_audio_dir, audio_filename)

            if not os.path.exists(audio_file_path):
                print(f"[éŸ³é¢‘æ‹¼æ¥] è·³è¿‡ç‰‡æ®µ {idx}: æ–‡ä»¶ä¸å­˜åœ¨ {audio_file_path}")
                continue

            # è¯»å–éŸ³é¢‘
            audio_data, sr = sf.read(audio_file_path)
            if sample_rate is None:
                sample_rate = sr
            elif sr != sample_rate:
                print(f"[éŸ³é¢‘æ‹¼æ¥] è­¦å‘Š: ç‰‡æ®µ {idx} é‡‡æ ·ç‡ä¸ä¸€è‡´ ({sr} vs {sample_rate})")

            # è·å–åŸå§‹æ—¶é—´æˆ³
            start_time = result.get("start_time", 0)
            end_time = result.get("end_time", 0)
            timestamp_duration = end_time - start_time

            # è®¡ç®—å®é™…éŸ³é¢‘æ—¶é•¿
            actual_duration = len(audio_data) / sample_rate

            segments_with_timing.append({
                "index": idx,
                "audio_data": audio_data,
                "start_time": start_time,
                "end_time": end_time,
                "timestamp_duration": timestamp_duration,
                "actual_duration": actual_duration,
                "original_volume": original_audio_volumes.get(idx, None)
            })

        if not segments_with_timing:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘ç‰‡æ®µå¯æ‹¼æ¥")

        # æŒ‰å¼€å§‹æ—¶é—´æ’åº
        segments_with_timing.sort(key=lambda x: x["start_time"])

        # å¤„ç†æ¯ä¸ªç‰‡æ®µçš„æ—¶é•¿å’ŒéŸ³é‡
        processed_segments = []

        for seg in segments_with_timing:
            audio_data = seg["audio_data"]
            timestamp_duration = seg["timestamp_duration"]
            actual_duration = seg["actual_duration"]
            original_volume = seg.get("original_volume")
            idx = seg["index"]

            # æ£€æŸ¥æ˜¯å¦æœ‰é‡æ–°è§„åˆ’çš„æ—¶é—´è½´
            if idx in replanned_segments:
                replan_info = replanned_segments[idx]
                # ä½¿ç”¨é‡æ–°è§„åˆ’çš„æ—¶é•¿
                target_duration = replan_info['actual_duration']
                actual_start = replan_info['actual_start']
                actual_end = replan_info['actual_end']

                print(f"[éŸ³é¢‘æ‹¼æ¥] ç‰‡æ®µ {idx}: ä½¿ç”¨é‡æ–°è§„åˆ’çš„æ—¶é—´è½´ {actual_start:.3f}s - {actual_end:.3f}s")
            else:
                # ä½¿ç”¨åŸå§‹æ—¶é—´
                target_duration = timestamp_duration
                actual_start = seg["start_time"]
                actual_end = seg["end_time"]

            target_samples = int(target_duration * sample_rate)
            actual_samples = len(audio_data)

            if actual_samples > target_samples:
                # æƒ…å†µ1: éŸ³é¢‘è¿‡é•¿ï¼Œä»ä¸¤ç«¯ç­‰æ¯”ä¾‹è£å‰ª
                excess_samples = actual_samples - target_samples
                trim_left = excess_samples // 2
                trim_right = excess_samples - trim_left
                processed_audio = audio_data[trim_left:actual_samples - trim_right]

            elif actual_samples < target_samples:
                # æƒ…å†µ2: éŸ³é¢‘è¿‡çŸ­ï¼Œå±…ä¸­å¹¶ä¸¤ç«¯è¡¥é›¶
                pad_samples = target_samples - actual_samples
                pad_left = pad_samples // 2
                pad_right = pad_samples - pad_left
                processed_audio = np.pad(audio_data, (pad_left, pad_right), mode='constant', constant_values=0)

            else:
                # æƒ…å†µ3: æ—¶é•¿å®Œå…¨åŒ¹é…
                processed_audio = audio_data

            # è°ƒæ•´éŸ³é‡ä»¥åŒ¹é…åŸè§†é¢‘
            if original_volume is not None and original_volume > 1e-6:
                cloned_rms = np.sqrt(np.mean(processed_audio**2))
                if cloned_rms > 1e-6:
                    volume_ratio = original_volume / cloned_rms
                    volume_ratio = np.clip(volume_ratio, 0.1, 10.0)
                    processed_audio = processed_audio * volume_ratio

            processed_segments.append({
                "audio": processed_audio,
                "start_time": actual_start,
                "end_time": actual_end
            })

        # æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µï¼Œä¸­é—´å¡«å……é™éŸ³
        final_audio_parts = []
        last_end_time = 0

        for seg in processed_segments:
            # è®¡ç®—ä¸ä¸Šä¸€æ®µçš„é—´éš™
            gap_duration = seg["start_time"] - last_end_time

            if gap_duration > 0.001:  # å¤§äº1msæ‰å¡«å……é™éŸ³
                gap_samples = int(gap_duration * sample_rate)
                silence = np.zeros(gap_samples, dtype=audio_data.dtype)
                final_audio_parts.append(silence)

            final_audio_parts.append(seg["audio"])
            last_end_time = seg["end_time"]

        # åˆå¹¶æ‰€æœ‰éƒ¨åˆ†
        if not final_audio_parts:
            raise ValueError("æ²¡æœ‰éŸ³é¢‘éƒ¨åˆ†å¯ä»¥æ‹¼æ¥")

        final_audio = np.concatenate(final_audio_parts)

        # æ•°æ®éªŒè¯å’Œæ¸…ç†
        has_nan = np.isnan(final_audio).any()
        has_inf = np.isinf(final_audio).any()

        if has_nan or has_inf:
            print(f"[éŸ³é¢‘æ‹¼æ¥] è­¦å‘Š: éŸ³é¢‘æ•°æ®åŒ…å« NaN æˆ– Infï¼Œè¿›è¡Œæ¸…ç†")
            final_audio = np.nan_to_num(final_audio, nan=0.0, posinf=1.0, neginf=-1.0)

        # è½¬æ¢ä¸º int16 PCM æ ¼å¼ï¼ˆæµè§ˆå™¨æœ€å…¼å®¹çš„æ ¼å¼ï¼‰
        # å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´
        max_val = np.max(np.abs(final_audio))
        if max_val > 0:
            final_audio = final_audio / max_val
        # è½¬æ¢ä¸º int16 (-32768 to 32767)
        final_audio_int16 = (final_audio * 32767).astype(np.int16)

        # ä¿å­˜æœ€ç»ˆéŸ³é¢‘
        stitched_filename = f"stitched_{task_id}.wav"
        stitched_path = os.path.join(EXPORTS_DIR, stitched_filename)

        # ä½¿ç”¨ scipy.io.wavfile ä¿å­˜ï¼Œç”Ÿæˆæ ‡å‡† WAV æ–‡ä»¶
        from scipy.io import wavfile
        wavfile.write(stitched_path, sample_rate, final_audio_int16)

        # è®¡ç®—æ€»æ—¶é•¿
        total_duration = len(final_audio) / sample_rate

        print(f"[éŸ³é¢‘æ‹¼æ¥] å®Œæˆ! æ€»æ—¶é•¿: {total_duration:.3f}s")

        # æ›´æ–°é‡æ–°è§„åˆ’çš„ç‰‡æ®µæ—¶é—´åˆ° cloned_resultsï¼ˆç”¨äºå‰ç«¯æ—¶é—´è½´æ˜¾ç¤ºï¼‰
        for idx, replan_info in replanned_segments.items():
            if idx < len(cloned_results):
                # ä¿å­˜é‡æ–°è§„åˆ’çš„å®é™…æ’­æ”¾æ—¶é—´
                cloned_results[idx]['actual_start_time'] = replan_info['actual_start']
                cloned_results[idx]['actual_end_time'] = replan_info['actual_end']
                print(f"[éŸ³é¢‘æ‹¼æ¥] æ›´æ–°ç‰‡æ®µ {idx} æ—¶é—´è½´: {replan_info['actual_start']:.3f}s - {replan_info['actual_end']:.3f}s")

        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        stitch_duration = end_time - start_time

        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆä½¿ç”¨ä¸è¯­éŸ³å…‹éš†ç›¸åŒçš„æ ¼å¼å‡½æ•°ï¼‰
        def format_duration(seconds):
            """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´å­—ç¬¦ä¸²"""
            if seconds < 60:
                return f"{seconds:.1f}ç§’"
            elif seconds < 3600:
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}åˆ†{secs}ç§’"
            else:
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

        duration_str = format_duration(stitch_duration)

        # æ›´æ–°çŠ¶æ€
        voice_cloning_status[task_id]["stitched_audio_path"] = f"/exports/{stitched_filename}"
        voice_cloning_status[task_id]["cloned_results"] = cloned_results  # æ›´æ–°ç»“æœ

        print(f"\nâœ… éŸ³é¢‘æ‹¼æ¥ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration_str}")

        return {
            "success": True,
            "stitched_audio_path": f"/exports/{stitched_filename}",
            "total_duration": total_duration,
            "segments_count": len(processed_segments),
            "message": f"éŸ³é¢‘æ‹¼æ¥å®Œæˆ (è€—æ—¶: {duration_str})",
            "replanned_segments": len(replanned_segments),  # è¿”å›é‡æ–°è§„åˆ’çš„ç‰‡æ®µæ•°é‡
            "stitch_duration": stitch_duration,  # åŸå§‹ç§’æ•°
            "duration_str": duration_str  # æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        }

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[éŸ³é¢‘æ‹¼æ¥] å¤±è´¥: {error_detail}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/export")
async def export_video(
    video_filename: str,
    subtitle_filename: Optional[str] = None,
    export_hard_subtitles: bool = False
):
    try:
        video_path = UPLOADS_DIR / video_filename
        
        if not video_path.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶å
        export_filename = f"export_{uuid.uuid4()}.mp4"
        export_path = EXPORTS_DIR / export_filename
        
        # æ‰§è¡Œå¯¼å‡º
        result = video_processor.export_video(
            str(video_path),
            str(export_path),
            subtitle_filename,
            export_hard_subtitles
        )
        
        return {
            "export_filename": export_filename,
            "success": True,
            "message": "è§†é¢‘å¯¼å‡ºæˆåŠŸ",
            "details": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)