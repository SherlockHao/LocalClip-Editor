"""
æµ‹è¯•éŸ©è¯­å’Œæ—¥è¯­æ–‡æœ¬è§„èŒƒåŒ–å’Œé•¿åº¦è®¡ç®—
"""
import sys
import io

# å¼ºåˆ¶ UTF-8 è¾“å‡ºï¼Œé¿å… Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

from text_utils import (
    normalize_korean,
    normalize_japanese,
    count_korean_length,
    count_japanese_length,
    count_text_length,
    check_translation_length
)


def test_korean_normalization():
    """æµ‹è¯•éŸ©è¯­è§„èŒƒåŒ–"""
    print("\n=== æµ‹è¯•éŸ©è¯­è§„èŒƒåŒ– ===")

    # æµ‹è¯•1: å¸¦ç©ºæ ¼çš„éŸ©è¯­
    text1 = "ì•ˆë…• í•˜ì„¸ìš”"
    normalized1 = normalize_korean(text1)
    print(f"åŸæ–‡: '{text1}'")
    print(f"è§„èŒƒåŒ–: '{normalized1}'")
    print(f"é•¿åº¦: {len(normalized1)} (åº”è¯¥æ˜¯5)")
    assert normalized1 == "ì•ˆë…•í•˜ì„¸ìš”", f"è§„èŒƒåŒ–å¤±è´¥: {normalized1}"
    assert len(normalized1) == 5, f"é•¿åº¦é”™è¯¯: {len(normalized1)}"

    # æµ‹è¯•2: å¸¦æ ‡ç‚¹çš„éŸ©è¯­
    text2 = "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤."
    normalized2 = normalize_korean(text2)
    print(f"\nåŸæ–‡: '{text2}'")
    print(f"è§„èŒƒåŒ–: '{normalized2}'")
    print(f"é•¿åº¦: {len(normalized2)}")

    # æµ‹è¯•3: æ··åˆç©ºæ ¼å’Œæ ‡ç‚¹
    text3 = "í° ì˜¤ë¹ ? ê·¸ë˜!"
    normalized3 = normalize_korean(text3)
    print(f"\nåŸæ–‡: '{text3}'")
    print(f"è§„èŒƒåŒ–: '{normalized3}'")
    print(f"é•¿åº¦: {len(normalized3)}")

    print("\nâœ… éŸ©è¯­è§„èŒƒåŒ–æµ‹è¯•é€šè¿‡")


def test_japanese_normalization():
    """æµ‹è¯•æ—¥è¯­è§„èŒƒåŒ–"""
    print("\n=== æµ‹è¯•æ—¥è¯­è§„èŒƒåŒ– ===")

    # æµ‹è¯•1: å¹³å‡å
    text1 = "ã“ã‚“ã«ã¡ã¯ ä¸–ç•Œ"
    normalized1 = normalize_japanese(text1)
    print(f"åŸæ–‡: '{text1}'")
    print(f"è§„èŒƒåŒ–: '{normalized1}'")
    print(f"é•¿åº¦: {len(normalized1)}")

    # æµ‹è¯•2: ç‰‡å‡å
    text2 = "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ ã§ã™"
    normalized2 = normalize_japanese(text2)
    print(f"\nåŸæ–‡: '{text2}'")
    print(f"è§„èŒƒåŒ–: '{normalized2}'")
    print(f"é•¿åº¦: {len(normalized2)}")

    # æµ‹è¯•3: æ··åˆï¼ˆå¹³å‡å+ç‰‡å‡å+æ±‰å­—ï¼‰
    text3 = "ç§ã¯å­¦ç”Ÿã§ã™ã€‚"
    normalized3 = normalize_japanese(text3)
    print(f"\nåŸæ–‡: '{text3}'")
    print(f"è§„èŒƒåŒ–: '{normalized3}'")
    print(f"é•¿åº¦: {len(normalized3)}")

    print("\nâœ… æ—¥è¯­è§„èŒƒåŒ–æµ‹è¯•é€šè¿‡")


def test_count_text_length():
    """æµ‹è¯•å¤šè¯­è¨€é•¿åº¦è®¡ç®—"""
    print("\n=== æµ‹è¯•å¤šè¯­è¨€é•¿åº¦è®¡ç®— ===")

    # éŸ©è¯­
    korean_text = "ì•ˆë…• í•˜ì„¸ìš”"
    korean_len = count_text_length(korean_text, "ko")
    print(f"éŸ©è¯­: '{korean_text}' -> é•¿åº¦: {korean_len}")
    assert korean_len == 5, f"éŸ©è¯­é•¿åº¦è®¡ç®—é”™è¯¯: {korean_len}"

    korean_len2 = count_text_length(korean_text, "korean")
    assert korean_len2 == 5, f"éŸ©è¯­é•¿åº¦è®¡ç®—é”™è¯¯ (å…³é”®è¯'korean'): {korean_len2}"

    korean_len3 = count_text_length(korean_text, "éŸ©æ–‡")
    assert korean_len3 == 5, f"éŸ©è¯­é•¿åº¦è®¡ç®—é”™è¯¯ (å…³é”®è¯'éŸ©æ–‡'): {korean_len3}"

    # æ—¥è¯­
    japanese_text = "ã“ã‚“ã«ã¡ã¯ ä¸–ç•Œ"
    japanese_len = count_text_length(japanese_text, "ja")
    print(f"æ—¥è¯­: '{japanese_text}' -> é•¿åº¦: {japanese_len}")

    japanese_len2 = count_text_length(japanese_text, "japanese")
    japanese_len3 = count_text_length(japanese_text, "æ—¥æ–‡")

    # è‹±è¯­
    english_text = "Hello world"
    english_len = count_text_length(english_text, "en")
    print(f"è‹±è¯­: '{english_text}' -> é•¿åº¦: {english_len}")
    assert english_len == 2, f"è‹±è¯­é•¿åº¦è®¡ç®—é”™è¯¯: {english_len}"

    # ä¸­æ–‡
    chinese_text = "ä½ å¥½ ä¸–ç•Œ"
    chinese_len = count_text_length(chinese_text, "zh")
    print(f"ä¸­æ–‡: '{chinese_text}' -> é•¿åº¦: {chinese_len}")
    assert chinese_len == 4, f"ä¸­æ–‡é•¿åº¦è®¡ç®—é”™è¯¯: {chinese_len}"

    print("\nâœ… å¤šè¯­è¨€é•¿åº¦è®¡ç®—æµ‹è¯•é€šè¿‡")


def test_translation_length_check():
    """æµ‹è¯•ç¿»è¯‘é•¿åº¦æ£€æŸ¥"""
    print("\n=== æµ‹è¯•ç¿»è¯‘é•¿åº¦æ£€æŸ¥ ===")

    # æµ‹è¯•: ä¸­æ–‡ -> éŸ©è¯­
    source = "ä½ å¥½"  # 2ä¸ªæ±‰å­—
    target_ok = "ì•ˆë…•í•˜ì„¸ìš”"  # 5ä¸ªéŸ©æ–‡å­—ç¬¦ (2.5å€ï¼Œè¶…è¿‡1.2å€)
    target_long = "ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°‘ìŠµë‹ˆë‹¤"  # 11ä¸ªéŸ©æ–‡å­—ç¬¦ (5.5å€)

    is_too_long_ok, src_len, tgt_len, ratio = check_translation_length(
        source, target_ok, "ko", max_ratio=1.2
    )
    print(f"\nä¸­æ–‡ '{source}' ({src_len}å­—) -> éŸ©è¯­ '{target_ok}' ({tgt_len}å­—)")
    print(f"æ¯”ä¾‹: {ratio:.2f}, è¶…é•¿: {is_too_long_ok}")

    is_too_long, src_len2, tgt_len2, ratio2 = check_translation_length(
        source, target_long, "ko", max_ratio=1.2
    )
    print(f"\nä¸­æ–‡ '{source}' ({src_len2}å­—) -> éŸ©è¯­ '{target_long}' ({tgt_len2}å­—)")
    print(f"æ¯”ä¾‹: {ratio2:.2f}, è¶…é•¿: {is_too_long}")

    assert is_too_long == True, "åº”è¯¥æ£€æµ‹åˆ°è¶…é•¿"

    print("\nâœ… ç¿»è¯‘é•¿åº¦æ£€æŸ¥æµ‹è¯•é€šè¿‡")


def test_real_korean_subtitle():
    """æµ‹è¯•çœŸå®éŸ©è¯­å­—å¹•"""
    print("\n=== æµ‹è¯•çœŸå®éŸ©è¯­å­—å¹• ===")

    # æ¥è‡ª srt_kor.srt çš„çœŸå®ä¾‹å­
    subtitles = [
        "ì•ˆë…•",
        "ë‚œ ë„¤ í°ì˜¤ë¹ ì•¼",
        "ì§€ê¸ˆì€",
        "ì‘ì€ í˜„ì¥ ì†Œì¥ì´ì§€",
        "í°ì˜¤ë¹ ?",
        "ê·¸ë˜"
    ]

    for subtitle in subtitles:
        length = count_korean_length(subtitle)
        print(f"'{subtitle}' -> é•¿åº¦: {length}")

    print("\nâœ… çœŸå®éŸ©è¯­å­—å¹•æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•éŸ©è¯­å’Œæ—¥è¯­æ–‡æœ¬å¤„ç†...")

    test_korean_normalization()
    test_japanese_normalization()
    test_count_text_length()
    test_translation_length_check()
    test_real_korean_subtitle()

    print("\n" + "="*50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*50)
