# è¿ç§»åˆ° Ollama ç¿»è¯‘æ–¹æ¡ˆ

## æ›´æ–°æ—¥æœŸ
2025-12-25

## å˜æ›´æ‘˜è¦

ä» **HuggingFace Transformers**ï¼ˆqwen_inference ç¯å¢ƒï¼‰è¿ç§»åˆ° **Ollama**ï¼ˆui ç¯å¢ƒï¼‰è¿›è¡Œæ‰¹é‡ç¿»è¯‘ã€‚

### ä¸»è¦ä¼˜åŠ¿

1. **æ€§èƒ½æå‡**
   - å¼‚æ­¥å¹¶å‘ç¿»è¯‘ï¼Œå……åˆ†åˆ©ç”¨ GPU æ‰¹å¤„ç†èƒ½åŠ›
   - 10-20 å¥è¯å¯åœ¨å‡ ç§’å†…å¹¶å‘å®Œæˆ

2. **ç®€åŒ–éƒ¨ç½²**
   - æ— éœ€ä¸‹è½½å’Œç®¡ç†å¤§å‹æ¨¡å‹æ–‡ä»¶ï¼ˆ4-5GBï¼‰
   - Ollama è‡ªåŠ¨ç®¡ç†æ¨¡å‹
   - æ›´å°‘çš„ç£ç›˜ç©ºé—´å ç”¨

3. **æ›´å¥½çš„èµ„æºåˆ©ç”¨**
   - Ollama ä¼˜åŒ–çš„æ˜¾å­˜ç®¡ç†
   - æ›´é«˜çš„å¹¶å‘èƒ½åŠ›
   - æ›´ç¨³å®šçš„æ¨ç†æœåŠ¡

---

## æŠ€æœ¯æ¶æ„

### æ—§æ–¹æ¡ˆï¼ˆHuggingFaceï¼‰

```
main.py
  â†“ è°ƒç”¨
batch_retranslate.py (qwen_inference ç¯å¢ƒ)
  â†“ åŠ è½½
Qwen3-4B-FP8 æœ¬åœ°æ¨¡å‹æ–‡ä»¶ (5GB)
  â†“ å¤šè¿›ç¨‹
é€å¥ç¿»è¯‘ï¼ˆä¸²è¡Œæˆ–å°‘é‡å¹¶å‘ï¼‰
```

**é—®é¢˜**:
- æ¨¡å‹åŠ è½½æ…¢ï¼ˆ15-30ç§’ï¼‰
- å•è¿›ç¨‹å¤„ç†æ•ˆç‡ä½
- æ¨¡å‹æ–‡ä»¶ç®¡ç†å¤æ‚
- æ˜¾å­˜å ç”¨é«˜å³°æœŸä¸ç¨³å®š

### æ–°æ–¹æ¡ˆï¼ˆOllamaï¼‰

```
main.py
  â†“ è°ƒç”¨
batch_retranslate_ollama.py (ui ç¯å¢ƒ)
  â†“ HTTP API
Ollama æœåŠ¡ (localhost:11434)
  â†“ è‡ªåŠ¨ç®¡ç†
qwen3:4b æ¨¡å‹
  â†“ å¼‚æ­¥å¹¶å‘
æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡åŒæ—¶æäº¤ï¼ŒOllama æ‰¹å¤„ç†
```

**ä¼˜åŠ¿**:
- Ollama åå°è¿è¡Œï¼Œæ— å†·å¯åŠ¨
- å¼‚æ­¥å¹¶å‘ï¼Œæ‰€æœ‰ä»»åŠ¡åŒæ—¶æäº¤
- Ollama è‡ªåŠ¨ä¼˜åŒ–æ‰¹å¤„ç†
- æ˜¾å­˜ç®¡ç†æ›´é«˜æ•ˆ

---

## æ–‡ä»¶å˜æ›´

### æ–°å¢æ–‡ä»¶

1. **batch_retranslate_ollama.py**
   - æ›¿ä»£ batch_retranslate.py
   - ä½¿ç”¨ AsyncOpenAI è¿æ¥ Ollama
   - å¼‚æ­¥å¹¶å‘ç¿»è¯‘
   - è‡ªåŠ¨æ£€æµ‹å’Œå¯åŠ¨ Ollama æœåŠ¡

2. **test_ollama_config.json**
   - æµ‹è¯•é…ç½®æ–‡ä»¶

3. **test_ollama_translation.bat**
   - æµ‹è¯•æ‰¹å¤„ç†æ–‡ä»¶

4. **OLLAMA_MIGRATION.md**
   - æœ¬æ–‡æ¡£

### ä¿®æ”¹æ–‡ä»¶

1. **main.py**
   - ä» qwen_inference ç¯å¢ƒæ”¹ä¸º ui ç¯å¢ƒ
   - ä» batch_retranslate.py æ”¹ä¸º batch_retranslate_ollama.py
   - æ›´æ–°æ—¥å¿—ä¿¡æ¯

### ä¿ç•™æ–‡ä»¶ï¼ˆä¸å†ä½¿ç”¨ï¼‰

1. **batch_retranslate.py**
   - ä¿ç•™ä½œä¸ºå¤‡ä»½
   - å¦‚æœ Ollama ä¸å¯ç”¨ï¼Œå¯ä»¥å›é€€

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. Ollama æœåŠ¡æ£€æµ‹å’Œè‡ªåŠ¨å¯åŠ¨

```python
def check_ollama_running() -> bool:
    """æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦åœ¨è¿è¡Œ"""
    for proc in psutil.process_iter(['name']):
        if 'ollama' in proc.info['name'].lower():
            return True
    return False

def start_ollama_server():
    """å¯åŠ¨ Ollama æœåŠ¡å™¨ï¼ˆåå°è¿è¡Œï¼‰"""
    subprocess.Popen(['ollama', 'serve'], ...)
```

**å·¥ä½œæµç¨‹**:
1. æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
2. å¦‚æœæœªè¿è¡Œï¼Œåå°å¯åŠ¨ `ollama serve`
3. ç­‰å¾… 3 ç§’è®©æœåŠ¡å™¨å¯åŠ¨
4. ç»§ç»­æ‰§è¡Œç¿»è¯‘

### 2. å¼‚æ­¥å¹¶å‘ç¿»è¯‘

```python
async def batch_translate(tasks, model="qwen3:4b"):
    client = AsyncOpenAI(
        base_url='http://localhost:11434/v1',
        api_key='ollama'
    )
    
    # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
    async_tasks = [
        translate_sentence(client, task["source"], ...)
        for task in tasks
    ]
    
    # å¹¶å‘æ‰§è¡Œ
    results = await asyncio.gather(*async_tasks)
```

**ç‰¹ç‚¹**:
- æ‰€æœ‰ä»»åŠ¡åŒæ—¶æäº¤
- Ollama æ ¹æ® GPU èƒ½åŠ›è‡ªåŠ¨æ‰¹å¤„ç†
- å……åˆ†åˆ©ç”¨ 5070 çš„ç®—åŠ›

### 3. JSON æ ¼å¼æå–

```python
def extract_translation_from_json(text, fallback=""):
    """ä» JSON æˆ–æ–‡æœ¬ä¸­æå–ç¿»è¯‘ç»“æœ"""
    # æ”¯æŒå¤šç§æ ¼å¼
    # 1. {"tr": "ç¿»è¯‘"}
    # 2. çº¯æ–‡æœ¬
    # 3. å¸¦å¼•å·çš„æ–‡æœ¬
```

---

## ç¯å¢ƒè¦æ±‚

### ui ç¯å¢ƒä¾èµ–

```bash
conda activate ui
pip install ollama openai psutil
```

### Ollama å®‰è£…

**Windows**:
```bash
# ä¸‹è½½å¹¶å®‰è£…
https://ollama.com/download

# æ‹‰å–æ¨¡å‹
ollama pull qwen3:4b
```

**éªŒè¯**:
```bash
ollama list
# åº”è¯¥çœ‹åˆ° qwen3:4b
```

---

## ä½¿ç”¨æ–¹æ³•

### æµ‹è¯•ç¿»è¯‘

```bash
cd C:\workspace\ai_editing\workspace\LocalClip-Editor\backend
test_ollama_translation.bat
```

### åœ¨åº”ç”¨ä¸­ä½¿ç”¨

æ— éœ€ä»»ä½•æ”¹åŠ¨ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
1. ä½¿ç”¨ ui ç¯å¢ƒè¿è¡Œ batch_retranslate_ollama.py
2. æ£€æµ‹ Ollama æœåŠ¡
3. å¦‚æœæœªè¿è¡Œï¼Œè‡ªåŠ¨å¯åŠ¨
4. å¼‚æ­¥å¹¶å‘ç¿»è¯‘æ‰€æœ‰ä»»åŠ¡
5. è¿”å›ç»“æœç»™åº”ç”¨

---

## æ€§èƒ½å¯¹æ¯”

### æ—§æ–¹æ¡ˆï¼ˆHuggingFaceï¼‰

| æŒ‡æ ‡ | å€¼ |
|-----|---|
| æ¨¡å‹åŠ è½½æ—¶é—´ | 15-30ç§’ |
| å•å¥ç¿»è¯‘æ—¶é—´ | 2-4ç§’ |
| 10å¥æ€»æ—¶é—´ | 20-40ç§’ |
| å¹¶å‘èƒ½åŠ› | ä½ï¼ˆå•è¿›ç¨‹æˆ–å°‘é‡è¿›ç¨‹ï¼‰ |
| æ˜¾å­˜å ç”¨ | 6GBï¼ˆQwen3-4B-FP8ï¼‰ |

### æ–°æ–¹æ¡ˆï¼ˆOllamaï¼‰

| æŒ‡æ ‡ | å€¼ |
|-----|---|
| é¦–æ¬¡å¯åŠ¨ | 3ç§’ï¼ˆå¦‚éœ€å¯åŠ¨æœåŠ¡ï¼‰ |
| åç»­å¯åŠ¨ | 0ç§’ï¼ˆæœåŠ¡å¸¸é©»ï¼‰ |
| å•å¥ç¿»è¯‘æ—¶é—´ | 1-2ç§’ |
| 10å¥æ€»æ—¶é—´ | 3-6ç§’ï¼ˆå¹¶å‘ï¼‰ |
| å¹¶å‘èƒ½åŠ› | é«˜ï¼ˆå¼‚æ­¥æ— é™å¹¶å‘ï¼‰ |
| æ˜¾å­˜å ç”¨ | åŠ¨æ€ä¼˜åŒ– |

**æ€§èƒ½æå‡**: 3-7å€

---

## æ—¥å¿—è¾“å‡º

### å¯åŠ¨é˜¶æ®µ

```
[Retranslate] ä½¿ç”¨ Python: C:\Users\7\miniconda3\envs\ui\python.exe
[Retranslate] è„šæœ¬: batch_retranslate_ollama.py
[Retranslate] é…ç½®: ...
[Retranslate] æ¨¡å‹: Ollama qwen3:4bï¼ˆå¼‚æ­¥å¹¶å‘ï¼‰
[Retranslate] è¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: 12345

[Ollama] âœ“ æœåŠ¡å™¨å·²åœ¨è¿è¡Œ
```

### ç¿»è¯‘é˜¶æ®µ

```
============================================================
[æ‰¹é‡ç¿»è¯‘] å¼€å§‹æ‰¹é‡ç¿»è¯‘
  ä»»åŠ¡æ•°é‡: 13
  æ¨¡å‹: qwen3:4b
  å¹¶å‘æ¨¡å¼: å¼‚æ­¥
============================================================

[æ‰¹é‡ç¿»è¯‘] å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç¿»è¯‘ä»»åŠ¡...

[ç¿»è¯‘ç»“æœ]
[1/13] âœ“ retrans-3: æ˜¯ä¸ªå°åŒ…å·¥å¤´ -> ì‘ì€ í˜„ì¥ ì†Œì¥ì´ì§€ (1.85s)
[2/13] âœ“ retrans-4: å¤§å“¥ -> í°ì˜¤ë¹  (1.92s)
...
[13/13] âœ“ retrans-45: åƒé¥­å» -> ë°¥ ë¨¹ìœ¼ëŸ¬ ê°€ (2.01s)

============================================================
[æ‰¹é‡ç¿»è¯‘] å…¨éƒ¨å®Œæˆï¼
  æ€»è®¡: 13 ä¸ªä»»åŠ¡
  æ€»è€—æ—¶: 5.32 ç§’
  å¹³å‡é€Ÿåº¦: 0.41 ç§’/å¥
============================================================
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: Ollama æœªå®‰è£…

**ç—‡çŠ¶**:
```
[Ollama] âŒ é”™è¯¯: æ‰¾ä¸åˆ° ollama å‘½ä»¤
```

**è§£å†³**:
```bash
# å®‰è£… Ollama
https://ollama.com/download

# æ‹‰å–æ¨¡å‹
ollama pull qwen3:4b
```

### é—®é¢˜2: æ¨¡å‹æœªä¸‹è½½

**ç—‡çŠ¶**:
```
Error: model 'qwen3:4b' not found
```

**è§£å†³**:
```bash
ollama pull qwen3:4b
```

### é—®é¢˜3: ç«¯å£è¢«å ç”¨

**ç—‡çŠ¶**:
```
Error: bind: address already in use
```

**è§£å†³**:
```bash
# æŸ¥æ‰¾å ç”¨ 11434 ç«¯å£çš„è¿›ç¨‹
netstat -ano | findstr :11434

# ç»“æŸè¯¥è¿›ç¨‹æˆ–ä½¿ç”¨å…¶ä»–ç«¯å£
```

### é—®é¢˜4: UI ç¯å¢ƒç¼ºå°‘ä¾èµ–

**ç—‡çŠ¶**:
```
ModuleNotFoundError: No module named 'ollama'
```

**è§£å†³**:
```bash
conda activate ui
pip install ollama openai psutil
```

---

## å›é€€æ–¹æ¡ˆ

å¦‚æœ Ollama æ–¹æ¡ˆæœ‰é—®é¢˜ï¼Œå¯ä»¥å›é€€åˆ°æ—§æ–¹æ¡ˆï¼š

### ä¿®æ”¹ main.py

```python
# æ”¹å› qwen_inference ç¯å¢ƒ
qwen_env_python = r"C:\Users\7\miniconda3\envs\qwen_inference\python.exe"

# æ”¹å›æ—§è„šæœ¬
batch_retranslate_script = "batch_retranslate.py"
```

---

## æ€»ç»“

### âœ… ä¼˜åŠ¿

1. **æ€§èƒ½**: 3-7å€æå‡
2. **ç®€åŒ–**: æ— éœ€ç®¡ç†å¤§å‹æ¨¡å‹æ–‡ä»¶
3. **ç¨³å®š**: Ollama ä¼˜åŒ–çš„æ¨ç†æœåŠ¡
4. **å¹¶å‘**: å……åˆ†åˆ©ç”¨ GPU æ‰¹å¤„ç†

### âš ï¸ æ³¨æ„äº‹é¡¹

1. éœ€è¦å®‰è£… Ollama
2. éœ€è¦æ‹‰å– qwen3:4b æ¨¡å‹
3. é¦–æ¬¡å¯åŠ¨éœ€è¦ç­‰å¾… 3 ç§’

### ğŸš€ ä¸‹ä¸€æ­¥

1. æµ‹è¯• Ollama ç¿»è¯‘åŠŸèƒ½
2. åœ¨åº”ç”¨ä¸­éªŒè¯å®Œæ•´æµç¨‹
3. ç›‘æ§æ€§èƒ½å’Œè´¨é‡

---

**æ›´æ–°æ—¥æœŸ**: 2025-12-25
**çŠ¶æ€**: âœ… å·²å®Œæˆï¼Œç­‰å¾…æµ‹è¯•
**ç¯å¢ƒ**: ui + Ollama
**æ¨¡å‹**: qwen3:4b
