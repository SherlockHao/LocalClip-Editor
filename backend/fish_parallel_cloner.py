"""
å¹¶è¡Œå…‹éš†å¼•æ“ - Layer 1 ä¼˜åŒ–
ä½¿ç”¨è¿›ç¨‹æ± å®ç°è·¨è¯´è¯äººå¹¶è¡Œå¤„ç†

ä½œè€…ï¼šClaude (ç¬¬äºŒé˜¶æ®µä¼˜åŒ–)
"""
import os
import psutil
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, List
from loguru import logger
from fish_worker_process import worker_process_main, init_worker_process


# fish-speech ä»“åº“è·¯å¾„
FISH_SPEECH_DIR = "/Users/yiya_workstation/Documents/ai_editing/fish-speech"
CHECKPOINT_DIR = os.path.join(FISH_SPEECH_DIR, "checkpoints/openaudio-s1-mini")


class ParallelFishCloner:
    """
    å¹¶è¡Œè¯­éŸ³å…‹éš†å™¨ - ç¬¬äºŒé˜¶æ®µä¼˜åŒ–

    æ ¸å¿ƒä¼˜åŠ¿ï¼š
    - âœ… æ¶ˆé™¤æ¨¡å‹é‡å¤åŠ è½½ï¼ˆæ¯ä¸ª worker ä»…åŠ è½½ä¸€æ¬¡ï¼‰
    - âœ… è·¨è¯´è¯äººå¹¶è¡Œå¤„ç†ï¼ˆ3 ä¸ª worker åŒæ—¶å·¥ä½œï¼‰
    - âœ… æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼ˆä»»åŠ¡å‡åŒ€åˆ†é…ï¼‰
    - âœ… é›†æˆ Layer 2 å’Œ Layer 3 ä¼˜åŒ–
    - âœ… è‡ªåŠ¨å†…å­˜ç®¡ç†å’Œé™çº§

    é¢„æœŸåŠ é€Ÿï¼š5-7xï¼ˆç›¸æ¯”åŸå§‹é¡ºåºæ¨¡å¼ï¼‰
    """

    def __init__(
        self,
        num_workers: int = None,
        checkpoint_path: str = CHECKPOINT_DIR,
        batch_size: int = 10,
        io_threads: int = 2
    ):
        """
        åˆå§‹åŒ–å¹¶è¡Œå…‹éš†å™¨

        Args:
            num_workers: Worker è¿›ç¨‹æ•°ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            checkpoint_path: Fish-Speech æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
            batch_size: DAC æ‰¹é‡è§£ç å¤§å°
            io_threads: æ¯ä¸ª worker çš„ I/O çº¿ç¨‹æ•°
        """
        self.checkpoint_path = checkpoint_path
        self.batch_size = batch_size
        self.io_threads = io_threads

        # è‡ªåŠ¨æ£€æµ‹æœ€ä¼˜ worker æ•°é‡
        if num_workers is None:
            self.num_workers = self._auto_detect_workers()
        else:
            self.num_workers = num_workers

        logger.info(f"ğŸš€ å¹¶è¡Œå…‹éš†å™¨åˆå§‹åŒ–: {self.num_workers} ä¸ª worker è¿›ç¨‹")

    def _auto_detect_workers(self) -> int:
        """
        æ ¹æ®å¯ç”¨å†…å­˜è‡ªåŠ¨æ£€æµ‹æœ€ä¼˜ worker æ•°é‡

        ä¼°ç®—ï¼š
        - æ¯ä¸ª worker éœ€è¦çº¦ 5-6GB å†…å­˜ï¼ˆæ¨¡å‹ + æ¨ç†ï¼‰
        - Mac mini M4 (24GB)ï¼šæœ€å¤š 3 ä¸ª worker
        - é¢„ç•™ 9GB ç³»ç»Ÿå†…å­˜

        Returns:
            æ¨èçš„ worker æ•°é‡
        """
        available_mem_gb = psutil.virtual_memory().available / (1024**3)

        logger.info(f"ğŸ’¾ å¯ç”¨å†…å­˜: {available_mem_gb:.1f} GB")

        if available_mem_gb >= 15:
            # å……è¶³å†…å­˜ï¼š3 ä¸ª worker
            num_workers = 3
        elif available_mem_gb >= 10:
            # ä¸­ç­‰å†…å­˜ï¼š2 ä¸ª worker
            num_workers = 2
        else:
            # å†…å­˜ç´§å¼ ï¼š1 ä¸ª workerï¼ˆé™çº§ä½†ä»æ¯”åŸå§‹æ¨¡å¼å¿«ï¼‰
            num_workers = 1

        logger.info(
            f"âš™ï¸  è‡ªåŠ¨æ£€æµ‹: ä½¿ç”¨ {num_workers} ä¸ª worker "
            f"(æ¯ä¸ªçº¦å ç”¨ 5GB, é¢„ç•™ 9GB ç³»ç»Ÿå†…å­˜)"
        )

        return num_workers

    def batch_generate_audio(
        self,
        tasks: List[Dict],
        speaker_npy_files: Dict[int, str],
        speaker_references: Dict[int, Dict],
        output_dir: str,
        script_dir: str = None  # ä¸ºäº†å…¼å®¹åŸæ¥å£ï¼Œä½†ä¸ä½¿ç”¨
    ) -> Dict[int, str]:
        """
        æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è¯­éŸ³ç‰‡æ®µï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ [{"speaker_id": int, "target_text": str, "segment_index": int}, ...]
            speaker_npy_files: è¯´è¯äºº npy æ–‡ä»¶å­—å…¸ {speaker_id: npy_path}
            speaker_references: è¯´è¯äººå‚è€ƒä¿¡æ¯å­—å…¸ {speaker_id: {"reference_text": str, ...}}
            output_dir: è¾“å‡ºç›®å½•
            script_dir: è„šæœ¬ç›®å½•ï¼ˆå…¼å®¹å‚æ•°ï¼Œå¹¶è¡Œæ¨¡å¼ä¸ä½¿ç”¨ï¼‰

        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶å­—å…¸ {segment_index: file_path}
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸŸ [å¹¶è¡Œç”Ÿæˆ] å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(tasks)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
        logger.info(f"ğŸš€ ä½¿ç”¨ {self.num_workers} ä¸ª worker è¿›ç¨‹å¹¶è¡Œå¤„ç†")
        logger.info(f"{'='*80}\n")

        os.makedirs(output_dir, exist_ok=True)

        # ==================================================================
        # Step 1: æŒ‰è¯´è¯äººåˆ†ç»„ä»»åŠ¡
        # ==================================================================
        tasks_by_speaker = self._group_by_speaker(tasks)
        logger.info(f"ğŸ“Š å…±æœ‰ {len(tasks_by_speaker)} ä¸ªè¯´è¯äºº")

        for speaker_id, speaker_tasks in tasks_by_speaker.items():
            logger.info(f"  - è¯´è¯äºº {speaker_id}: {len(speaker_tasks)} ä¸ªç‰‡æ®µ")

        # ==================================================================
        # Step 2: è´Ÿè½½å‡è¡¡åˆ†é…ä»»åŠ¡
        # ==================================================================
        worker_assignments = self._balance_workload(
            tasks_by_speaker,
            self.num_workers
        )

        logger.info(f"\nğŸ“‹ ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ:")
        for worker_id, speaker_ids in enumerate(worker_assignments):
            total_tasks = sum(
                len(tasks_by_speaker[sid]) for sid in speaker_ids
            )
            logger.info(
                f"  Worker #{worker_id}: è¯´è¯äºº {speaker_ids} "
                f"({total_tasks} ä¸ªç‰‡æ®µ)"
            )

        # ==================================================================
        # Step 3: åˆ›å»ºè¿›ç¨‹æ± å¹¶å¹¶è¡Œæ‰§è¡Œ
        # ==================================================================
        logger.info(f"\nğŸš€ å¯åŠ¨ {self.num_workers} ä¸ª worker è¿›ç¨‹...\n")

        all_generated_files = {}

        # ä½¿ç”¨ spawn æ–¹å¼åˆ›å»ºè¿›ç¨‹ï¼ˆMPS è¦æ±‚ï¼‰
        import multiprocessing
        ctx = multiprocessing.get_context('spawn')

        with ProcessPoolExecutor(
            max_workers=self.num_workers,
            mp_context=ctx,
            initializer=init_worker_process
        ) as executor:
            # æäº¤æ‰€æœ‰ worker ä»»åŠ¡
            futures = []
            for worker_id, speaker_ids in enumerate(worker_assignments):
                if not speaker_ids:
                    continue  # è·³è¿‡ç©ºåˆ†é…

                future = executor.submit(
                    worker_process_main,
                    worker_id=worker_id,
                    assigned_speaker_ids=speaker_ids,
                    tasks=tasks,
                    speaker_npy_files=speaker_npy_files,
                    speaker_references=speaker_references,
                    output_dir=output_dir,
                    checkpoint_path=self.checkpoint_path,
                    batch_size=self.batch_size,
                    io_threads=self.io_threads
                )
                futures.append((worker_id, future))

            # ç­‰å¾…æ‰€æœ‰ worker å®Œæˆå¹¶æ”¶é›†ç»“æœ
            for worker_id, future in futures:
                try:
                    generated_files = future.result()
                    all_generated_files.update(generated_files)
                    logger.info(
                        f"âœ… Worker #{worker_id} å®Œæˆ: "
                        f"ç”Ÿæˆ {len(generated_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶"
                    )
                except Exception as e:
                    logger.error(f"âŒ Worker #{worker_id} å¤±è´¥: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ‰ å¹¶è¡Œç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(all_generated_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        logger.info(f"{'='*80}\n")

        return all_generated_files

    def _group_by_speaker(self, tasks: List[Dict]) -> Dict[int, List[Dict]]:
        """
        æŒ‰è¯´è¯äººåˆ†ç»„ä»»åŠ¡

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨

        Returns:
            åˆ†ç»„åçš„ä»»åŠ¡å­—å…¸ {speaker_id: [task1, task2, ...]}
        """
        tasks_by_speaker = {}
        for task in tasks:
            speaker_id = task['speaker_id']
            if speaker_id not in tasks_by_speaker:
                tasks_by_speaker[speaker_id] = []
            tasks_by_speaker[speaker_id].append(task)

        return tasks_by_speaker

    def _balance_workload(
        self,
        tasks_by_speaker: Dict[int, List[Dict]],
        num_workers: int
    ) -> List[List[int]]:
        """
        è´Ÿè½½å‡è¡¡ç®—æ³• - è´ªå¿ƒç­–ç•¥

        ç›®æ ‡ï¼šå°†è¯´è¯äººåˆ†é…ç»™å„ä¸ª workerï¼Œä½¿å„ worker çš„ä»»åŠ¡æ•°å°½é‡å‡è¡¡

        ç­–ç•¥ï¼š
        1. æŒ‰ä»»åŠ¡æ•°é‡å¯¹è¯´è¯äººé™åºæ’åº
        2. æ¯æ¬¡å°†ä»»åŠ¡æœ€å¤šçš„è¯´è¯äººåˆ†é…ç»™å½“å‰è´Ÿè½½æœ€å°çš„ worker

        Args:
            tasks_by_speaker: æŒ‰è¯´è¯äººåˆ†ç»„çš„ä»»åŠ¡
            num_workers: Worker æ•°é‡

        Returns:
            åˆ†é…æ–¹æ¡ˆ [[speaker_id1, speaker_id2], [speaker_id3], ...]
        """
        # æŒ‰ä»»åŠ¡æ•°é‡é™åºæ’åºè¯´è¯äºº
        sorted_speakers = sorted(
            tasks_by_speaker.keys(),
            key=lambda sid: len(tasks_by_speaker[sid]),
            reverse=True
        )

        # åˆå§‹åŒ– worker åˆ†é…å’Œè´Ÿè½½ç»Ÿè®¡
        worker_assignments = [[] for _ in range(num_workers)]
        worker_loads = [0] * num_workers

        # è´ªå¿ƒåˆ†é…
        for speaker_id in sorted_speakers:
            task_count = len(tasks_by_speaker[speaker_id])

            # æ‰¾åˆ°å½“å‰è´Ÿè½½æœ€å°çš„ worker
            min_load_worker = worker_loads.index(min(worker_loads))

            # åˆ†é…ç»™è¯¥ worker
            worker_assignments[min_load_worker].append(speaker_id)
            worker_loads[min_load_worker] += task_count

        return worker_assignments

    # ==================================================================
    # å…¼å®¹æ¥å£ - æ”¯æŒæ‰¹é‡ç¼–ç 
    # ==================================================================
    def batch_encode_speakers(
        self,
        speaker_references: Dict,
        output_dir: str
    ) -> Dict[int, str]:
        """
        æ‰¹é‡ç¼–ç æ‰€æœ‰è¯´è¯äººçš„å‚è€ƒéŸ³é¢‘

        æ³¨æ„ï¼šç¼–ç é˜¶æ®µä¸éœ€è¦å¹¶è¡Œï¼ˆé€Ÿåº¦å·²ç»å¾ˆå¿«ï¼‰
        å¤ç”¨åŸæœ‰çš„ FishBatchCloner å®ç°

        Args:
            speaker_references: è¯´è¯äººå‚è€ƒä¿¡æ¯
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ç¼–ç ç»“æœ {speaker_id: npy_file_path}
        """
        from fish_batch_cloner import FishBatchCloner

        logger.info("ğŸ”„ ä½¿ç”¨é¡ºåºæ¨¡å¼è¿›è¡Œæ‰¹é‡ç¼–ç ï¼ˆç¼–ç é€Ÿåº¦å·²è¶³å¤Ÿå¿«ï¼‰")
        cloner = FishBatchCloner(
            fish_speech_dir=FISH_SPEECH_DIR,
            checkpoint_dir=self.checkpoint_path
        )
        return cloner.batch_encode_speakers(speaker_references, output_dir)
