"""
Fish-Speech æ‰¹é‡è¯­éŸ³å…‹éš†æ¨¡å—
ä½¿ç”¨ fish-speech/batch_inference.py çš„æ‰¹é‡æ¨ç†èƒ½åŠ›
"""
import os
import json
import subprocess
import shutil
from pathlib import Path

# fish-speech ä»“åº“è·¯å¾„
FISH_SPEECH_DIR = "/Users/yiya_workstation/Documents/ai_editing/fish-speech"
CHECKPOINT_DIR = os.path.join(FISH_SPEECH_DIR, "checkpoints/openaudio-s1-mini")
FISH_AUDIO_PYTHON = "/Users/yiya_workstation/miniconda3/envs/fish-speech/bin/python"


class FishBatchCloner:
    """Fish-Speech æ‰¹é‡è¯­éŸ³å…‹éš†å™¨"""

    def __init__(self, fish_speech_dir=FISH_SPEECH_DIR, checkpoint_dir=CHECKPOINT_DIR):
        self.fish_speech_dir = fish_speech_dir
        self.checkpoint_dir = checkpoint_dir
        self.python_executable = FISH_AUDIO_PYTHON

    def batch_encode_speakers(self, speaker_references, output_dir):
        """
        æ‰¹é‡ç¼–ç æ‰€æœ‰è¯´è¯äººçš„å‚è€ƒéŸ³é¢‘ä¸º VQ codes

        Args:
            speaker_references: dict, {speaker_id: {"reference_audio": path, "reference_text": text, ...}}
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            dict: {speaker_id: npy_file_path}
        """
        print(f"\nğŸŸ [æ‰¹é‡ç¼–ç ] å¼€å§‹æ‰¹é‡ç¼–ç  {len(speaker_references)} ä¸ªè¯´è¯äººçš„å‚è€ƒéŸ³é¢‘...")

        os.makedirs(output_dir, exist_ok=True)

        # å‡†å¤‡æ‰¹é‡ç¼–ç è„šæœ¬
        batch_script = self._create_batch_encode_script(speaker_references, output_dir)
        script_path = os.path.abspath(os.path.join(output_dir, "batch_encode.py"))

        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(batch_script)

        # æ‰§è¡Œæ‰¹é‡ç¼–ç è„šæœ¬
        cmd = [self.python_executable, script_path]

        env = os.environ.copy()
        env["PYTHONPATH"] = self.fish_speech_dir + (f":{env.get('PYTHONPATH', '')}" if env.get('PYTHONPATH') else '')

        try:
            print(f"æ‰§è¡Œæ‰¹é‡ç¼–ç è„šæœ¬: {script_path}")
            result = subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True,
                cwd=self.fish_speech_dir,
                env=env
            )
            print(result.stdout)

            # è¯»å–ç”Ÿæˆçš„.npyæ–‡ä»¶è·¯å¾„
            speaker_npy_files = {}
            for speaker_id in speaker_references.keys():
                npy_path = os.path.join(output_dir, f"speaker_{speaker_id}_codes.npy")
                if os.path.exists(npy_path):
                    speaker_npy_files[speaker_id] = npy_path
                    print(f"âœ… è¯´è¯äºº {speaker_id} ç¼–ç å®Œæˆ: {npy_path}")
                else:
                    print(f"âŒ è¯´è¯äºº {speaker_id} ç¼–ç å¤±è´¥: æœªæ‰¾åˆ° {npy_path}")

            return speaker_npy_files

        except subprocess.CalledProcessError as e:
            print(f"âŒ æ‰¹é‡ç¼–ç å¤±è´¥: {e.stderr}")
            raise

    def batch_generate_audio(self, tasks, speaker_npy_files, speaker_references, output_dir, script_dir=None):
        """
        æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è¯­éŸ³ç‰‡æ®µ

        Args:
            tasks: list of dict, [{"speaker_id": int, "target_text": str, "segment_index": int}, ...]
            speaker_npy_files: dict, {speaker_id: npy_file_path}
            speaker_references: dict, {speaker_id: {"reference_text": text, ...}}
            output_dir: è¾“å‡ºç›®å½•
            script_dir: è„šæœ¬ä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨output_dirï¼‰

        Returns:
            dict: {segment_index: audio_file_path}
        """
        print(f"\nğŸŸ [æ‰¹é‡ç”Ÿæˆ] å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(tasks)} ä¸ªè¯­éŸ³ç‰‡æ®µ...")

        os.makedirs(output_dir, exist_ok=True)

        # å¦‚æœæœªæŒ‡å®šè„šæœ¬ç›®å½•ï¼Œä½¿ç”¨output_dir
        if script_dir is None:
            script_dir = output_dir
        else:
            os.makedirs(script_dir, exist_ok=True)

        # æŒ‰è¯´è¯äººåˆ†ç»„ä»»åŠ¡ï¼Œä»¥æé«˜æ‰¹é‡å¤„ç†æ•ˆç‡
        tasks_by_speaker = {}
        for task in tasks:
            speaker_id = task['speaker_id']
            if speaker_id not in tasks_by_speaker:
                tasks_by_speaker[speaker_id] = []
            tasks_by_speaker[speaker_id].append(task)

        generated_audio_files = {}

        # å¯¹æ¯ä¸ªè¯´è¯äººæ‰¹é‡ç”Ÿæˆå…¶æ‰€æœ‰ç‰‡æ®µ
        for speaker_id, speaker_tasks in tasks_by_speaker.items():
            if speaker_id not in speaker_npy_files:
                print(f"âš ï¸ è¯´è¯äºº {speaker_id} æ²¡æœ‰.npyæ–‡ä»¶ï¼Œè·³è¿‡")
                continue

            print(f"\nå¤„ç†è¯´è¯äºº {speaker_id} çš„ {len(speaker_tasks)} ä¸ªç‰‡æ®µ...")

            # åˆ›å»ºè¯¥è¯´è¯äººçš„æ‰¹é‡ç”Ÿæˆè„šæœ¬
            batch_script = self._create_batch_generate_script(
                speaker_id,
                speaker_tasks,
                speaker_npy_files[speaker_id],
                speaker_references[speaker_id]["reference_text"],
                output_dir
            )

            # è„šæœ¬ä¿å­˜åˆ°script_dirï¼Œé¿å…è§¦å‘uvicorn reload
            script_path = os.path.abspath(os.path.join(script_dir, f"batch_generate_speaker_{speaker_id}.py"))
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(batch_script)

            # æ‰§è¡Œæ‰¹é‡ç”Ÿæˆè„šæœ¬
            cmd = [self.python_executable, script_path]

            env = os.environ.copy()
            env["PYTHONPATH"] = self.fish_speech_dir + (f":{env.get('PYTHONPATH', '')}" if env.get('PYTHONPATH') else '')

            try:
                print(f"æ‰§è¡Œæ‰¹é‡ç”Ÿæˆè„šæœ¬: {script_path}")
                result = subprocess.run(
                    cmd,
                    check=True,
                    capture_output=True,
                    text=True,
                    cwd=self.fish_speech_dir,
                    env=env,
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
                )
                print(result.stdout)

                # æ”¶é›†ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
                for task in speaker_tasks:
                    segment_index = task['segment_index']
                    audio_path = os.path.join(output_dir, f"segment_{segment_index:04d}.wav")
                    if os.path.exists(audio_path):
                        generated_audio_files[segment_index] = audio_path
                        print(f"âœ… ç‰‡æ®µ {segment_index} ç”Ÿæˆå®Œæˆ")
                    else:
                        print(f"âŒ ç‰‡æ®µ {segment_index} ç”Ÿæˆå¤±è´¥")

            except subprocess.CalledProcessError as e:
                print(f"âŒ è¯´è¯äºº {speaker_id} æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e.stderr}")
                continue
            except subprocess.TimeoutExpired:
                print(f"âŒ è¯´è¯äºº {speaker_id} æ‰¹é‡ç”Ÿæˆè¶…æ—¶")
                continue

        return generated_audio_files

    def _create_batch_encode_script(self, speaker_references, output_dir):
        """åˆ›å»ºæ‰¹é‡ç¼–ç è„šæœ¬"""
        # å‡†å¤‡å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬åˆ—è¡¨
        ref_audio_list = []
        ref_text_list = []
        speaker_ids = []

        for speaker_id, ref_data in speaker_references.items():
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            audio_path = os.path.abspath(ref_data["reference_audio"])
            ref_audio_list.append(audio_path)
            ref_text_list.append(ref_data["reference_text"])
            speaker_ids.append(speaker_id)

        # ç¡®ä¿è¾“å‡ºç›®å½•ä¹Ÿæ˜¯ç»å¯¹è·¯å¾„
        output_dir = os.path.abspath(output_dir)

        script = f'''#!/usr/bin/env python3
import os
import sys
import torch
import numpy as np
import torchaudio
from loguru import logger

# å¯¼å…¥ Fish Speech çš„æ¨ç†æ¨¡å—
from fish_speech.models.dac.inference import load_model as load_dac_model

# é…ç½®
CHECKPOINT_PATH = "{self.checkpoint_dir}"
OUTPUT_DIR = "{output_dir}"

REF_AUDIO_PATH_LIST = {json.dumps(ref_audio_list)}
REF_TEXT_LIST = {json.dumps(ref_text_list)}
SPEAKER_IDS = {json.dumps(speaker_ids)}

def get_device():
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        return "mps"
    else:
        return "cpu"

def main():
    device = get_device()
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {{device}}")

    # åŠ è½½ DAC æ¨¡å‹
    logger.info("æ­£åœ¨åŠ è½½ DAC æ¨¡å‹...")
    dac_model = load_dac_model(
        config_name="modded_dac_vq",
        checkpoint_path=os.path.join(CHECKPOINT_PATH, "codec.pth"),
        device=device
    )
    logger.info("âœ… DAC æ¨¡å‹åŠ è½½å®Œæˆ")

    # æ‰¹é‡ç¼–ç 
    for i, (speaker_id, ref_audio, ref_text) in enumerate(zip(SPEAKER_IDS, REF_AUDIO_PATH_LIST, REF_TEXT_LIST)):
        logger.info(f"\\næ­£åœ¨ç¼–ç è¯´è¯äºº {{speaker_id}}: {{ref_audio}}")

        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = torchaudio.load(str(ref_audio))

            # è½¬æ¢ä¸ºå•å£°é“
            if audio.shape[0] > 1:
                audio = audio.mean(0, keepdim=True)

            # é‡é‡‡æ ·
            audio = torchaudio.functional.resample(audio, sr, dac_model.sample_rate)

            # ç¼–ç ä¸º VQ codes
            audios = audio[None].to(device)
            audio_lengths = torch.tensor([audios.shape[2]], device=device, dtype=torch.long)

            with torch.no_grad():
                indices, _ = dac_model.encode(audios, audio_lengths)

            if indices.ndim == 3:
                indices = indices[0]

            # ä¿å­˜ .npy æ–‡ä»¶
            npy_filename = os.path.join(OUTPUT_DIR, f"speaker_{{speaker_id}}_codes.npy")
            np.save(npy_filename, indices.cpu().numpy())
            logger.info(f"âœ… å·²ä¿å­˜: {{npy_filename}}")

            # æ¸…ç†æ˜¾å­˜
            del audio, audios, indices
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        except Exception as e:
            logger.error(f"âŒ ç¼–ç è¯´è¯äºº {{speaker_id}} å¤±è´¥: {{e}}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
'''
        return script

    def _create_batch_generate_script(self, speaker_id, tasks, npy_file, ref_text, output_dir):
        """
        åˆ›å»ºæ‰¹é‡ç”Ÿæˆè„šæœ¬ï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ç‰ˆï¼‰

        ä¼˜åŒ–å†…å®¹ï¼š
        1. æ‰¹é‡ DAC è§£ç ï¼šæ”¶é›†å¤šä¸ªè¯­ä¹‰ codes åä¸€æ¬¡æ€§æ‰¹é‡è§£ç ï¼ˆ2.5x åŠ é€Ÿï¼‰
        2. å¼‚æ­¥ I/Oï¼šä½¿ç”¨ IOPipeline å¼‚æ­¥ä¿å­˜éŸ³é¢‘ï¼ˆ20% é¢å¤–æå‡ï¼‰
        """
        # å‡†å¤‡æ–‡æœ¬åˆ—è¡¨å’Œè¾“å‡ºæ–‡ä»¶ååˆ—è¡¨
        text_list = [task['target_text'] for task in tasks]
        segment_indices = [task['segment_index'] for task in tasks]

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        npy_file = os.path.abspath(npy_file)
        output_dir = os.path.abspath(output_dir)

        # è·å– backend ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼ˆç”¨äºå¯¼å…¥ IOPipelineï¼‰
        backend_dir = os.path.dirname(os.path.abspath(__file__))

        script = f'''#!/usr/bin/env python3
import os
import sys
import torch
import numpy as np
import soundfile as sf
from loguru import logger

# æ·»åŠ  backend ç›®å½•åˆ° Python è·¯å¾„ï¼ˆç”¨äºå¯¼å…¥ IOPipelineï¼‰
sys.path.insert(0, "{backend_dir}")

# å¯¼å…¥ Fish Speech çš„æ¨ç†æ¨¡å—
from fish_speech.models.text2semantic.inference import init_model, generate_long
from fish_speech.models.dac.inference import load_model as load_dac_model

# å¯¼å…¥ I/O æµæ°´çº¿ï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼‰
from fish_io_pipeline import IOPipeline

# é…ç½®
CHECKPOINT_PATH = "{self.checkpoint_dir}"
OUTPUT_DIR = "{output_dir}"
PROMPT_TOKENS_PATH = "{npy_file}"
REF_TEXT = {json.dumps(ref_text)}
TEXT_LIST = {json.dumps(text_list)}
SEGMENT_INDICES = {json.dumps(segment_indices)}

# ç”Ÿæˆå‚æ•°
MAX_NEW_TOKENS = 1024
TOP_P = 0.7
TEMPERATURE = 0.7
REPETITION_PENALTY = 1.2

# æ‰¹å¤„ç†å‚æ•°ï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼‰
BATCH_SIZE = 5  # æ¯æ‰¹ DAC è§£ç çš„æ ·æœ¬æ•°

def get_device():
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        return "mps"
    else:
        return "cpu"

def batch_dac_decode(dac_model, codes_list, device):
    """
    æ‰¹é‡ DAC è§£ç  - æ ¸å¿ƒä¼˜åŒ–ï¼

    åŸæ¥ï¼šé€ä¸ªè§£ç ï¼ŒN æ¬¡ GPU è°ƒç”¨
    ç°åœ¨ï¼šæ‰¹é‡è§£ç ï¼Œ1 æ¬¡ GPU è°ƒç”¨

    Args:
        dac_model: DAC æ¨¡å‹
        codes_list: è¯­ä¹‰ codes åˆ—è¡¨
        device: è®¾å¤‡

    Returns:
        éŸ³é¢‘æ•°ç»„åˆ—è¡¨
    """
    if not codes_list:
        return []

    # å‡†å¤‡æ‰¹é‡è¾“å…¥
    batch_codes = []
    codes_lens = []

    for codes in codes_list:
        if codes.ndim == 2:
            codes = codes.unsqueeze(0)
        batch_codes.append(codes)
        codes_lens.append(codes.shape[-1])

    # Padding åˆ°ç›¸åŒé•¿åº¦
    max_len = max(codes_lens)
    padded_codes = []

    for codes in batch_codes:
        if codes.shape[-1] < max_len:
            # Padding
            pad_len = max_len - codes.shape[-1]
            codes = torch.nn.functional.pad(codes, (0, pad_len), value=0)
        padded_codes.append(codes)

    # æ‰¹é‡æ‹¼æ¥
    batch_tensor = torch.cat(padded_codes, dim=0)  # [B, C, T]
    codes_lens_tensor = torch.tensor(codes_lens, device=device, dtype=torch.long)

    # æ‰¹é‡è§£ç ï¼ˆä¸€æ¬¡ GPU è°ƒç”¨ï¼ï¼‰
    with torch.no_grad():
        batch_fake_audios, audio_lengths = dac_model.decode(batch_tensor, codes_lens_tensor)

    # åˆ†ç¦»å„ä¸ªéŸ³é¢‘ï¼Œå¹¶æ ¹æ®å®é™…é•¿åº¦è£å‰ª
    audios = []
    for i in range(len(codes_lens)):
        # è·å–å®é™…éŸ³é¢‘é•¿åº¦ï¼ˆdecode å‡½æ•°å·²ç»è®¡ç®—å¥½äº†ï¼‰
        actual_audio_len = audio_lengths[i].item()

        # æå–éŸ³é¢‘å¹¶è£å‰ªåˆ°å®é™…é•¿åº¦ï¼ˆå»é™¤ paddingï¼‰
        audio = batch_fake_audios[i, 0].float().cpu().numpy()
        audio = audio[:actual_audio_len]
        audios.append(audio)

    return audios

def main():
    device = get_device()
    logger.info(f"ğŸš€ [ä¼˜åŒ–ç‰ˆ] ä½¿ç”¨è®¾å¤‡: {{device}}")

    # è®¾ç½®ç²¾åº¦
    if device == "cuda":
        precision = torch.bfloat16
    else:
        precision = torch.float32

    # åŠ è½½ DAC æ¨¡å‹
    logger.info("æ­£åœ¨åŠ è½½ DAC æ¨¡å‹...")
    dac_model = load_dac_model(
        config_name="modded_dac_vq",
        checkpoint_path=os.path.join(CHECKPOINT_PATH, "codec.pth"),
        device=device
    )
    logger.info("âœ… DAC æ¨¡å‹åŠ è½½å®Œæˆ")

    # åŠ è½½ Text2Semantic æ¨¡å‹
    logger.info("æ­£åœ¨åŠ è½½ Text2Semantic æ¨¡å‹...")
    llama_model, decode_one_token = init_model(
        checkpoint_path=CHECKPOINT_PATH,
        device=device,
        precision=precision,
        compile=False
    )
    logger.info("âœ… Text2Semantic æ¨¡å‹åŠ è½½å®Œæˆ")

    # åŠ è½½ Prompt Tokens
    logger.info(f"åŠ è½½ Prompt Tokens: {{PROMPT_TOKENS_PATH}}")
    prompt_tokens = np.load(PROMPT_TOKENS_PATH)
    prompt_tokens = torch.from_numpy(prompt_tokens).to(device).long()
    if prompt_tokens.ndim == 3:
        prompt_tokens = prompt_tokens[0]
    logger.info(f"âœ… Prompt Tokens åŠ è½½å®Œæˆ")

    # åˆ›å»º I/O æµæ°´çº¿ï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼‰
    io_pipeline = IOPipeline(num_threads=2)

    # æ‰¹é‡ç”Ÿæˆ
    total_segments = len(TEXT_LIST)
    logger.info(f"\\nğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {{total_segments}} ä¸ªç‰‡æ®µï¼ˆæ‰¹å¤§å°: {{BATCH_SIZE}}ï¼‰...")

    try:
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_segments, BATCH_SIZE):
            batch_end = min(batch_start + BATCH_SIZE, total_segments)
            batch_texts = TEXT_LIST[batch_start:batch_end]
            batch_indices = SEGMENT_INDICES[batch_start:batch_end]
            batch_num = batch_start // BATCH_SIZE + 1

            logger.info(f"\\nğŸ“¦ æ‰¹æ¬¡ {{batch_num}}: å¤„ç†ç‰‡æ®µ {{batch_start}}-{{batch_end-1}} ({{len(batch_texts)}} ä¸ª)")

            # Step 1: ç”Ÿæˆæ‰€æœ‰è¯­ä¹‰ tokensï¼ˆä»éœ€å¾ªç¯ï¼Œå— generate_long é™åˆ¶ï¼‰
            codes_list = []
            valid_indices = []

            for i, text in enumerate(batch_texts):
                segment_idx = batch_indices[i]
                logger.info(f"  [{{i+1}}/{{len(batch_texts)}}] ç”Ÿæˆè¯­ä¹‰ tokens (ç‰‡æ®µ {{segment_idx}}): {{text[:30]}}...")

                try:
                    codes = None
                    for response in generate_long(
                        model=llama_model,
                        device=device,
                        decode_one_token=decode_one_token,
                        text=text,
                        prompt_text=REF_TEXT,
                        prompt_tokens=prompt_tokens,
                        max_new_tokens=MAX_NEW_TOKENS,
                        top_p=TOP_P,
                        temperature=TEMPERATURE,
                        repetition_penalty=REPETITION_PENALTY,
                        num_samples=1
                    ):
                        if response.action == "sample":
                            codes = response.codes

                    if codes is not None:
                        codes_list.append(codes)
                        valid_indices.append(segment_idx)
                    else:
                        logger.error(f"  âŒ æœªèƒ½ç”Ÿæˆè¯­ä¹‰ tokens (ç‰‡æ®µ {{segment_idx}})")

                except Exception as e:
                    logger.error(f"  âŒ ç”Ÿæˆå¤±è´¥ (ç‰‡æ®µ {{segment_idx}}): {{e}}")

            if not codes_list:
                logger.warning(f"  âš ï¸ æ‰¹æ¬¡ {{batch_num}} æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•è¯­ä¹‰ tokens")
                continue

            # Step 2: æ‰¹é‡ DAC è§£ç ï¼ˆå…³é”®ä¼˜åŒ–ï¼ï¼‰
            logger.info(f"  ğŸ”„ æ‰¹é‡ DAC è§£ç  {{len(codes_list)}} ä¸ªæ ·æœ¬...")
            audios = batch_dac_decode(dac_model, codes_list, device)
            logger.info(f"  âœ… æ‰¹é‡è§£ç å®Œæˆ")

            # Step 3: å¼‚æ­¥ä¿å­˜ï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼‰
            logger.info(f"  ğŸ’¾ å¼‚æ­¥ä¿å­˜ {{len(audios)}} ä¸ªéŸ³é¢‘æ–‡ä»¶...")
            for audio, segment_idx in zip(audios, valid_indices):
                output_filename = os.path.join(OUTPUT_DIR, f"segment_{{segment_idx:04d}}.wav")
                # å¼‚æ­¥æäº¤ä¿å­˜ä»»åŠ¡ï¼ˆä¸é˜»å¡ï¼‰
                io_pipeline.async_save_audio(
                    audio=audio,
                    path=output_filename,
                    sample_rate=dac_model.sample_rate
                )

            logger.info(f"  âœ… æ‰¹æ¬¡ {{batch_num}} å¤„ç†å®Œæˆ")

            # æ¸…ç†æ˜¾å­˜
            del codes_list, audios
            if device == "mps":
                torch.mps.empty_cache()
            elif torch.cuda.is_available():
                torch.cuda.empty_cache()

        # ç­‰å¾…æ‰€æœ‰ I/O å®Œæˆ
        logger.info(f"\\nâ³ ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ä¿å­˜å®Œæˆ...")
        saved_files = io_pipeline.wait_all()
        logger.info(f"âœ… å·²ä¿å­˜ {{len(saved_files)}} ä¸ªéŸ³é¢‘æ–‡ä»¶")

    finally:
        # ç¡®ä¿å…³é—­ I/O æµæ°´çº¿
        io_pipeline.shutdown()

    logger.info("\\nğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()
'''
        return script
